# 音频录制开发概述

更新时间: 2025-12-16 16:35

## 如何选择音频录制开发方式

系统提供了多样化的API，来帮助开发者完成音频录制的开发，不同的API适用于不同录音输出格式、音频使用场景或不同开发语言。因此，选择合适的音频录制API，有助于降低开发工作量，实现更佳的音频录制效果。

- [AudioCapturer](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-audiocapturer-for-recording)：用于音频输入的ArkTS/JS API，仅支持PCM格式，需要应用持续读取音频数据进行工作。应用可以在音频输出后添加数据处理，要求开发者具备音频处理的基础知识，适用于更专业、更多样化的媒体录制应用开发。
    
- [OHAudio](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-ohaudio-for-recording)：用于音频输入的Native API，此API在设计上实现归一，同时支持普通音频通路和低时延通路。仅支持PCM格式，适用于依赖Native层实现音频输入功能的场景。
    

除上述方式外，也可以通过Media Kit中的AVRecorder实现音频录制。

- [AVRecorder](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-avrecorder-for-recording)：用于音频录制的ArkTS/JS API，集成了音频输入录制、音频编码和媒体封装的功能。开发者可以直接调用设备硬件如麦克风录音，并生成m4a音频文件。

## 开发音频录制应用须知

- 应用可以调用麦克风录制音频，但该行为属于隐私敏感行为，在调用麦克风前，需要先[向用户申请权限](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/request-user-authorization)：ohos.permission.MICROPHONE。
    
    如何使用和管理麦克风请参考[管理麦克风](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/mic-management)。
    
- 如果需要持续录制或后台录制，请申请长时任务避免进入挂起（Suspend）状态。具体参考[长时任务开发指导](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/continuous-task)。
    
- 录制需要在前台启动，启动后可以退后台。在后台启动录制将会失败。
    
- 应用录制音频时需要使用合适的录制流类型，请参考[使用合适的音频流类型](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-right-streamusage-and-sourcetype)。
    
- 如果开发者需要实现屏幕录制功能，可参考[使用AVScreenCaptureRecorder录屏写文件(ArkTs)](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-avscreencapture-arkts)和[使用AVScreenCapture录屏写文件(C/C++)](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-avscreencapture-for-file)。
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-recording "音频录制")
# 使用AudioCapturer开发音频录制功能

更新时间: 2025-12-16 16:35

AudioCapturer是音频采集器，用于录制PCM（Pulse Code Modulation）音频数据，适合有音频开发经验的开发者实现更灵活的录制功能。

## 开发指导

使用AudioCapturer录制音频涉及到AudioCapturer实例的创建、音频采集参数的配置、采集的开始与停止、资源的释放等。本开发指导将以一次录制音频数据的过程为例，向开发者讲解如何使用AudioCapturer进行音频录制，建议搭配[AudioCapturer的API说明](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiocapturer)阅读。

下图展示了AudioCapturer的状态变化，在创建实例后，调用对应的方法可以进入指定的状态实现对应的行为。需要注意的是在确定的状态执行不合适的方法可能导致AudioCapturer发生错误，建议开发者在调用状态转换的方法前进行状态检查，避免程序运行产生预期以外的结果。

**图1** AudioCapturer状态变化示意图

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163523.31798315565006708713609018877635:50001231000000:2800:FCFBE76D54BDBD7848805B23B5EE73277B54EDF8658E17C3D201B3377BB00C49.png)

使用on('stateChange')方法可以监听AudioCapturer的状态变化，每个状态对应值与说明见[AudioState](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audiostate8)。

### 开发步骤及注意事项

1. 配置音频采集参数并创建AudioCapturer实例，音频采集参数的详细信息可以查看[AudioCapturerOptions](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-i#audiocaptureroptions8)。
    
    说明
    
    当设置Mic音频源（即[SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#sourcetype8)为SOURCE_TYPE_MIC、SOURCE_TYPE_VOICE_RECOGNITION、SOURCE_TYPE_VOICE_COMMUNICATION、SOURCE_TYPE_VOICE_MESSAGE、SOURCE_TYPE_LIVE（从API version 20开始支持））时，需要申请麦克风权限ohos.permission.MICROPHONE，申请方式参考：[向用户申请授权](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/request-user-authorization)。
    
    1.  import { audio } from '@kit.AudioKit';
    
    2.  let audioStreamInfo: audio.AudioStreamInfo = {
    3.    samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率。
    4.    channels: audio.AudioChannel.CHANNEL_2, // 通道。
    5.    sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式。
    6.    encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式。
    7.  };
    
    8.  let audioCapturerInfo: audio.AudioCapturerInfo = {
    9.    source: audio.SourceType.SOURCE_TYPE_MIC, // 音源类型：Mic音频源。根据业务场景配置，参考SourceType。
    10.    capturerFlags: 0 // 音频采集器标志。
    11.  };
    
    12.  let audioCapturerOptions: audio.AudioCapturerOptions = {
    13.    streamInfo: audioStreamInfo,
    14.    capturerInfo: audioCapturerInfo
    15.  };
    
    16.  audio.createAudioCapturer(audioCapturerOptions, (err, data) => {
    17.    if (err) {
    18.      console.error(`Invoke createAudioCapturer failed, code is ${err.code}, message is ${err.message}`);
    19.    } else {
    20.      console.info('Invoke createAudioCapturer succeeded.');
    21.      let audioCapturer = data;
    22.    }
    23.  });
    
2. 调用on('readData')方法，订阅监听音频数据读入回调。
    
    注意
    
    - **线程管理**：不建议使用多线程来处理数据读取。若需使用多线程读取数据，需要做好线程管理。
    - **线程耗时**：readData 方法所在的线程中，不建议执行耗时任务。否则可能会导致数据处理线程响应回调延迟，进而引发录音数据缺失、卡顿、杂音等音频效果问题。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    2.  import { fileIo as fs } from '@kit.CoreFileKit';
    3.  import { common } from '@kit.AbilityKit';
    
    4.  class Options {
    5.    offset?: number;
    6.    length?: number;
    7.  }
    
    8.  let bufferSize: number = 0;
    9.  // 请在组件内获取context，确保this.getUIContext().getHostContext()返回结果为UIAbilityContext。
    10.  let context = this.getUIContext().getHostContext() as common.UIAbilityContext;
    11.  let path = context.cacheDir;
    12.  let filePath = path + '/StarWars10s-2C-48000-4SW.pcm';
    13.  let file: fs.File = fs.openSync(filePath, fs.OpenMode.READ_WRITE | fs.OpenMode.CREATE);
    14.  let readDataCallback = (buffer: ArrayBuffer) => {
    15.    let options: Options = {
    16.      offset: bufferSize,
    17.      length: buffer.byteLength
    18.    }
    19.    fs.writeSync(file.fd, buffer, options);
    20.    bufferSize += buffer.byteLength;
    21.  };
    
    22.  audioCapturer.on('readData', readDataCallback);
    
3. 调用start()方法进入running状态，开始录制音频。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioCapturer.start((err: BusinessError) => {
    3.    if (err) {
    4.      console.error(`Capturer start failed, code is ${err.code}, message is ${err.message}`);
    5.    } else {
    6.      console.info('Capturer start success.');
    7.    }
    8.  });
    
4. 调用stop()方法停止录制。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioCapturer.stop((err: BusinessError) => {
    3.    if (err) {
    4.      console.error(`Capturer stop failed, code is ${err.code}, message is ${err.message}`);
    5.    } else {
    6.      console.info('Capturer stopped.');
    7.    }
    8.  });
    
5. 调用release()方法销毁实例，释放资源。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioCapturer.release((err: BusinessError) => {
    3.    if (err) {
    4.      console.error(`capturer release failed, code is ${err.code}, message is ${err.message}`);
    5.    } else {
    6.      console.info('capturer released.');
    7.    }
    8.  });
    

### 完整示例

下面展示了使用AudioCapturer录制音频的完整示例代码。

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';
3. import { fileIo as fs } from '@kit.CoreFileKit';
4. import { common } from '@kit.AbilityKit';

5. const TAG = 'AudioCapturerDemo';

6. class Options {
7.   offset?: number;
8.   length?: number;
9. }

10. let audioCapturer: audio.AudioCapturer | undefined = undefined;
11. let audioStreamInfo: audio.AudioStreamInfo = {
12.   samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率。
13.   channels: audio.AudioChannel.CHANNEL_2, // 通道。
14.   sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式。
15.   encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式。
16. };
17. let audioCapturerInfo: audio.AudioCapturerInfo = {
18.   source: audio.SourceType.SOURCE_TYPE_MIC, // 音源类型：Mic音频源。根据业务场景配置，参考SourceType。
19.   capturerFlags: 0 // 音频采集器标志。
20. };
21. let audioCapturerOptions: audio.AudioCapturerOptions = {
22.   streamInfo: audioStreamInfo,
23.   capturerInfo: audioCapturerInfo
24. };
25. let file: fs.File;
26. let readDataCallback: Callback<ArrayBuffer>;

27. async function initArguments(context: common.UIAbilityContext) {
28.   let bufferSize: number = 0;
29.   let path = context.cacheDir;
30.   let filePath = path + '/StarWars10s-2C-48000-4SW.pcm';
31.   file = fs.openSync(filePath, fs.OpenMode.READ_WRITE | fs.OpenMode.CREATE);
32.   readDataCallback = (buffer: ArrayBuffer) => {
33.     let options: Options = {
34.       offset: bufferSize,
35.       length: buffer.byteLength
36.     }
37.     fs.writeSync(file.fd, buffer, options);
38.     bufferSize += buffer.byteLength;
39.   };
40. }

41. // 初始化，创建实例，设置监听事件。
42. async function init() {
43.   audio.createAudioCapturer(audioCapturerOptions, (err, capturer) => { // 创建AudioCapturer实例。
44.     if (err) {
45.       console.error(`Invoke createAudioCapturer failed, code is ${err.code}, message is ${err.message}`);
46.       return;
47.     }
48.     console.info(`${TAG}: create AudioCapturer success`);
49.     audioCapturer = capturer;
50.     if (audioCapturer !== undefined) {
51.       audioCapturer.on('readData', readDataCallback);
52.     }
53.   });
54. }

55. // 开始一次音频采集。
56. async function start() {
57.   if (audioCapturer !== undefined) {
58.     let stateGroup = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];
59.     if (stateGroup.indexOf(audioCapturer.state.valueOf()) === -1) { // 当且仅当状态为STATE_PREPARED、STATE_PAUSED和STATE_STOPPED之一时才能启动采集。
60.       console.error(`${TAG}: start failed`);
61.       return;
62.     }

63.     // 启动采集。
64.     audioCapturer.start((err: BusinessError) => {
65.       if (err) {
66.         console.error('Capturer start failed.');
67.       } else {
68.         console.info('Capturer start success.');
69.       }
70.     });
71.   }
72. }

73. // 停止采集。
74. async function stop() {
75.   if (audioCapturer !== undefined) {
76.     // 只有采集器状态为STATE_RUNNING或STATE_PAUSED的时候才可以停止。
77.     if (audioCapturer.state.valueOf() !== audio.AudioState.STATE_RUNNING && audioCapturer.state.valueOf() !== audio.AudioState.STATE_PAUSED) {
78.       console.info('Capturer is not running or paused');
79.       return;
80.     }

81.     // 停止采集。
82.     audioCapturer.stop((err: BusinessError) => {
83.       if (err) {
84.         console.error('Capturer stop failed.');
85.       } else {
86.         console.info('Capturer stop success.');
87.       }
88.     });
89.   }
90. }

91. // 销毁实例，释放资源。
92. async function release() {
93.   if (audioCapturer !== undefined) {
94.     // 采集器状态不是STATE_RELEASED或STATE_NEW状态，才能release。
95.     if (audioCapturer.state.valueOf() === audio.AudioState.STATE_RELEASED || audioCapturer.state.valueOf() === audio.AudioState.STATE_NEW) {
96.       console.info('Capturer already released');
97.       return;
98.     }

99.     // 释放资源。
100.     audioCapturer.release((err: BusinessError) => {
101.       if (err) {
102.         console.error('Capturer release failed.');
103.       } else {
104.         fs.closeSync(file);
105.         console.info('Capturer release success.');
106.       }
107.     });
108.   }
109. }

110. @Entry
111. @Component
112. struct Index {
113.   build() {
114.     Scroll() {
115.       Column() {
116.         Row() {
117.           Column() {
118.             Text('初始化').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
119.           }
120.           .backgroundColor(Color.White)
121.           .borderRadius(30)
122.           .width('45%')
123.           .height('25%')
124.           .margin({ right: 12, bottom: 12 })
125.           .onClick(async () => {
126.             let context = this.getUIContext().getHostContext() as common.UIAbilityContext;
127.             initArguments(context);
128.             init();
129.           });

130.           Column() {
131.             Text('开始录制').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
132.           }
133.           .backgroundColor(Color.White)
134.           .borderRadius(30)
135.           .width('45%')
136.           .height('25%')
137.           .margin({ bottom: 12 })
138.           .onClick(async () => {
139.             start();
140.           });
141.         }

142.         Row() {
143.           Column() {
144.             Text('停止录制').fontSize(16).margin({ top: 12 });
145.           }
146.           .id('audio_effect_manager_card')
147.           .backgroundColor(Color.White)
148.           .borderRadius(30)
149.           .width('45%')
150.           .height('25%')
151.           .margin({ right: 12, bottom: 12 })
152.           .onClick(async () => {
153.             stop();
154.           });

155.           Column() {
156.             Text('释放资源').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
157.           }
158.           .backgroundColor(Color.White)
159.           .borderRadius(30)
160.           .width('45%')
161.           .height('25%')
162.           .margin({ bottom: 12 })
163.           .onClick(async () => {
164.             release();
165.           });
166.         }
167.         .padding(12)
168.       }
169.       .height('100%')
170.       .width('100%')
171.       .backgroundColor('#F1F3F5');
172.     }
173.   }
174. }

### 设置静音打断模式

如果需要实现录音全程不被系统基于焦点并发规则打断的效果，提供将打断策略从停止录音切换为静音录制的功能，录音过程中也不影响其他应用启动录音。开发者在创建AudioCapturer实例时，调用[setWillMuteWhenInterrupted](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiocapturer#setwillmutewheninterrupted20)接口设置是否开启静音打断模式。默认不开启，此时由音频焦点策略管理并发音频流的执行顺序。开启后，被其他应用打断导致停止或暂停录制时会进入静音录制状态，在此状态下录制的音频没有声音。

### 回声消除功能

回声消除功能可在支持的设备上有效消除录音过程中的回声干扰，提升音频采集质量。开发者可通过指定特定的Mic音频源[SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#sourcetype8)（SOURCE_TYPE_VOICE_COMMUNICATION、SOURCE_TYPE_LIVE）来启用该功能，系统将会自动对采集的音频信号进行回声消除处理。

在启用前，建议先调用[isAcousticEchoCancelerSupported](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#isacousticechocancelersupported20)接口（从API version 20开始支持）查询当前设备对音频输入源类型[SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#sourcetype8)是否支持回声消除功能，以确保功能的可用性。若支持，则可在创建音频录制构造器时设置相应的Mic音频源，从而激活回声消除处理流程。

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-recording-overview "音频录制开发概述")
# 使用OHAudio开发音频录制功能(C/C++)

更新时间: 2025-12-16 16:35

OHAudio是系统在API version 10中引入的一套C API，此API在设计上实现归一，同时支持普通音频通路和低时延通路。仅支持PCM格式，适用于依赖Native层实现音频输入功能的场景。

OHAudio音频录制状态变化示意图：

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163527.60223848569943251171511280346773:50001231000000:2800:42522F6F665FA1E88392E7228AC1EDC8489766A4E43CB347CB8015A33376F4F4.png)

## 使用入门

开发者要使用OHAudio提供的录制能力，需要添加对应的头文件。

### 在 CMake 脚本中链接动态库

1. target_link_libraries(sample PUBLIC libohaudio.so)

### 添加头文件

开发者通过引入<[native_audiostreambuilder.h](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h)>和<[native_audiocapturer.h](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiocapturer-h)>头文件，使用音频录制相关API。

1. #include <ohaudio/native_audiocapturer.h>
2. #include <ohaudio/native_audiostreambuilder.h>

## 开发步骤

详细的API说明请参考[OHAudio](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-ohaudio)。

### 音频流构造器

OHAudio提供OH_AudioStreamBuilder接口，遵循构造器设计模式，用于构建音频流。开发者需要根据业务场景，指定对应的[OH_AudioStream_Type](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_type)。

OH_AudioStream_Type包含两种类型：

- AUDIOSTREAM_TYPE_RENDERER
- AUDIOSTREAM_TYPE_CAPTURER

使用[OH_AudioStreamBuilder_Create](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_create)创建构造器示例：

1. OH_AudioStreamBuilder* builder;
2. OH_AudioStreamBuilder_Create(&builder, streamType);

在音频业务结束之后，开发者应该执行[OH_AudioStreamBuilder_Destroy](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_destroy)接口来销毁构造器。

1. OH_AudioStreamBuilder_Destroy(builder);

开发者可以通过以下几个步骤来实现一个简单的录制功能。

### 实现音频录制

1. 创建构造器。
    
    1. OH_AudioStreamBuilder* builder;
    2. OH_AudioStreamBuilder_Create(&builder, AUDIOSTREAM_TYPE_CAPTURER);
    
2. 配置音频流参数。
    
    创建音频录制构造器后，可以设置音频流所需要的参数，可以参考下面的案例。
    
    1. // 设置音频采样率。
    2. OH_AudioStreamBuilder_SetSamplingRate(builder, 48000);
    3. // 设置音频声道。
    4. OH_AudioStreamBuilder_SetChannelCount(builder, 2);
    5. // 设置音频采样格式。
    6. OH_AudioStreamBuilder_SetSampleFormat(builder, AUDIOSTREAM_SAMPLE_S16LE);
    7. // 设置音频流的编码类型。
    8. OH_AudioStreamBuilder_SetEncodingType(builder, AUDIOSTREAM_ENCODING_TYPE_RAW);
    9. // 设置输入音频流的工作场景。
    10. OH_AudioStreamBuilder_SetCapturerInfo(builder, AUDIOSTREAM_SOURCE_TYPE_MIC);
    
    注意，音频录制的音频数据需要通过回调接口读入，开发者要实现回调接口，从API version 12开始支持使用[OH_AudioStreamBuilder_SetCapturerReadDataCallback](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_setcapturerreaddatacallback)设置回调函数。回调函数的声明请查看[OH_AudioCapturer_OnReadDataCallback](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiocapturer-h#oh_audiocapturer_onreaddatacallback)。
    
3. 设置音频回调函数。
    
    多音频并发处理可参考文档[处理音频焦点事件](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency)，仅接口语言差异。
    
    1. // 自定义读入数据函数。
    2. void MyOnReadData(
    3.     OH_AudioCapturer* capturer,
    4.     void* userData,
    5.     void* audioData,
    6.     int32_t audioDataSize)
    7. {
    8.     // 从buffer中取出length长度的录音数据。
    9. }
    10. // 自定义音频中断事件函数。
    11. void MyOnInterruptEvent(
    12.     OH_AudioCapturer* capturer,
    13.     void* userData,
    14.     OH_AudioInterrupt_ForceType type,
    15.     OH_AudioInterrupt_Hint hint)
    16. {
    17.     // 根据type和hint表示的音频中断信息，更新录制器状态和界面。
    18. }
    19. // 自定义异常回调函数。
    20. void MyOnError(
    21.     OH_AudioCapturer* capturer,
    22.     void* userData,
    23.     OH_AudioStream_Result error)
    24. {
    25.     // 根据error表示的音频异常信息，做出相应的处理。
    26. }
    
    27. // 配置音频中断事件回调函数。
    28. OH_AudioCapturer_OnInterruptCallback OnIntereruptCb = MyOnInterruptEvent;
    29. OH_AudioStreamBuilder_SetCapturerInterruptCallback(builder, OnIntereruptCb, nullptr);
    
    30. // 配置音频异常回调函数。
    31. OH_AudioCapturer_OnErrorCallback OnErrorCb = MyOnError;
    32. OH_AudioStreamBuilder_SetCapturerErrorCallback(builder, OnErrorCb, nullptr);
    
    33. // 配置音频输入流的回调。
    34. OH_AudioCapturer_OnReadDataCallback OnReadDataCb = MyOnReadData;
    35. OH_AudioStreamBuilder_SetCapturerReadDataCallback(builder, OnReadDataCb, nullptr);
    
4. 构造录制音频流。
    
    1. OH_AudioCapturer* audioCapturer;
    2. OH_AudioStreamBuilder_GenerateCapturer(builder, &audioCapturer);
    
5. 使用音频流。
    
    录制音频流中包含以下接口，用来实现对音频流的控制。
    
    |接口|说明|
    |:--|:--|
    |OH_AudioStream_Result OH_AudioCapturer_Start(OH_AudioCapturer* capturer)|开始录制。|
    |OH_AudioStream_Result OH_AudioCapturer_Pause(OH_AudioCapturer* capturer)|暂停录制。|
    |OH_AudioStream_Result OH_AudioCapturer_Stop(OH_AudioCapturer* capturer)|停止录制。|
    |OH_AudioStream_Result OH_AudioCapturer_Flush(OH_AudioCapturer* capturer)|释放缓存数据。|
    |OH_AudioStream_Result OH_AudioCapturer_Release(OH_AudioCapturer* capturer)|释放录制实例。|
    
6. 释放构造器。
    
    构造器不再使用时，需要释放相关资源。
    
    1. OH_AudioStreamBuilder_Destroy(builder);
    

### 设置低时延模式

当设备支持低时延通路时，开发者可以使用低时延模式创建音频录制构造器，获得更低时延的音频体验。

开发流程与普通录制（[实现音频录制](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-ohaudio-for-recording#%E5%AE%9E%E7%8E%B0%E9%9F%B3%E9%A2%91%E5%BD%95%E5%88%B6)）场景一致，仅需要在步骤1创建音频录制构造器时，调用[OH_AudioStreamBuilder_SetLatencyMode()](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_setlatencymode)设置低时延模式。

注意

- 当音频录制场景[OH_AudioStream_SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_sourcetype)为AUDIOSTREAM_SOURCE_TYPE_VOICE_COMMUNICATION时，不支持主动设置低时延模式，系统会根据设备的能力，决策输出的音频通路。
- 部分场景（如通话来电）下系统能力受限会回落至普通音频通路模式，缓冲区大小也会发生变化，此时应同普通音频通路模式一样根据缓冲区大小将缓冲区中数据一次性全部取走，否则录制的数据会出现不连续，导致杂音。

1. OH_AudioStream_LatencyMode latencyMode = AUDIOSTREAM_LATENCY_MODE_FAST;
2. OH_AudioStreamBuilder_SetLatencyMode(builder, latencyMode);

### 设置静音打断模式

静音打断模式提供将打断策略从停止录音切换为静音录制的功能，可以实现录音全程不被系统基于焦点并发规则打断的效果，并且录音过程中也不影响其他应用启动录音。开发者在创建音频录制构造器时，调用[OH_AudioStreamBuilder_SetCapturerWillMuteWhenInterrupted](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_setcapturerwillmutewheninterrupted)接口设置是否开启静音打断模式。默认不开启，此时由音频焦点策略管理并发音频流的执行顺序。开启后，被其他应用打断导致停止或暂停录制时会进入静音录制状态，在此状态下录制的音频没有声音。

### 回声消除功能

回声消除功能可在支持的设备上有效消除录音过程中的回声干扰，提升音频采集质量。开发者可通过指定特定的音频输入源类型[OH_AudioStream_SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_sourcetype)（AUDIOSTREAM_SOURCE_TYPE_VOICE_COMMUNICATION、AUDIOSTREAM_SOURCE_TYPE_LIVE）来启用该功能，系统将会自动对采集的音频信号进行回声消除处理。

在启用前，建议先调用[OH_AudioStreamManager_IsAcousticEchoCancelerSupported](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audio-stream-manager-h#oh_audiostreammanager_isacousticechocancelersupported)接口（从API version 20开始支持）查询当前设备对音频输入源类型[OH_AudioStream_SourceType](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_sourcetype)是否支持回声消除功能，以确保功能的可用性。若支持，则可在创建音频录制构造器时通过[OH_AudioStreamBuilder_SetCapturerInfo](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_setcapturerinfo) 设置相应的音频输入源类型，从而激活回声消除处理流程。

## 注意事项

从API version 12开始**不再推荐**使用[OH_AudioCapturer_Callbacks](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-ohaudio-oh-audiocapturer-callbacks-struct)的方式设置音频回调函数。若必须使用，需要注意在设置音频回调函数时，通过下面两种方式中的任意一种来设置音频回调函数，避免不可预期的行为。

- 方式1：请确保[OH_AudioCapturer_Callbacks](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-ohaudio-oh-audiocapturer-callbacks-struct)的每一个回调都被**自定义的回调方法**或**空指针**初始化。
    
    1. // 自定义读入数据函数。
    2. int32_t MyOnReadData(
    3.     OH_AudioCapturer* capturer,
    4.     void* userData,
    5.     void* buffer,
    6.     int32_t length)
    7. {
    8.     // 从buffer中取出length长度的录音数据。
    9.     return 0;
    10. }
    11. // 自定义音频中断事件函数。
    12. int32_t MyOnInterruptEvent(
    13.     OH_AudioCapturer* capturer,
    14.     void* userData,
    15.     OH_AudioInterrupt_ForceType type,
    16.     OH_AudioInterrupt_Hint hint)
    17. {
    18.     // 根据type和hint表示的音频中断信息，更新录制器状态和界面。
    19.     return 0;
    20. }
    21. OH_AudioCapturer_Callbacks callbacks;
    
    22. // 配置回调函数，如果需要监听，则赋值。
    23. callbacks.OH_AudioCapturer_OnReadData = MyOnReadData;
    24. callbacks.OH_AudioCapturer_OnInterruptEvent = MyOnInterruptEvent;
    
    25. // （必选）如果不需要监听，使用空指针初始化。
    26. callbacks.OH_AudioCapturer_OnStreamEvent = nullptr;
    27. callbacks.OH_AudioCapturer_OnError = nullptr;
    
- 方式2：使用前，初始化并清零结构体。
    
    1. // 自定义读入数据函数。
    2. int32_t MyOnReadData(
    3.     OH_AudioCapturer* capturer,
    4.     void* userData,
    5.     void* buffer,
    6.     int32_t length)
    7. {
    8.     // 从buffer中取出length长度的录音数据。
    9.     return 0;
    10. }
    11. // 自定义音频中断事件函数。
    12. int32_t MyOnInterruptEvent(
    13.     OH_AudioCapturer* capturer,
    14.     void* userData,
    15.     OH_AudioInterrupt_ForceType type,
    16.     OH_AudioInterrupt_Hint hint)
    17. {
    18.     // 根据type和hint表示的音频中断信息，更新录制器状态和界面。
    19.     return 0;
    20. }
    21. OH_AudioCapturer_Callbacks callbacks;
    
    22. // 使用前，初始化并清零结构体。
    23. memset(&callbacks, 0, sizeof(OH_AudioCapturer_Callbacks));
    
    24. // 配置需要的回调函数。
    25. callbacks.OH_AudioCapturer_OnReadData = MyOnReadData;
    26. callbacks.OH_AudioCapturer_OnInterruptEvent = MyOnInterruptEvent;
    

## 示例代码

- [音频低时延录制与播放](https://gitee.com/harmonyos_samples/audio-native)

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-audiocapturer-for-recording "使用AudioCapturer开发音频录制功能")
# 管理麦克风

更新时间: 2025-12-16 16:35

因为在录制过程中需要使用麦克风录制相关音频数据，所以建议开发者在调用录制接口前查询麦克风状态，并在录制过程中监听麦克风的状态变化，避免影响录制效果。

在音频录制过程中，用户可以将麦克风静音，此时录音过程正常进行，录制生成的数据文件的大小随录制时长递增，但写入文件的数据均为0，即无声数据（空白数据）。

## 开发步骤及注意事项

在AudioVolumeGroupManager中提供了管理麦克风状态的方法，接口的详细说明请参考[API文档](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiovolumegroupmanager)。

1. 创建audioVolumeGroupManager对象。
    
    1. import { audio } from '@kit.AudioKit';
    
    2. let audioVolumeGroupManager: audio.AudioVolumeGroupManager;
    
    3. // 创建audioVolumeGroupManager对象。
    4. async function loadVolumeGroupManager() {
    5.   const groupid = audio.DEFAULT_VOLUME_GROUP_ID;
    6.   audioVolumeGroupManager = await audio.getAudioManager().getVolumeManager().getVolumeGroupManager(groupid);
    7.   console.info('audioVolumeGroupManager create success.');
    8. }
    
2. 调用[on('micStateChange')](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiovolumegroupmanager#onmicstatechange9)监听麦克风状态变化，当麦克风静音状态发生变化时将通知应用。
    
    目前此订阅接口在单进程多AudioManager实例的使用场景下，仅最后一个实例的订阅生效，其他实例的订阅会被覆盖（即使最后一个实例没有进行订阅），因此推荐使用单一AudioManager实例进行开发。
    
    1. // 监听麦克风状态变化。
    2. async function on() {
    3.   audioVolumeGroupManager.on('micStateChange', (micStateChange: audio.MicStateChangeEvent) => {
    4.     console.info(`Current microphone status is: ${micStateChange.mute} `);
    5.   });
    6. }
    
3. 调用[isMicrophoneMute](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiovolumegroupmanager#ismicrophonemute9)查询麦克风当前静音状态，返回true为静音，false为非静音。
    
    1. // 查询麦克风是否静音。
    2. async function isMicrophoneMute() {
    3.   await audioVolumeGroupManager.isMicrophoneMute().then((value: boolean) => {
    4.     console.info(`isMicrophoneMute is: ${value}.`);
    5.   });
    6. }
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-fast-recording "低时延音频录制(C/C++)")
# 音频录制流管理

更新时间: 2025-12-16 16:35

对于录制音频类的应用，开发者需要关注该应用的音频流的状态以做出相应的操作，比如监听到状态为结束时，及时提示用户录制已结束。

## 读取或监听应用内音频流状态变化

参考[使用AudioCapturer开发音频录制功能](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-audiocapturer-for-recording)或[audio.createAudioCapturer](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-f#audiocreateaudiocapturer8)，完成AudioCapturer的创建，然后可以通过以下两种方式查看音频流状态的变化：

- 方法1：直接查看AudioCapturer的[state](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiocapturer#%E5%B1%9E%E6%80%A7)：
    
    1. let audioCapturerState: audio.AudioState = audioCapturer.state;
    2. console.info(`Current state is: ${audioCapturerState }`)
    
- 方法2：注册stateChange监听AudioCapturer的状态变化：
    
    1. audioCapturer.on('stateChange', (capturerState: audio.AudioState) => {
    2.   console.info(`State change to: ${capturerState}`)
    3. });
    

获取state后可对照[AudioState](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audiostate8)来进行相应的操作，比如显示录制结束的提示等。

## 读取或监听所有录制流的变化

如果部分应用需要查询获取所有音频流的变化信息，可以通过AudioStreamManager读取或监听所有音频流的变化。

如下为音频流管理调用关系图：

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163531.71426000390500168754362539037571:50001231000000:2800:1A373A8FD3DFB472ACBE1A4A82474AFA700B402A333873664EB72E0D85CE3873.png)

在进行应用开发的过程中，开发者需要先调用[getStreamManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiomanager#getstreammanager9)创建AudioStreamManager实例，进而通过该实例管理音频流。

详细API含义可参考[AudioStreamManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager)。

## 开发步骤及注意事项

1. 创建AudioStreamManager实例。
    
    1. import { audio } from '@kit.AudioKit';
    2. import { BusinessError } from '@kit.BasicServicesKit';
    
    3. let audioManager = audio.getAudioManager();
    4. let audioStreamManager = audioManager.getStreamManager();
    
2. 使用[on('audioCapturerChange')](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#onaudiocapturerchange9)监听音频录制流更改事件。 如果音频流监听应用需要在音频录制流状态变化、设备变化时获取通知，可以订阅该事件。
    
    1. audioStreamManager.on('audioCapturerChange', (AudioCapturerChangeInfoArray: audio.AudioCapturerChangeInfoArray) =>  {
    2.   for (let i = 0; i < AudioCapturerChangeInfoArray.length; i++) {
    3.     console.info(`## CapChange on is called for element ${i} ##`);
    4.     console.info(`StreamId for ${i} is: ${AudioCapturerChangeInfoArray[i].streamId}`);
    5.     console.info(`Source for ${i} is: ${AudioCapturerChangeInfoArray[i].capturerInfo.source}`);
    6.     console.info(`Flag  ${i} is: ${AudioCapturerChangeInfoArray[i].capturerInfo.capturerFlags}`);
    7.     let devDescriptor: audio.AudioDeviceDescriptors = AudioCapturerChangeInfoArray[i].deviceDescriptors;
    8.     for (let j = 0; j < AudioCapturerChangeInfoArray[i].deviceDescriptors.length; j++) {
    9.       console.info(`Id: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].id}`);
    10.       console.info(`Type: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].deviceType}`);
    11.       console.info(`Role: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].deviceRole}`);
    12.       console.info(`Name: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].name}`);
    13.       console.info(`Address: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].address}`);
    14.       console.info(`SampleRates: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].sampleRates[0]}`);
    15.       console.info(`ChannelCounts ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].channelCounts[0]}`);
    16.       console.info(`ChannelMask: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].channelMasks}`);
    17.     }
    18.   }
    19. });
    
3. （可选）使用[off('audioCapturerChange')](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#offaudiocapturerchange9)取消监听音频录制流变化。
    
    1. audioStreamManager.off('audioCapturerChange');
    2. console.info('CapturerChange Off is called');
    
4. （可选）使用[getCurrentAudioCapturerInfoArray](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#getcurrentaudiocapturerinfoarray9)获取当前音频录制流的信息。该接口可获取音频录制流唯一ID、音频采集器信息以及音频录制设备信息。
    
    说明
    
    对所有音频流状态进行监听的应用需要[声明权限](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/declare-permissions)ohos.permission.USE_BLUETOOTH，否则无法获得实际的设备名称和设备地址信息，查询到的设备名称和设备地址（蓝牙设备的相关属性）将为空字符串。
    
    从API version 20开始，通常在音频录制启动前调用[isRecordingAvailable](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#isrecordingavailable20)，判断当前传入的音频采集器信息中音源类型的录制是否可以启动成功。
    
    1. async function getCurrentAudioCapturerInfoArray(){
    2.   await audioStreamManager.getCurrentAudioCapturerInfoArray().then((AudioCapturerChangeInfoArray: audio.AudioCapturerChangeInfoArray) => {
    3.     console.info('getCurrentAudioCapturerInfoArray  Get Promise Called ');
    4.     if (AudioCapturerChangeInfoArray != null) {
    5.       for (let i = 0; i < AudioCapturerChangeInfoArray.length; i++) {
    6.         console.info(`StreamId for ${i} is: ${AudioCapturerChangeInfoArray[i].streamId}`);
    7.         console.info(`Source for ${i} is: ${AudioCapturerChangeInfoArray[i].capturerInfo.source}`);
    8.         console.info(`Flag  ${i} is: ${AudioCapturerChangeInfoArray[i].capturerInfo.capturerFlags}`);
    9.         for (let j = 0; j < AudioCapturerChangeInfoArray[i].deviceDescriptors.length; j++) {
    10.           console.info(`Id: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].id}`);
    11.           console.info(`Type: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].deviceType}`);
    12.           console.info(`Role: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].deviceRole}`);
    13.           console.info(`Name: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].name}`);
    14.           console.info(`Address: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].address}`);
    15.           console.info(`SampleRates: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].sampleRates[0]}`);
    16.           console.info(`ChannelCounts ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].channelCounts[0]}`);
    17.           console.info(`ChannelMask: ${i} : ${AudioCapturerChangeInfoArray[i].deviceDescriptors[j].channelMasks}`);
    18.         }
    19.       }
    20.     }
    21.   }).catch((err: BusinessError) => {
    22.     console.error(`Invoke getCurrentAudioCapturerInfoArray failed, code is ${err.code}, message is ${err.message}`);
    23.   });
    24. }
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/mic-management "管理麦克风")
# 共享音频输入

更新时间: 2025-12-16 16:35

音频输入的音频源通常是由内置麦克风、外接设备或远端分布式设备的采集的音频数据，但也可能是其他应用发送到系统以供播放的音频数据。根据音频源的不同，音频输入可分为两类：内录型音频输入和外录型音频输入。

- 内录型音频输入：是指以系统内部音频数据作为音频源的输入类型，简称为内录，对应的流称为内录流。
    
    常见的内录音频包括录屏时录制的其他应用播放的音频数据、投播到其他设备上播放的音频数据。
    
- 外录型音频输入：是指通过音频接口将系统外部的声音采集进来作为音频源的输入类型，简称为外录，对应的流称为外录流。
    
    常见的外录示例有录音机的音频录制、语音助手的语音唤醒和识别、以及在VoIP通话中传输给对端的音频录制。
    

通常，当应用请求录音时，它是独占音频输入的。然而，在某些情况下，可能会有两个或多个应用同时或先后请求录音，在同一时间段内都希望从音频输入中获得数据，这种情况称为录音并发，录音并发又细分为：录音并存和录音并行。

- 录音并存是指一个或多个应用创建的不同录音客户端（AudioCapturer）在同一时间段内同时存在的状态。
- 录音并行是指在录音并存的基础上，不同录音客户端（AudioCapturer）启动的录音流在同一时间段内同时处于运行（Running）状态，即同时进行音频录制。

当录音并发发生时，每个请求录音的应用都希望能够获得音频输入数据，但此时会面临将同一音频源同时传输给多个应用的问题。

## 录音并发

此前，系统不支持不同应用程序间不同录音流类型的录音并发，会受到严格的[音频焦点策略管控](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E7%AD%96%E7%95%A5)。

内录型与外录型音频输入之间的并发录音在安全隐私策略允许下不受此限制，例如在录屏应用中启用内录流时，可以同时使用录音机录音或语音助手进行语音识别。

当前系统版本虽已放宽了部分录音流类型之间的并行录音限制，允许多个录音流同时获取音频数据，但由于这些数据来源于同一音频输入，音频效果相同，可能只能满足部分并行录音需求。

### 优先级调控方案

大多数情况下，音频数据的效果依赖于系统对音频输入数据的优化处理策略。

应用发起录音时，系统会依据应用下发的录音流类型等相关参数识别音频场景，并选择合适的策略处理输入数据。例如，当应用发起VoIP通话时，系统会对VoIP录音流进行降低噪声、增强人声等优化处理。

一些录音流类型的音频录制仅需获取音频输入数据即可，但另一些录音流类型的音频录制则高度依赖于系统的优化处理，不当的处理可能会导致不良体验。因此，对于这类录音流类型的音频录制，在并发录音时需确保系统仍能配置适当的优化处理策略。为此，系统为这些录音流类型配置了优先级，并在原有的[音频焦点策略](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E7%AD%96%E7%95%A5)管控方案上增加了优先级调控方案。

其调控原则是**优先采用高优先级录音流类型对应的优化策略处理音频输入数据**。

### 录音并发策略

当前录音并发策略整体遵循如下原则：

1. 在并发录音时，是否能同时获取音频输入数据取决于各录音流类型的[音频焦点策略](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E7%AD%96%E7%95%A5)，开发人员需确保焦点适配良好。
2. 音频输入数据的效果将根据系统依据当前优先级调控方案选择的优化处理策略来决定，建议开发人员在并发录音时告知用户录音数据的效果可能受到影响。

## 使用建议

当前系统通过[音频焦点策略](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E7%AD%96%E7%95%A5)与优先级调控的双重机制，针对录音并发场景做了初步管理。尽管系统已经允许个别不同录音流类型的流实现有限并行录音，但仍需注意以下关键点：

### 录音并发的局限性

- 音频效果不可控：并发录音时，多条录音流的音频输入数据来自同一音频输入，可能影响音频效果。
- 系统开销：并发录音可能增加系统开销。

### 对开发者的建议

- 了解[音频焦点策略](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E7%AD%96%E7%95%A5)，做好焦点适配，及时[处理焦点变化](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-playback-concurrency#%E5%A4%84%E7%90%86%E9%9F%B3%E9%A2%91%E7%84%A6%E7%82%B9%E5%8F%98%E5%8C%96)。
    
- 尽量避免并发录音场景，在应用设计时尽量避免与其他录音任务重叠。如需要，可以在界面中提示用户“当前存在其他录音任务”。
    
    如果必须进行并发录音，建议在界面上明确告知用户音频质量可能会受到影响。
    
- [选择合适的录音流类型](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-right-streamusage-and-sourcetype)，不同的录音流类型对应着不同的系统优化处理策略，建议开发者根据需求选择合适的[录音流类型](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#sourcetype8)。
    
- 在没有录音需求时，应及时停止并释放录音资源，避免对其他录音流产生影响，并减少不必要的系统开销。
    
- 应用实现不应过度依赖固定的录音并发规则，而应根据系统接口返回的状态进行自适应处理。
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-recording-stream-management "音频录制流管理")
# 实现音频耳返

更新时间: 2025-12-16 16:35

实现音频耳返的功能，可将音频实时传输到耳机中，让用户可以实时听到自己或者其他相关声音。

常用于K歌类应用，将录制的人声和背景音乐实时送到耳机中，使用户通过反馈即时调整，获得更好的使用体验。

## 使用前提

- 开发者可使用OHAudio提供的播放和录制能力相结合，将录制获取的音频数据作为播放的音频输入，实现耳返功能。
    
    实现参考[使用OHAudio开发音频播放功能](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-ohaudio-for-playback)、[使用OHAudio开发音频录制功能](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-ohaudio-for-recording)。
    
- 当前仅支持通过有线耳机实现耳返功能。音频由有线耳机采集并播放。
    

## 开发指导

### 创建音频录制

通过OHAudio提供OH_AudioStreamBuilder接口，遵循构造器设计模式，构建录制音频流。指定对应的[OH_AudioStream_Type](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_type), 设置为AUDIOSTREAM_TYPE_CAPTURER。

1. OH_AudioStreamBuilder* builder;
2. OH_AudioStreamBuilder_Create(&builder, AUDIOSTREAM_TYPE_CAPTURER);

### 创建音频播放

通过OHAudio提供OH_AudioStreamBuilder接口，遵循构造器设计模式，构建播放音频流。指定对应的[OH_AudioStream_Type](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostream-base-h#oh_audiostream_type), AUDIOSTREAM_TYPE_RENDERER。

1. OH_AudioStreamBuilder* builder;
2. OH_AudioStreamBuilder_Create(&builder, AUDIOSTREAM_TYPE_RENDERER);

### 设置低时延模式

为了实现更好的耳返功能，需要使得音频从录制到播放保持较低的时延，当设备支持低时延通路时，开发者需要使用低时延模式来进行录制和播放。

在创建音频录制构造器时调用[OH_AudioStreamBuilder_SetLatencyMode()](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiostreambuilder-h#oh_audiostreambuilder_setlatencymode)设置低时延模式，播放和录制均按如下方式设置为低时延模式。

1. OH_AudioStream_LatencyMode latencyMode = AUDIOSTREAM_LATENCY_MODE_FAST;
2. OH_AudioStreamBuilder_SetLatencyMode(builder, latencyMode);

为实现实时耳返功能，需创建一个公共缓存区用于存储录制的数据，并及时从该缓存区获取数据写入播放构造器。

### 定义公共缓存和录制、播放函数

1. // 创建一块公共缓存buffer，用于写入录制数据和读取播放数据。

2. // 自定义读入录制数据函数。
3.     int32_t MyOnReadData(
4.         OH_AudioCapturer* capturer,
5.         void* userData,
6.         void* buffer,
7.         int32_t length)
8.     {
9.         // 从buffer中取出length长度的录音数据，放在创建好的公共缓存buffer中，用于供renderer进行读取。
10.         return 0;
11.     }

12.     // 自定义写入数据函数。
13.     int32_t MyOnWriteData(
14.         OH_AudioRenderer* renderer,
15.         void* userData,
16.         void* buffer,
17.         int32_t length)
18.     {
19.         // 从公共缓存buffer中读取数据，并按length长度写入buffer。
20.         return 0;
21.     }

注意

应用的公共缓存大小不应设置过大，以避免增加耳返时延，影响用户体验。开发者应根据时延要求和抗抖动要求，选择合适的缓存大小，确保用户体验。

### 设置音频流参数

以录制流参数设置为例：

1. // 设置音频采样率。
2. OH_AudioStreamBuilder_SetSamplingRate(builder, 48000);
3. // 设置音频声道。
4. OH_AudioStreamBuilder_SetChannelCount(builder, 2);
5. // 设置音频采样格式。
6. OH_AudioStreamBuilder_SetSampleFormat(builder, AUDIOSTREAM_SAMPLE_S16LE);
7. // 设置音频流的编码类型。
8. OH_AudioStreamBuilder_SetEncodingType(builder, AUDIOSTREAM_ENCODING_TYPE_RAW);
9. // 设置输出音频流的工作场景。
10. OH_AudioStreamBuilder_SetRendererInfo(builder, AUDIOSTREAM_SOURCE_TYPE_MIC);

对于播放流，除了音频流的工作场景外，其余设置为和录制流相同的参数。

工作场景参数设置如下：

1. OH_AudioStreamBuilder_SetRendererInfo(builder, AUDIOSTREAM_USAGE_MUSIC);

### 设置录制回调函数

1. // 自定义读入数据函数。
2. int32_t MyOnReadData(
3.     OH_AudioCapturer* capturer,
4.     void* userData,
5.     void* buffer,
6.     int32_t length)
7. {
8.     // 从buffer中取出length长度的录音数据。
9.     return 0;
10. }
11. // 自定义音频流事件函数。
12. int32_t MyOnStreamEvent(
13.     OH_AudioCapturer* capturer,
14.     void* userData,
15.     OH_AudioStream_Event event)
16. {
17.     // 根据event表示的音频流事件信息，更新录制器状态和界面。
18.     return 0;
19. }
20. // 自定义音频中断事件函数。
21. int32_t MyOnInterruptEvent(
22.     OH_AudioCapturer* capturer,
23.     void* userData,
24.     OH_AudioInterrupt_ForceType type,
25.     OH_AudioInterrupt_Hint hint)
26. {
27.     // 根据type和hint表示的音频中断信息，更新录制器状态和界面。
28.     return 0;
29. }
30. // 自定义异常回调函数。
31. int32_t MyOnError(
32.     OH_AudioCapturer* capturer,
33.     void* userData,
34.     OH_AudioStream_Result error)
35. {
36.     // 根据error表示的音频异常信息，做出相应的处理。
37.     return 0;
38. }

39. OH_AudioCapturer_Callbacks callbacks;

40. // 配置回调函数。
41. callbacks.OH_AudioCapturer_OnReadData = MyOnReadData;
42. callbacks.OH_AudioCapturer_OnStreamEvent = MyOnStreamEvent;
43. callbacks.OH_AudioCapturer_OnInterruptEvent = MyOnInterruptEvent;
44. callbacks.OH_AudioCapturer_OnError = MyOnError;

45. // 设置音频输入流的回调。
46. OH_AudioStreamBuilder_SetCapturerCallback(builder, callbacks, nullptr);

### 设置播放回调函数

1.     // 自定义写入数据函数。
2.     int32_t MyOnWriteData(
3.         OH_AudioRenderer* renderer,
4.         void* userData,
5.         void* buffer,
6.         int32_t length)
7.     {
8.         // 从公共缓存BUFFER中读取数据，并按length长度写入buffer。
9.         return 0;
10.     }
11.     // 自定义音频流事件函数。
12.     int32_t MyOnStreamEvent(
13.         OH_AudioRenderer* renderer,
14.         void* userData,
15.         OH_AudioStream_Event event)
16.     {
17.         // 根据event表示的音频流事件信息，更新播放器状态和界面。
18.         return 0;
19.     }
20.     // 自定义音频中断事件函数。
21.     int32_t MyOnInterruptEvent(
22.         OH_AudioRenderer* renderer,
23.         void* userData,
24.         OH_AudioInterrupt_ForceType type,
25.         OH_AudioInterrupt_Hint hint)
26.     {
27.         // 根据type和hint表示的音频中断信息，更新播放器状态和界面。
28.         return 0;
29.     }
30.     // 自定义异常回调函数。
31.     int32_t MyOnError(
32.         OH_AudioRenderer* renderer,
33.         void* userData,
34.         OH_AudioStream_Result error)
35.     {
36.         // 根据error表示的音频异常信息，做出相应的处理。
37.         return 0;
38.     }

39.     OH_AudioRenderer_Callbacks callbacks;

40.     // 配置回调函数。
41.     callbacks.OH_AudioRenderer_OnWriteData = MyOnWriteData;
42.     callbacks.OH_AudioRenderer_OnStreamEvent = MyOnStreamEvent;
43.     callbacks.OH_AudioRenderer_OnInterruptEvent = MyOnInterruptEvent;
44.     callbacks.OH_AudioRenderer_OnError = MyOnError;

45.     // 设置输出音频流的回调。
46.     OH_AudioStreamBuilder_SetRendererCallback(builder, callbacks, nullptr);

### 构造录制音频流

1. OH_AudioCapturer* audioCapturer;
2. OH_AudioStreamBuilder_GenerateCapturer(builder, &audioCapturer);

### 构造播放音频流

1. OH_AudioRenderer* audioRenderer;
2. OH_AudioStreamBuilder_GenerateRenderer(builder, &audioRenderer);

### 使用音频流

以录制为例，开发者可以使用以下接口控制音频流的开始、暂停、停止和释放。

注意

在实现耳返功能时，开发者需同时控制录制流和播放流，确保两者同步。

|接口|说明|
|:--|:--|
|OH_AudioStream_Result [OH_AudioRenderer_Start](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiorenderer-h#oh_audiorenderer_start)(OH_AudioRenderer* renderer)|开始播放。|
|OH_AudioStream_Result [OH_AudioRenderer_Pause](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiorenderer-h#oh_audiorenderer_pause)(OH_AudioRenderer* renderer)|暂停播放。|
|OH_AudioStream_Result [OH_AudioRenderer_Stop](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiorenderer-h#oh_audiorenderer_stop)(OH_AudioRenderer* renderer)|停止播放。|
|OH_AudioStream_Result [OH_AudioRenderer_Flush](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiorenderer-h#oh_audiorenderer_flush)(OH_AudioRenderer* renderer)|释放缓存数据。|
|OH_AudioStream_Result [OH_AudioRenderer_Release](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audiorenderer-h#oh_audiorenderer_release)(OH_AudioRenderer* renderer)|释放播放实例。|

### 释放构造器

构造器不再使用时，采用如下方式释放资源。

1. OH_AudioStreamBuilder_Destroy(builder);

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-recording-concurrency "共享音频输入")
# 实现音频低时延耳返

更新时间: 2025-12-16 16:35

从API version 20开始，支持音频低时延耳返。

AudioLoopback是音频返听器，可将音频以更低时延的方式实时传输到耳机中，让用户可以实时听到自己或者其他的相关声音。

常用于K歌类应用，将录制的人声和背景音乐实时传送到耳机中，使用户通过反馈即时进行调整，获得更好的使用体验。

当启用音频返听时，系统会创建低时延渲染器与低时延采集器，实现低时延耳返功能。采集的音频直接通过内部路由返回到渲染器。对于渲染器，其音频焦点策略与[STREAM_USAGE_MUSIC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#streamusage)相匹配。对于采集器，其音频焦点策略与[SOURCE_TYPE_MIC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#sourcetype8)相匹配。

输入\输出设备由系统自动选择。如果当前输入\输出不支持低时延，则音频返听无法启用。在运行过程中，如果音频焦点被另一个音频流抢占，输入\输出设备切换到不支持低时延的设备，系统会自动禁用音频返听。

## 使用前提

- 当前仅支持通过有线耳机实现低时延返听功能，音频由有线耳机进行采集并播放。
    
- 低功耗渲染器和低时延渲染器在API version 20不能实现并发。若要启用渲染器，建议采用[STREAM_USAGE_UNKNOWN](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#streamusage)；系统内决策采用[STREAM_USAGE_MUSIC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#streamusage)创建普通渲染器。
    

## 开发指导

使用AudioLoopback音频返听涉及到[isAudioLoopbackSupported](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiostreammanager#isaudioloopbacksupported20)返听能力查询、AudioLoopback实例创建、返听音量设置、返听状态监听与返听启用禁用等。本开发指导将以一次启用返听的过程为例，向开发者讲解如何使用AudioLoopback进行音频返听，建议搭配[AudioLoopback](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback)的API说明阅读。

下图展示了AudioLoopback的状态变化，在创建实例后，调用对应的方法可以进入指定的状态实现对应行为。

需要注意的是在确定的状态执行不合适的方法可能导致AudioLoopback发生错误，建议开发者在调用状态转换的方法前进行状态检查，避免程序运行产生预期以外的结果。

**AudioLoopback状态变化示意图**

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163535.83141128181577866044551153134231:50001231000000:2800:5EDE7B1887737BA13B5367CA2705B42930FDBBCFB7281EC4B115A992ED6F9855.png)

使用[on('statusChange')](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#onstatuschange20)方法可以监听AudioLoopback的状态变化，每个状态对应值与说明见[AudioLoopbackStatus](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackstatus20)。

### 开发步骤及注意事项

1. 查询返听能力并创建AudioLoopback实例，音频返听模式可以查看[AudioLoopbackMode](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackmode20)。
    
    说明
    
    返听需要申请麦克风权限ohos.permission.MICROPHONE，申请方式参考：[向用户申请授权](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/request-user-authorization)。
    
    1.  import { audio } from '@kit.AudioKit';
    2.  import { BusinessError } from '@kit.BasicServicesKit';
    
    3.  let mode: audio.AudioLoopbackMode = audio.AudioLoopbackMode.HARDWARE;
    4.  let audioLoopback: audio.AudioLoopback;
    5.  let isSupported = audio.getAudioManager().getStreamManager().isAudioLoopbackSupported(mode);
    6.  if (isSupported) {
    7.    audio.createAudioLoopback(mode).then((loopback) => {
    8.      audioLoopback = loopback;
    9.      console.info('Invoke createAudioLoopback succeeded.');
    10.    }).catch((err: BusinessError) => {
    11.      console.error(`Invoke createAudioLoopback failed, code is ${err.code}, message is ${err.message}.`);
    12.    });
    13.  }
    
2. 调用[getStatus](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#getstatus20)方法，查询当前返听状态。
    
    注意
    
    音频返听状态受音频焦点、低时延管控、采集与播放设备等因素影响。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioLoopback.getStatus().then((status: audio.AudioLoopbackStatus) => {
    3.    console.info(`getStatus success, status is ${status}.`);
    4.  }).catch((err: BusinessError) => {
    5.    console.error(`getStatus failed, code is ${err.code}, message is ${err.message}.`);
    6.  })
    
3. 调用[setVolume](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#setvolume20)方法，设置音频返听音量。
    
    注意
    
    - 在启用返听前设置音量，音量将在启用返听成功后生效。
    - 在启用返听后设置音量，音量将立即生效。
    - 启用返听前未设置音量，启用返听时将采用默认音量0.5。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioLoopback.setVolume(0.5).then(() => {
    3.    console.info('setVolume success.');
    4.  }).catch((err: BusinessError) => {
    5.    console.error(`setVolume failed, code is ${err.code}, message is ${err.message}.`);
    6.  });
    
4. 从API21开始，支持调用[setReverbPreset](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#setreverbpreset21)方法，设置音频返听的混响模式。
    
    注意
    
    - 在启用返听前设置混响模式，混响模式将在启用返听成功后生效。
    - 在启用返听后设置混响模式，混响模式将立即生效。
    - 启用返听前未设置混响模式，启用返听时将采用默认混响模式[THEATER](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackreverbpreset21)。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    2.  try {
    3.    audioLoopback.setReverbPreset(audio.AudioLoopbackReverbPreset.THEATER);
    4.  } catch (err) {
    5.    console.error(`setReverbPreset :ERROR: ${err}`);
    6.  }
    
5. 从API21开始，支持调用[getReverbPreset](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#getreverbpreset21)方法，查询当前的音频返听的混响模式。
    
    注意
    
    若未设置混响模式，查询得到将是默认混响模式[THEATER](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackreverbpreset21)。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    2.  try {
    3.    let reverbPreset = audioLoopback.getReverbPreset();
    4.  } catch (err) {
    5.    console.error(`getReverbPreset:ERROR: ${err}`);
    6.  }
    
6. 从API21开始，支持调用[setEqualizerPreset](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#setequalizerpreset21)方法，设置音频返听的均衡器类型。
    
    注意
    
    - 在启用返听前设置均衡器类型，均衡器类型将在启用返听成功后生效。
    - 在启用返听后设置均衡器类型，均衡器类型将立即生效。
    - 启用返听前未设置均衡器类型，启用返听时将采用默认均衡器类型[FULL](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackequalizerpreset21)。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    2.  try {
    3.    audioLoopback.setEqualizerPreset(audio.AudioLoopbackEqualizerPreset.FULL);
    4.  } catch (err) {
    5.    console.error(`setEqualizerPreset :ERROR: ${err}`);
    6.  }
    
7. 从API21开始，支持调用[getEqualizerPreset](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#getequalizerpreset21)方法，查询当前的音频返听的均衡器类型。
    
    注意
    
    若未设置均衡器类型，查询得到将是默认均衡器类型[FULL](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioloopbackequalizerpreset21)。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    2.  try {
    3.    let reverbPreset = audioLoopback.getEqualizerPreset();
    4.  } catch (err) {
    5.    console.error(`getEqualizerPreset:ERROR: ${err}`);
    6.  }
    
8. 调用[enable](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioloopback#enable20)方法，启用或禁用音频返听功能。
    
    1.  import { BusinessError } from '@kit.BasicServicesKit';
    
    2.  audioLoopback.enable(true).then((isSuccess) => {
    3.    if (isSuccess) {
    4.      console.info('enable success.');
    5.    } else {
    6.      console.info('enable failed.');
    7.    }
    8.  }).catch((err: BusinessError) => {
    9.    console.error(`enable failed, code is ${err.code}, message is ${err.message}.`);
    10.  });
    
    11.  audioLoopback.enable(false).then((isSuccess) => {
    12.    if (isSuccess) {
    13.      console.info('disable success.');
    14.    } else {
    15.      console.info('disable failed.');
    16.    }
    17.  }).catch((err: BusinessError) => {
    18.    console.error(`disable failed, code is ${err.code}, message is ${err.message}.`);
    19.  });
    

### 完整示例

使用AudioLoopback启用音频低时延返听示例代码如下所示。

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';
3. import { common } from '@kit.AbilityKit';

4. const TAG = 'AudioLoopbackDemo';

5. let mode: audio.AudioLoopbackMode = audio.AudioLoopbackMode.HARDWARE;
6. let audioLoopback: audio.AudioLoopback | undefined = undefined;
7. let currentReverbPreset: audio.AudioLoopbackReverbPreset = audio.AudioLoopbackReverbPreset.THEATER;
8. let currentEqualizerPreset: audio.AudioLoopbackEqualizerPreset = audio.AudioLoopbackEqualizerPreset.FULL;

9. let statusChangeCallback = (status: audio.AudioLoopbackStatus) => {
10.   if (status == audio.AudioLoopbackStatus.UNAVAILABLE_DEVICE) {
11.     console.info('Audio loopback status is: UNAVAILABLE_DEVICE');
12.   } else if (status == audio.AudioLoopbackStatus.UNAVAILABLE_SCENE) {
13.     console.info('Audio loopback status is: UNAVAILABLE_SCENE');
14.   } else if (status == audio.AudioLoopbackStatus.AVAILABLE_IDLE) {
15.     console.info('Audio loopback status is: AVAILABLE_IDLE');
16.   } else if (status == audio.AudioLoopbackStatus.AVAILABLE_RUNNING) {
17.     console.info('Audio loopback status is: AVAILABLE_RUNNING');
18.   }
19. };

20. // 查询能力，创建实例。
21. function init() {
22.   let isSupported = audio.getAudioManager().getStreamManager().isAudioLoopbackSupported(mode);
23.   if (isSupported) {
24.     audio.createAudioLoopback(mode).then((loopback) => {
25.       console.info('Invoke createAudioLoopback succeeded.');
26.       audioLoopback = loopback;
27.     }).catch((err: BusinessError) => {
28.       console.error(`Invoke createAudioLoopback failed, code is ${err.code}, message is ${err.message}.`);
29.     });
30.   } else {
31.     console.error('Audio loopback is unsupported.');
32.   }
33. }

34. // 设置音频返听音量。
35. async function setVolume(volume: number) {
36.   if (audioLoopback !== undefined) {
37.     try {
38.       await audioLoopback.setVolume(volume);
39.       console.info(`Invoke setVolume ${volume} succeeded.`);
40.     } catch (err) {
41.       console.error(`Invoke setVolume failed, code is ${err.code}, message is ${err.message}.`);
42.     }
43.   } else {
44.     console.error('Audio loopback not created.');
45.   }
46. }

47. // 设置音频返听的混响模式。
48. async function setReverbPreset(preset: audio.AudioLoopbackReverbPreset) {
49.   if (audioLoopback !== undefined) {
50.     try {
51.       audioLoopback.setReverbPreset(preset);
52.       console.info(`setReverbPreset( ${preset} succeeded.`);
53.       currentReverbPreset = audioLoopback.getReverbPreset(); // 查询当前的混响模式，防止设置失败。
54.     } catch (err) {
55.       console.error(`setReverbPreset( failed, code is ${err.code}, message is ${err.message}.`);
56.     }
57.   } else {
58.     console.error('Audio loopback not created.');
59.   }
60. }

61. // 设置音频返听的均衡器类型。
62. async function setEqualizerPreset(preset: audio.AudioLoopbackEqualizerPreset) {
63.   if (audioLoopback !== undefined) {
64.     try {
65.       audioLoopback.setEqualizerPreset(preset);
66.       console.info(`setEqualizerPreset ${preset} succeeded.`);
67.       currentEqualizerPreset = audioLoopback.getEqualizerPreset(); // 查询当前的均衡器类型，防止设置失败。
68.     } catch (err) {
69.       console.error(`setEqualizerPreset failed, code is ${err.code}, message is ${err.message}.`);
70.     }
71.   } else {
72.     console.error('Audio loopback not created.');
73.   }
74. }

75. // 设置监听事件，启用音频返听。
76. async function enable() {
77.   if (audioLoopback !== undefined) {
78.     try {
79.       let status = await audioLoopback.getStatus();
80.       if (status == audio.AudioLoopbackStatus.AVAILABLE_IDLE) {
81.         // 注册监听。
82.         audioLoopback.on('statusChange', statusChangeCallback);
83.         // 启动返听。
84.         let success = await audioLoopback.enable(true);
85.         if (success) {
86.           console.info('Invoke enable succeeded');
87.         } else {
88.           status = await audioLoopback.getStatus();
89.           statusChangeCallback(status);
90.         }
91.       } else {
92.         statusChangeCallback(status);
93.       }
94.     } catch (err) {
95.       console.error(`Invoke enable failed, code is ${err.code}, message is ${err.message}.`);
96.     }
97.   } else {
98.     console.error('Audio loopback not created.');
99.   }
100. }

101. // 禁用音频返听，关闭监听事件。
102. async function disable() {
103.   if (audioLoopback !== undefined) {
104.     try {
105.       let status = await audioLoopback.getStatus();
106.       if (status == audio.AudioLoopbackStatus.AVAILABLE_RUNNING) {
107.         // 禁用返听。
108.         let success = await audioLoopback.enable(false);
109.         if (success) {
110.           console.info('Invoke disable succeeded');
111.           // 关闭监听。
112.           audioLoopback.off('statusChange', statusChangeCallback);
113.         } else {
114.           status = await audioLoopback.getStatus();
115.           statusChangeCallback(status);
116.         }
117.       } else {
118.         statusChangeCallback(status);
119.       }
120.     } catch (err) {
121.       console.error(`Invoke disable failed, code is ${err.code}, message is ${err.message}.`);
122.     }
123.   } else {
124.     console.error('Audio loopback not created.');
125.   }
126. }

### 音频低时延返听示例

可参考[使用AudioLoopback启用音频低时延返听的示例](https://gitcode.com/openharmony/applications_app_samples/tree/master/code/BasicFeature/Media/Audio)。

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-ear-monitor "实现音频耳返")
# 查询和监听音频输入设备

更新时间: 2025-12-16 16:35

本模块提供音频输入设备管理能力，包括查询输入设备信息、监听设备连接状态变化等。具体API说明可参考文档[AudioRoutingManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioroutingmanager)。

## 创建AudioRoutingManager实例

在使用AudioRoutingManager管理音频设备前，需要先导入模块并创建实例。

1. import { audio } from '@kit.AudioKit';  // 导入audio模块。

2. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。
3. let audioRoutingManager = audioManager.getRoutingManager();  // 再调用AudioManager的方法创建AudioRoutingManager实例。

## 支持的音频输入设备类型

目前支持的音频输入设备见下表：

|名称|值|说明|
|:--|:--|:--|
|WIRED_HEADSET|3|有线耳机，带麦克风。|
|BLUETOOTH_SCO|7|蓝牙设备SCO（Synchronous Connection Oriented）连接。|
|MIC|15|麦克风。|
|USB_HEADSET|22|USB耳机，带麦克风。|

## 获取输入设备信息

使用getDevices()方法可以获取当前所有输入设备的信息。

1. import { audio } from '@kit.AudioKit';

2. audioRoutingManager.getDevices(audio.DeviceFlag.INPUT_DEVICES_FLAG).then((data: audio.AudioDeviceDescriptors) => {
3.   console.info('Promise returned to indicate that the device list is obtained.');
4. });

## 监听设备连接状态变化

可以设置监听事件来监听设备连接状态的变化，当有设备连接或断开时触发回调：

1. import { audio } from '@kit.AudioKit';

2. // 监听音频设备状态变化。
3. audioRoutingManager.on('deviceChange', audio.DeviceFlag.INPUT_DEVICES_FLAG, (deviceChanged: audio.DeviceChangeAction) => {
4.   console.info('device change type : ' + deviceChanged.type);  // 设备连接状态变化，0为连接，1为断开连接。
5.   console.info('device descriptor size : ' + deviceChanged.deviceDescriptors.length);
6.   console.info('device change descriptor : ' + deviceChanged.deviceDescriptors[0].deviceRole);  // 设备角色。
7.   console.info('device change descriptor : ' + deviceChanged.deviceDescriptors[0].deviceType);  // 设备类型。
8. });

9. // 取消监听音频设备状态变化。
10. audioRoutingManager.off('deviceChange', (deviceChanged: audio.DeviceChangeAction) => {
11.   console.info('Should be no callback.');
12. });

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-device "音频设备路由管理")
# 查询和监听音频输出设备

更新时间: 2025-12-16 16:35

应用可通过以下两种方式管理全局音频输出设备：

- 通常情况下，可以[通过AudioRoutingManager查询和监听音频输出设备](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-output-device-management#%E9%80%9A%E8%BF%87audioroutingmanager%E6%9F%A5%E8%AF%A2%E5%92%8C%E7%9B%91%E5%90%AC%E9%9F%B3%E9%A2%91%E8%BE%93%E5%87%BA%E8%AE%BE%E5%A4%87)。
- 从API version 20开始，AudioSessionManager提供了部分输出设备管理的接口，支持[通过AudioSession查询和监听音频输出设备](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-output-device-management#%E9%80%9A%E8%BF%87audiosession%E6%9F%A5%E8%AF%A2%E5%92%8C%E7%9B%91%E5%90%AC%E9%9F%B3%E9%A2%91%E8%BE%93%E5%87%BA%E8%AE%BE%E5%A4%87)，方便在使用AudioSession管理音频焦点的同时管理音频输出。

## 通过AudioRoutingManager查询和监听音频输出设备

本模块提供音频输出设备管理能力，包括查询设备信息和监听连接状态变化。具体API说明请参考文档[AudioRoutingManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audioroutingmanager)。

### 创建AudioRoutingManager实例

在使用AudioRoutingManager管理音频设备前，需要先导入模块并创建实例。

1. import { audio } from '@kit.AudioKit';  // 导入audio模块。

2. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。

3. let audioRoutingManager = audioManager.getRoutingManager();  // 再调用AudioManager的方法创建AudioRoutingManager实例。

### 支持的音频输出设备类型

目前支持的输出设备如下表所示：

|名称|值|说明|
|:--|:--|:--|
|EARPIECE|1|听筒。|
|SPEAKER|2|扬声器。|
|WIRED_HEADSET|3|有线耳机，带麦克风。|
|WIRED_HEADPHONES|4|有线耳机，无麦克风。|
|BLUETOOTH_SCO|7|蓝牙设备SCO（Synchronous Connection Oriented）连接。|
|BLUETOOTH_A2DP|8|蓝牙设备A2DP（Advanced Audio Distribution Profile）连接。|
|USB_HEADSET|22|USB耳机，带麦克风。|

### 获取输出设备信息

使用getDevices()方法可以获取当前所有输出设备的信息。

1. import { audio } from '@kit.AudioKit';

2. audioRoutingManager.getDevices(audio.DeviceFlag.OUTPUT_DEVICES_FLAG).then((data: audio.AudioDeviceDescriptors) => {
3.   console.info('Promise returned to indicate that the device list is obtained.');
4. });

### 监听设备连接状态变化

设置监听事件以监控设备连接状态的变化，设备连接或断开时触发回调。

说明

监听设备连接状态变化可以监听到全部的设备连接状态变化，不建议作为应用处理自动暂停的依据。应用如需处理自动暂停相关业务，可参考[音频流输出设备变更原因](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-output-device-change#%E9%9F%B3%E9%A2%91%E6%B5%81%E8%BE%93%E5%87%BA%E8%AE%BE%E5%A4%87%E5%8F%98%E6%9B%B4%E5%8E%9F%E5%9B%A0)。

1. import { audio } from '@kit.AudioKit';

2. // 监听音频设备状态变化。
3. audioRoutingManager.on('deviceChange', audio.DeviceFlag.OUTPUT_DEVICES_FLAG, (deviceChanged: audio.DeviceChangeAction) => {
4.   console.info(`device change type : ${deviceChanged.type}`);  // 设备连接状态变化，0为连接，1为断开连接。
5.   console.info(`device descriptor size : ${deviceChanged.deviceDescriptors.length}`);
6.   console.info(`device change descriptor : ${deviceChanged.deviceDescriptors[0].deviceRole}`);  // 设备角色。
7.   console.info(`device change descriptor : ${deviceChanged.deviceDescriptors[0].deviceType}`);  // 设备类型。
8. });

9. // 取消监听音频设备状态变化。
10. audioRoutingManager.off('deviceChange');

### 获取最高优先级输出设备信息

使用getPreferOutputDeviceForRendererInfo()方法, 可以获取当前最高优先级的输出设备。

说明

最高优先级输出设备表示声音将在此设备输出的设备。

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';

3. let rendererInfo: audio.AudioRendererInfo = {
4.     usage: audio.StreamUsage.STREAM_USAGE_MUSIC,// 音频流使用类型：音乐。根据业务场景配置，参考StreamUsage。
5.     rendererFlags: 0 // 音频渲染器标志。
6. };

7. async function getPreferOutputDeviceForRendererInfo() {
8.   audioRoutingManager.getPreferOutputDeviceForRendererInfo(rendererInfo).then((desc: audio.AudioDeviceDescriptors) => {
9.     console.info(`device descriptor: ${desc}`);
10.   }).catch((err: BusinessError) => {
11.     console.error(`Result ERROR: ${err}`);
12.   })
13. }

### 监听最高优先级输出设备变化

1. import { audio } from '@kit.AudioKit';

2. let rendererInfo: audio.AudioRendererInfo = {
3.     usage: audio.StreamUsage.STREAM_USAGE_MUSIC, // 音频流使用类型：音乐。根据业务场景配置，参考StreamUsage。
4.     rendererFlags: 0 // 音频渲染器标志。
5. };

6. // 监听最高优先级输出设备变化。
7. audioRoutingManager.on('preferOutputDeviceChangeForRendererInfo', rendererInfo, (desc: audio.AudioDeviceDescriptors) => {
8.     console.info(`device change descriptor : ${desc[0].deviceRole}`);  // 设备角色。
9.     console.info(`device change descriptor : ${desc[0].deviceType}`);  // 设备类型。
10. });

11. // 取消监听最高优先级输出设备变化。
12. audioRoutingManager.off('preferOutputDeviceChangeForRendererInfo');

## 通过AudioSession查询和监听音频输出设备

应用使用播放器的SDK播放音频流，不持有AudioRenderer对象，因此无法灵活控制播放设备的选择和状态监听。从API version 20开始，AudioSession不仅增加了焦点管理功能，还提供了音频输出设备管理功能，包括设置默认输出设备和监听设备变化。请参考以下文档获取更多信息：

- ArkTS API：[AudioSessionManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager)
- C API：[OH_AudioSessionManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-audio-session-manager-h)

### 创建AudioSession实例

在使用AudioSessionManager管理音频设备前，需要先导入模块并创建实例。

1. import { audio } from '@kit.AudioKit';  // 导入audio模块。

2. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。

3. let audioSessionManager = audioManager.getSessionManager();  // 再调用AudioManager的方法创建AudioSessionManager实例。

### 设置本机默认音频输出设备

[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setdefaultoutputdevice20)可以用于设置本机默认输出设备。

说明

- 由于AudioSession是应用级设置，调用本接口设置默认音频输出设备会覆盖AudioRenderer的setDefaultOutputDevice接口设置的音频输出设备信息。
- 调用setDefaultOutputDevice设置音频输出设备后，如需取消，可将参数设为audio.DeviceType.DEFAULT，将音频设备选择权交还给系统。否则，每次调用activateAudioSession时，应用选择的默认输出设备将生效。

1. import { BusinessError } from '@kit.BasicServicesKit';

2. // 设置默认输出设备为本机扬声器。
3. audioSessionManager.setDefaultOutputDevice(audio.DeviceType.SPEAKER).then(() => {
4.   console.info('setDefaultOutputDevice Success!');
5. }).catch((err: BusinessError) => {
6.   console.error(`setDefaultOutputDevice Fail: ${err}`);
7. });

8. // 设置默认输出设备为默认设备，即取消应用设置的默认设备，交由系统选择设备。
9. audioSessionManager.setDefaultOutputDevice(audio.DeviceType.DEFAULT).then(() => {
10.   console.info('setDefaultOutputDevice Success!');
11. }).catch((err: BusinessError) => {
12.   console.error(`setDefaultOutputDevice Fail: ${err}`);
13. });

### 查询本机默认音频输出设备

应用可以通过[getDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#getdefaultoutputdevice20)查询本机默认输出设备类型。

说明

本接口用于查询通过[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setdefaultoutputdevice20)接口设置的输出设备。

1. let deviceType = audioSessionManager.getDefaultOutputDevice();
2. console.info('getDefaultOutputDevice Success, deviceType: ${deviceType}');

### 监听输出设备变化

应用可以通过注册[CurrentOutputDeviceChangedEvent](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-i#currentoutputdevicechangedevent20)监听输出设备的连接状态变化。

说明

currentOutputDeviceChangedCallback 包含设备变更的原因及推荐的后续操作。应用应根据不同的变更原因进行处理，并按系统推荐的操作继续或停止当前播放。

1. import { audio } from '@kit.AudioKit';

2. // 同一监听事件中，on方法和off方法传入callback参数一致，off方法取消对应on方法订阅的监听。
3. let currentOutputDeviceChangedCallback = (currentOutputDeviceChangedEvent: audio.CurrentOutputDeviceChangedEvent) => {
4.   console.info(`reason of audioSessionStateChanged: ${currentOutputDeviceChangedEvent.changeReason} `);

5.   switch (currentOutputDeviceChangedEvent.changeReason) {
6.     case audio.AudioStreamDeviceChangeReason.REASON_OLD_DEVICE_UNAVAILABLE:
7.       // 响应设备不可用事件，如果应用处于播放状态，应暂停播放，更新UX界面。
8.       break;
9.     case audio.AudioStreamDeviceChangeReason.REASON_NEW_DEVICE_AVAILABLE:
10.       // 应用根据业务情况响应设备可用事件。
11.       break;
12.     case audio.AudioStreamDeviceChangeReason.REASON_OVERRODE:
13.       // 应用根据业务情况响应设备强选事件。
14.       break;
15.     case audio.AudioStreamDeviceChangeReason.REASON_SESSION_ACTIVATED:
16.       // 应用根据业务情况响应audio session激活时的输出设备信息。
17.       break;
18.     case audio.AudioStreamDeviceChangeReason.REASON_STREAM_PRIORITY_CHANGED:
19.       // 应用根据业务情况响应其它更高优先级的音频流触发的设备变更事件。
20.       break;
21.     case audio.AudioStreamDeviceChangeReason.REASON_UNKNOWN:
22.       // 应用根据业务情况响应未知原因事件。
23.       break;
24.   }
25. };

26. audioSessionManager.on('currentOutputDeviceChanged', currentOutputDeviceChangedCallback);

27. audioSessionManager.off('currentOutputDeviceChanged', currentOutputDeviceChangedCallback);

28. // 取消该事件的所有监听。
29. audioSessionManager.off('currentOutputDeviceChanged');

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-input-device-management "查询和监听音频输入设备")
# 实现音频输入设备路由切换

更新时间: 2025-12-16 16:35

从API version 21开始，支持音频输入设备路由切换。

当应用进行音频输入时，系统会根据音频流类型选择对应的输入设备（SOURCE_TYPE_MIC：内置MIC录音；SOURCE_TYPE_VOICE_COMMUNICATION：跟随当前输出设备）。若默认输入设备不满足应用需求，应用可通过[setBluetoothAndNearlinkPreferredRecordCategory](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setbluetoothandnearlinkpreferredrecordcategory21)或[selectMediaInputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#selectmediainputdevice21)实现音频输入设备路由切换。

## 选择使用蓝牙或者星闪设备进行录音

应用可使用AudioSessionManager的[setBluetoothAndNearlinkPreferredRecordCategory](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setbluetoothandnearlinkpreferredrecordcategory21)设置应用程序的输入设备选择偏好，当蓝牙或星闪设备上线时生效。

说明

通话场景下，如果蓝牙或星闪设备在线，系统默认使用蓝牙或星闪设备作为输入设备。

1. import { audio } from '@kit.AudioKit';  // 导入audio模块。
2. import { BusinessError } from '@kit.BasicServicesKit';

3. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。

4. let audioSessionManager = audioManager.getSessionManager();  // 再调用AudioManager的方法创建AudioSessionManager实例。

5. audioSessionManager.setBluetoothAndNearlinkPreferredRecordCategory(audio.BluetoothAndNearlinkPreferredRecordCategory.PREFERRED_LOW_LATENCY).then(() => {
6.   console.info('Succeeded in setting bluetooth and nearlink preferred record category.');
7. }).catch((err: BusinessError) => {
8.   console.error(`Failed to set bluetooth and nearlink preferred record category. Code: ${err.code}, message: ${err.message}`);
9. });

## 选择任意设备进行录音

应用可使用AudioSessionManager的[selectMediaInputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#selectmediainputdevice21)选择输入设备。

说明

通话场景下，输入设备跟随当前输出设备，此时其他与通话并发的录音流也会跟随通话输入设备。

1. import { audio } from '@kit.AudioKit';  // 导入audio模块。
2. import { BusinessError } from '@kit.BasicServicesKit';

3. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。

4. let audioSessionManager = audioManager.getSessionManager();  // 再调用AudioManager的方法创建AudioSessionManager实例。

5. // 监听音频可选输入设备连接状态变化事件，当有输入设备上下线时会收到回调通知。
6. let availableDeviceChangeCallback = (deviceChanged: audio.DeviceChangeAction) => {
7.   // 回调返回更新后的可用输入设备列表，应用也可在此处执行选择输入设备操作。
8.   let data: audio.AudioDeviceDescriptors = deviceChanged.deviceDescriptors;
9.   console.info(`Succeeded in using on or off function, AudioDeviceDescriptors: ${data}.`);
10. };
11. audioSessionManager.on('availableDeviceChange', audio.DeviceUsage.MEDIA_INPUT_DEVICES, availableDeviceChangeCallback);

12. // 监听当前输入设备变化事件，当选择输入设备成功后会触发该回调。
13. let currentInputDeviceChangedCallback = (currentInputDeviceChangedEvent: audio.CurrentInputDeviceChangedEvent) => {
14.   console.info(`Succeeded in using on or off function, CurrentInputDeviceChangedEvent: ${currentInputDeviceChangedEvent}.`);
15. };
16. audioSessionManager.on('currentInputDeviceChanged', currentInputDeviceChangedCallback);

17. try {
18.   // 获取当前可选的音频输入设备列表。
19.   let data: audio.AudioDeviceDescriptors = audioSessionManager.getAvailableDevices(audio.DeviceUsage.MEDIA_INPUT_DEVICES);
20.   console.info(`Succeeded in getting available devices, AudioDeviceDescriptors: ${data}.`);

21.   // 当前可选音频输入设备列表不为空时，可进行选择。
22.   if (data[0]) {
23.     // 选择输入设备。
24.     await audioSessionManager.selectMediaInputDevice(data[0]).then(() => {
25.       console.info('Succeeded in selecting media input device.');
26.     }).catch((err: BusinessError) => {
27.       console.error(`Failed to select media input device. Code: ${err.code}, message: ${err.message}`);
28.     });
29.   }
30. } catch (err) {
31.   let error = err as BusinessError;
32.   console.error(`Failed to get available devices. Code: ${error.code}, message: ${error.message}`);
33. }

34. // 可通过该接口查询选择输入设备是否成功。
35. try {
36.   let device: audio.AudioDeviceDescriptor = audioSessionManager.getSelectedMediaInputDevice();
37.   console.info('Succeeded in getting select media input device.');
38. } catch (err) {
39.   let error = err as BusinessError;
40.   console.error(`Failed to get selected media input device. Code: ${error.code}, message: ${error.message}`);
41. }

42. // 取消监听音频可选输入设备连接状态变化事件。
43. audioSessionManager.off('availableDeviceChange', availableDeviceChangeCallback);

44. // 取消监听当前输入设备变化事件。
45. audioSessionManager.off('currentInputDeviceChanged', currentInputDeviceChangedCallback);

46. // 清空通过selectMediaInputDevice选择的输入设备。
47. audioSessionManager.clearSelectedMediaInputDevice().then(() => {
48.   console.info('Succeeded in clearing selected media input device.');
49. }).catch((err: BusinessError) => {
50.   console.error(`Failed to clear selected media input device. Code: ${err.code}, message: ${err.message}`);
51. });

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-output-device-management "查询和监听音频输出设备")
# 实现音频输出设备路由切换

更新时间: 2025-12-16 16:35

当应用进行音频输出时，系统会根据音频流类型选择对应的输出设备（STREAM_USAGE_MUSIC：扬声器发声；STREAM_USAGE_VOICE_COMMUNICATION：听筒发声）。如果系统提供的默认输出设备不满足应用需求，应用可通过AVCastPicker或setDefaultOutputDevice实现音频输出设备路由切换。

## 媒体类应用实现输出设备路由切换

应用可使用[AVCastPicker](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/ohos-multimedia-avcastpicker#avcastpicker)投播组件进行媒体类应用输出设备路由切换。

## 通话类应用实现输出设备路由切换

### 外接设备路由切换

应用可使用[AVCastPicker通话组件](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-switch-call-devices)进行通话类应用外接输出设备路由切换。

### 内置听筒和扬声器路由切换

如果未连接外设，语音通话场景系统默认听筒发声，其他场景系统默认扬声器发声；如果连接了外设，系统默认通过外接设备发声。

调用setDefaultOutputDevice设置音频输出设备后，如需取消，可将参数设为audio.DeviceType.DEFAULT，将音频输出设备选择权交还给系统。

1. 从API version 12开始，应用可使用AudioRenderer的[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiorenderer#setdefaultoutputdevice12)设置听筒和扬声器路由切换，调用前需要先获取[AudioRenderer](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-f#audiocreateaudiorenderer8)实例。
    
    说明
    
    - 由于AudioRenderer是流级别，调用本接口设置的默认音频输出设备仅对当前流生效。
    - 本接口优先级低于AudioSessionManager的[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setdefaultoutputdevice20)。如果使用AudioSessionManager的[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setdefaultoutputdevice20)设置了默认音频输出设备，本接口的设置将不会生效。
    
    1. import { audio } from '@kit.AudioKit';
    2. import { BusinessError } from '@kit.BasicServicesKit';
    
    3. // 设置默认输出设备为本机扬声器。
    4. audioRenderer.setDefaultOutputDevice(audio.DeviceType.SPEAKER).then(() => {
    5.   console.info('Succeeded in setting default output device.');
    6. }).catch((err: BusinessError) => {
    7.   console.error(`Failed to set default output device. Code: ${err.code}, message: ${err.message}`);
    8. });
    
    9. // 设置默认输出设备为系统默认输出设备，即取消应用设置的默认设备，交由系统选择设备。
    10. audioRenderer.setDefaultOutputDevice(audio.DeviceType.DEFAULT).then(() => {
    11.   console.info('Succeeded in setting default output device.');
    12. }).catch((err: BusinessError) => {
    13.   console.error(`Failed to set default output device. Code: ${err.code}, message: ${err.message}`);
    14. });
    
2. 从API version 20开始，应用可使用AudioSessionManager的[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiosessionmanager#setdefaultoutputdevice20)设置听筒和扬声器路由切换。
    
    说明
    
    由于AudioSessionManager是应用级设置，调用本接口设置默认音频输出设备，会对当前应用所有适用范围内的音频流生效，且会覆盖AudioRenderer的[setDefaultOutputDevice](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiorenderer#setdefaultoutputdevice12)接口设置的默认音频输出设备信息。
    
    1. import { audio } from '@kit.AudioKit';  // 导入audio模块。
    2. import { BusinessError } from '@kit.BasicServicesKit';
    
    3. let audioManager = audio.getAudioManager();  // 需要先创建AudioManager实例。
    
    4. let audioSessionManager = audioManager.getSessionManager();  // 再调用AudioManager的方法创建AudioSessionManager实例。
    
    5. // 设置默认输出设备为本机扬声器。
    6. audioSessionManager.setDefaultOutputDevice(audio.DeviceType.SPEAKER).then(() => {
    7.   console.info('Succeeded in setting default output device.');
    8. }).catch((err: BusinessError) => {
    9.   console.error(`Failed to set default output device. Code: ${err.code}, message: ${err.message}`);
    10. });
    
    11. // 设置默认输出设备为系统默认输出设备，即取消应用设置的默认设备，交由系统选择设备。
    12. audioSessionManager.setDefaultOutputDevice(audio.DeviceType.DEFAULT).then(() => {
    13.   console.info('Succeeded in setting default output device.');
    14. }).catch((err: BusinessError) => {
    15.   console.error(`Failed to set default output device. Code: ${err.code}, message: ${err.message}`);
    16. });
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-input-device-switcher "实现音频输入设备路由切换")
# 响应输出设备变更时合理暂停

更新时间: 2025-12-16 16:35

开发者可以了解音频流输出设备变更信息，并完成相应适配，比如：应用在播放音乐时发现输出设备下线，为避免打扰用户，应该立即暂停音乐。

开发者可使用AudioRenderer的[outputDeviceChangeWithInfo](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiorenderer#onoutputdevicechangewithinfo11)，用于监听音频流输出设备变化及原因。当系统出现音频输出设备的上下线、用户强选、设备抢占或设备选择策略变更等情况，导致音频流输出设备变更时，系统将通过该接口通知应用当前音频流设备变更信息，包含当前音频流输出设备信息和设备变更原因。

## 音频流输出设备信息

在[outputDeviceChangeWithInfo](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiorenderer#onoutputdevicechangewithinfo11)返回的音频流设备变更信息中，包含当前音频流输出设备信息，以数组形式发送，一般该列表仅包含一个设备信息，具体可参考[AudioDeviceDescriptors](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-t#audiodevicedescriptors)（设备信息列表）。

## 音频流输出设备变更原因

说明

当发生下述四种情况（[AudioStreamDeviceChangeReason](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audiostreamdevicechangereason11)）时，系统将向应用发送设备变更回调。

- **REASON_NEW_DEVICE_AVAILABLE**：新设备可用。
    
    **触发场景：**
    
    普通蓝牙设备（耳机、眼镜、音箱、车机等）连接、支持佩戴检测的蓝牙设备（耳机、眼镜等）佩戴、有线设备（3.5mm耳机、Type-C耳机、USB耳机、USB音箱等）插入、分布式设备上线等。
    
- **REASON_OLD_DEVICE_UNAVAILABLE**：旧设备不可用。
    
    当报告此原因时，应用程序应考虑暂停音频播放。
    
    **触发场景：**
    
    普通蓝牙设备（耳机、眼镜、音箱、车机等）断开、支持佩戴检测的蓝牙耳机双耳摘下、支持佩戴检测的蓝牙眼镜摘下、有线设备（3.5mm耳机、Type-C耳机、USB耳机、USB音箱等）拔出、分布式设备下线等。
    
    针对此场景，常用业务场景的**处理建议**如下：
    
    - 游戏场景：不暂停
    - 听书场景：暂停
    - 音乐场景：暂停
    - 视频场景：暂停
- **REASON_OVERRODE**：用户强制选择设备。
    
    **触发场景：**
    
    用户从界面选择切换音频流输出设备、从外设选择接听蜂窝或VoIP来电。
    
- **REASON_UNKNOWN**：未知原因。
    

## 参考示例

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';

3. let audioRenderer: audio.AudioRenderer | undefined = undefined;
4. let audioStreamInfo: audio.AudioStreamInfo = {
5.   samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率。
6.   channels: audio.AudioChannel.CHANNEL_2, // 通道。
7.   sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式。
8.   encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式。
9. };
10. let audioRendererInfo: audio.AudioRendererInfo = {
11.   usage: audio.StreamUsage.STREAM_USAGE_MUSIC, // 音频流使用类型：音乐。根据业务场景配置，参考StreamUsage。
12.   rendererFlags: 0 // 音频渲染器标志。
13. };
14. let audioRendererOptions: audio.AudioRendererOptions = {
15.   streamInfo: audioStreamInfo,
16.   rendererInfo: audioRendererInfo
17. };

18. // 创建AudioRenderer实例。
19. audio.createAudioRenderer(audioRendererOptions).then((data) => {
20.   audioRenderer = data;
21.   console.info('AudioFrameworkRenderLog: AudioRenderer Created : Success : Stream Type: SUCCESS');
22. }).catch((err: BusinessError) => {
23.   console.error(`AudioFrameworkRenderLog: AudioRenderer Created : ERROR : ${err}`);
24. });

25. if (audioRenderer) {
26.   // 订阅监听音频流输出设备变化及原因。
27.   (audioRenderer as audio.AudioRenderer).on('outputDeviceChangeWithInfo', async (deviceChangeInfo: audio.AudioStreamDeviceChangeInfo) => {
28.     switch (deviceChangeInfo.changeReason) {
29.       case audio.AudioStreamDeviceChangeReason.REASON_OLD_DEVICE_UNAVAILABLE:
30.         // 响应设备不可用事件，如果应用处于播放状态，应暂停播放，更新UX界面。
31.         // await audioRenderer.pause();
32.         break;
33.       case audio.AudioStreamDeviceChangeReason.REASON_NEW_DEVICE_AVAILABLE:
34.         // 应用根据业务情况响应设备可用事件。
35.         break;
36.       case audio.AudioStreamDeviceChangeReason.REASON_OVERRODE:
37.         // 应用根据业务情况响应设备强选事件。
38.         break;
39.       case audio.AudioStreamDeviceChangeReason.REASON_UNKNOWN:
40.         // 应用根据业务情况响应未知原因事件。
41.         break;
42.     }
43.   });
44. }

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-output-device-switcher "实现音频输出设备路由切换")
# 音频通话开发概述

更新时间: 2025-12-16 16:35

常用的音频通话模式包括VoIP通话和蜂窝通话。

- VoIP通话：
    
    VoIP（Voice over Internet Protocol）通话是指基于互联网协议（IP）进行通讯的一种语音通话技术。VoIP通话会将通话信息打包成数据包，通过网络进行传输，因此VoIP通话对网络要求较高，通话质量与网络连接速度紧密相关。
    
- 蜂窝通话（仅对系统应用开放）：
    
    蜂窝通话是指传统的电话功能，由运营商提供服务，目前仅对系统应用开放，未向第三方应用提供开发接口。
    

在开发音频通话相关功能时，开发者可以根据实际情况，检查当前的[音频场景模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call-overview#%E9%9F%B3%E9%A2%91%E5%9C%BA%E6%99%AF%E6%A8%A1%E5%BC%8F)和[铃声模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call-overview#%E9%93%83%E5%A3%B0%E6%A8%A1%E5%BC%8F)，以使用相应的音频处理策略。

## 音频场景模式

应用使用音频通话相关功能时，系统会切换至与通话相关的音频场景模式（[AudioScene](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioscene8)），当前预置了多种音频场景，包括响铃、通话、语音聊天等，在不同的场景下，系统会采用不同的策略来处理音频。

如在通话场景中会更注重人声的清晰度。系统会使用3A算法对音频数据进行预处理，抑制通话回声，消除背景噪音，调整音量范围，从而达到清晰人声的效果。3A算法，指声学回声消除（Acoustic Echo Cancellation, AEC）、背景噪声抑制（Active Noise Control, ANC）、自动增益控制（Automatic Gain Control, AGC）三种音频处理算法。

当前预置的音频场景：

- AUDIO_SCENE_DEFAULT：默认音频场景，音频通话之外的场景均可使用。
    
- AUDIO_SCENE_VOICE_CHAT：语音聊天音频场景，VoIP通话时使用。
    

应用可通过[AudioManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiomanager)的getAudioScene来获取当前的音频场景模式。当应用开始或结束使用音频通话相关功能时，可通过此方法检查系统是否已切换为合适的音频场景模式。

## 铃声模式

在用户进入到音频通话时，应用可以使用铃声或振动来提示用户。系统通过调整铃声模式（[AudioRingMode](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-e#audioringmode)），实现便捷地管理铃声音量，并调整设备的振动模式。

当前预置的三种铃声模式：

- RINGER_MODE_SILENT：静音模式，此模式下铃声音量为零（即静音）。
    
- RINGER_MODE_VIBRATE：振动模式，此模式下铃声音量为零，设备振动开启（即响铃时静音，触发振动）。
    
- RINGER_MODE_NORMAL：响铃模式，此模式下铃声音量正常。
    

应用可以调用[AudioVolumeGroupManager](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/arkts-apis-audio-audiovolumegroupmanager)中的getRingerMode获取当前的铃声模式，以便采取合适的提示策略。

如果应用希望及时获取铃声模式的变化情况，可以通过AudioVolumeGroupManager中的on('ringerModeChange')监听铃声模式变化事件，使应用在铃声模式发生变化时及时收到通知，方便应用做出相应的调整。

## 通话场景音频设备切换

在通话场景下，系统会根据默认优先级选择合适的音频设备。应用可以根据需要，切换音频设备。

切换方式可参考[AVSession Kit使用通话设备切换组件](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-switch-call-devices)。

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call "音频通话")
# 开发音频通话功能

更新时间: 2025-12-16 16:35

在音频通话场景下，音频输出（播放对端声音）和音频输入（录制本端声音）会同时进行，应用可以通过使用AudioRenderer来实现音频输出，通过使用AudioCapturer来实现音频输入，同时使用AudioRenderer和AudioCapturer即可实现音频通话功能。

在音频通话开始和结束时，应用可以自行检查当前的[音频场景模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call-overview#%E9%9F%B3%E9%A2%91%E5%9C%BA%E6%99%AF%E6%A8%A1%E5%BC%8F)和[铃声模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call-overview#%E9%93%83%E5%A3%B0%E6%A8%A1%E5%BC%8F)，以便采取合适的音频管理及提示策略。

以下代码示范了同时使用AudioRenderer和AudioCapturer实现音频通话功能的基本过程，其中未包含音频通话数据的传输过程，实际开发中，需要将网络传输来的对端通话数据解码播放，此处仅以读取音频文件的数据代替；同时需要将本端录制的通话数据编码打包，通过网络发送给对端，此处仅以将数据写入音频文件代替。

## 使用AudioRenderer播放对端的通话声音

该过程与[使用AudioRenderer开发音频播放功能](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-audiorenderer-for-playback)过程相似，关键区别在于audioRendererInfo参数和音频数据来源。audioRendererInfo参数中，音频流使用类型usage需设置为VoIP通话：STREAM_USAGE_VOICE_COMMUNICATION。

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';
3. import { fileIo as fs } from '@kit.CoreFileKit';
4. import { common } from '@kit.AbilityKit';

5. // 与使用AudioRenderer开发音频播放功能过程相似，关键区别在于audioRendererInfo参数和音频数据来源。
6. const TAG = 'VoIPDemoForAudioRenderer';

7. class Options {
8.   offset?: number;
9.   length?: number;
10. }

11. let bufferSize: number = 0;
12. let audioRenderer: audio.AudioRenderer | undefined = undefined;
13. let audioStreamInfo: audio.AudioStreamInfo = {
14.   samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率。
15.   channels: audio.AudioChannel.CHANNEL_2, // 通道。
16.   sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式。
17.   encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式。
18. };
19. let audioRendererInfo: audio.AudioRendererInfo = {
20.   // 需使用通话场景相应的参数。
21.   usage: audio.StreamUsage.STREAM_USAGE_VOICE_COMMUNICATION, // 音频流使用类型：VoIP通话。
22.   rendererFlags: 0 // 音频渲染器标志：默认为0即可。
23. };
24. let audioRendererOptions: audio.AudioRendererOptions = {
25.   streamInfo: audioStreamInfo,
26.   rendererInfo: audioRendererInfo
27. };
28. let file: fs.File;
29. let writeDataCallback: audio.AudioRendererWriteDataCallback;

30. async function initArguments(context: common.UIAbilityContext) {
31.   let path = context.cacheDir;
32.   // 此处仅作示例，实际使用时需要将文件替换为应用要播放的PCM文件。
33.   let filePath = path + '/StarWars10s-2C-48000-4SW.pcm';
34.   file = fs.openSync(filePath, fs.OpenMode.READ_ONLY);
35.   writeDataCallback = (buffer: ArrayBuffer) => {
36.     let options: Options = {
37.       offset: bufferSize,
38.       length: buffer.byteLength
39.     };

40.     try {
41.       let bufferLength = fs.readSync(file.fd, buffer, options);
42.       bufferSize += buffer.byteLength;
43.       // 如果当前回调传入的数据不足一帧，空白区域需要使用静音数据填充，否则会导致播放出现杂音。
44.       if (bufferLength < buffer.byteLength) {
45.         let view = new DataView(buffer);
46.         for (let i = bufferLength; i < buffer.byteLength; i++) {
47.           // 空白区域填充静音数据。当使用音频采样格式为SAMPLE_FORMAT_U8时0x7F为静音数据，使用其他采样格式时0为静音数据。
48.           view.setUint8(i, 0);
49.         }
50.       }
51.       // API version 11不支持返回回调结果，从API version 12开始支持返回回调结果。
52.       // 如果开发者不希望播放某段buffer，返回audio.AudioDataCallbackResult.INVALID即可。
53.       return audio.AudioDataCallbackResult.VALID;
54.     } catch (error) {
55.       console.error('Error reading file:', error);
56.       // API version 11不支持返回回调结果，从API version 12开始支持返回回调结果。
57.       return audio.AudioDataCallbackResult.INVALID;
58.     }
59.   };
60. }

61. // 初始化，创建实例，设置监听事件。
62. async function init() {
63.   audio.createAudioRenderer(audioRendererOptions, (err, renderer) => { // 创建AudioRenderer实例。
64.     if (!err) {
65.       console.info(`${TAG}: creating AudioRenderer success`);
66.       audioRenderer = renderer;
67.       if (audioRenderer !== undefined) {
68.         audioRenderer.on('writeData', writeDataCallback);
69.       }
70.     } else {
71.       console.info(`${TAG}: creating AudioRenderer failed, error: ${err.message}`);
72.     }
73.   });
74. }

75. // 开始一次音频渲染。
76. async function start() {
77.   if (audioRenderer !== undefined) {
78.     let stateGroup = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];
79.     if (stateGroup.indexOf(audioRenderer.state.valueOf()) === -1) { // 当且仅当状态为prepared、paused和stopped之一时才能启动渲染。
80.       console.error(TAG + 'start failed');
81.       return;
82.     }
83.     // 启动渲染。
84.     audioRenderer.start((err: BusinessError) => {
85.       if (err) {
86.         console.error('Renderer start failed.');
87.       } else {
88.         console.info('Renderer start success.');
89.       }
90.     });
91.   }
92. }

93. // 暂停渲染。
94. async function pause() {
95.   if (audioRenderer !== undefined) {
96.     // 只有渲染器状态为running的时候才能暂停。
97.     if (audioRenderer.state.valueOf() !== audio.AudioState.STATE_RUNNING) {
98.       console.info('Renderer is not running');
99.       return;
100.     }
101.     // 暂停渲染。
102.     audioRenderer.pause((err: BusinessError) => {
103.       if (err) {
104.         console.error('Renderer pause failed.');
105.       } else {
106.         console.info('Renderer pause success.');
107.       }
108.     });
109.   }
110. }

111. // 停止渲染。
112. async function stop() {
113.   if (audioRenderer !== undefined) {
114.     // 只有渲染器状态为running或paused的时候才可以停止。
115.     if (audioRenderer.state.valueOf() !== audio.AudioState.STATE_RUNNING && audioRenderer.state.valueOf() !== audio.AudioState.STATE_PAUSED) {
116.       console.info('Renderer is not running or paused.');
117.       return;
118.     }
119.     // 停止渲染。
120.     audioRenderer.stop((err: BusinessError) => {
121.       if (err) {
122.         console.error('Renderer stop failed.');
123.       } else {
124.         fs.close(file);
125.         console.info('Renderer stop success.');
126.       }
127.     });
128.   }
129. }

130. // 销毁实例，释放资源。
131. async function release() {
132.   if (audioRenderer !== undefined) {
133.     // 渲染器状态不是released状态，才能release。
134.     if (audioRenderer.state.valueOf() === audio.AudioState.STATE_RELEASED) {
135.       console.info('Renderer already released');
136.       return;
137.     }
138.     // 释放资源。
139.     audioRenderer.release((err: BusinessError) => {
140.       if (err) {
141.         console.error('Renderer release failed.');
142.       } else {
143.         console.info('Renderer release success.');
144.       }
145.     });
146.   }
147. }

148. @Entry
149. @Component
150. struct Index {
151.   build() {
152.     Scroll() {
153.       Column() {
154.         Row() {
155.           Column() {
156.             Text('初始化').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
157.           }
158.           .backgroundColor(Color.White)
159.           .borderRadius(30)
160.           .width('45%')
161.           .height('25%')
162.           .margin({ right: 12, bottom: 12 })
163.           .onClick(async () => {
164.             let context = this.getUIContext().getHostContext() as common.UIAbilityContext;
165.             initArguments(context);
166.             init();
167.           });

168.           Column() {
169.             Text('开始播放').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
170.           }
171.           .backgroundColor(Color.White)
172.           .borderRadius(30)
173.           .width('45%')
174.           .height('25%')
175.           .margin({ bottom: 12 })
176.           .onClick(async () => {
177.             start();
178.           });
179.         }

180.         Row() {
181.           Column() {
182.             Text('暂停播放').fontSize(16).margin({ top: 12 });
183.           }
184.           .id('audio_effect_manager_card')
185.           .backgroundColor(Color.White)
186.           .borderRadius(30)
187.           .width('45%')
188.           .height('25%')
189.           .margin({ right: 12, bottom: 12 })
190.           .onClick(async () => {
191.             pause();
192.           });

193.           Column() {
194.             Text('停止播放').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
195.           }
196.           .backgroundColor(Color.White)
197.           .borderRadius(30)
198.           .width('45%')
199.           .height('25%')
200.           .margin({ bottom: 12 })
201.           .onClick(async () => {
202.             stop();
203.           });
204.         }

205.         Row() {
206.           Column() {
207.             Text('释放资源').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
208.           }
209.           .id('audio_volume_card')
210.           .backgroundColor(Color.White)
211.           .borderRadius(30)
212.           .width('45%')
213.           .height('25%')
214.           .margin({ right: 12, bottom: 12 })
215.           .onClick(async () => {
216.             release();
217.           });
218.         }
219.         .padding(12)
220.       }
221.       .height('100%')
222.       .width('100%')
223.       .backgroundColor('#F1F3F5');
224.     }
225.   }
226. }

## 使用AudioCapturer录制本端的通话声音

该过程与[使用AudioCapturer开发音频录制功能](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/using-audiocapturer-for-recording)过程相似，关键区别在于audioCapturerInfo参数和音频数据流向。audioCapturerInfo参数中音源类型source需设置为语音通话：SOURCE_TYPE_VOICE_COMMUNICATION。

所有录制均需要申请麦克风权限：ohos.permission.MICROPHONE，申请方式请参考[向用户申请授权](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/request-user-authorization)。

1. import { audio } from '@kit.AudioKit';
2. import { BusinessError } from '@kit.BasicServicesKit';
3. import { fileIo as fs } from '@kit.CoreFileKit';
4. import { common } from '@kit.AbilityKit';

5. // 与使用AudioCapturer开发音频录制功能过程相似，关键区别在于audioCapturerInfo参数和音频数据流向。
6. const TAG = 'VoIPDemoForAudioCapturer';

7. class Options {
8.   offset?: number;
9.   length?: number;
10. }

11. let bufferSize: number = 0;
12. let audioCapturer: audio.AudioCapturer | undefined = undefined;
13. let audioStreamInfo: audio.AudioStreamInfo = {
14.   samplingRate: audio.AudioSamplingRate.SAMPLE_RATE_48000, // 采样率。
15.   channels: audio.AudioChannel.CHANNEL_2, // 通道。
16.   sampleFormat: audio.AudioSampleFormat.SAMPLE_FORMAT_S16LE, // 采样格式。
17.   encodingType: audio.AudioEncodingType.ENCODING_TYPE_RAW // 编码格式。
18. };
19. let audioCapturerInfo: audio.AudioCapturerInfo = {
20.   // 需使用通话场景相应的参数。
21.   source: audio.SourceType.SOURCE_TYPE_VOICE_COMMUNICATION, // 音源类型：语音通话。
22.   capturerFlags: 0 // 音频采集器标志：默认为0即可。
23. };
24. let audioCapturerOptions: audio.AudioCapturerOptions = {
25.   streamInfo: audioStreamInfo,
26.   capturerInfo: audioCapturerInfo
27. };
28. let file: fs.File;
29. let readDataCallback: Callback<ArrayBuffer>;

30. async function initArguments(context: common.UIAbilityContext) {
31.   let path = context.cacheDir;
32.   let filePath = path + '/StarWars10s-2C-48000-4SW.pcm';
33.   file = fs.openSync(filePath, fs.OpenMode.READ_WRITE | fs.OpenMode.CREATE);
34.   readDataCallback = (buffer: ArrayBuffer) => {
35.     let options: Options = {
36.       offset: bufferSize,
37.       length: buffer.byteLength
38.     }
39.     fs.writeSync(file.fd, buffer, options);
40.     bufferSize += buffer.byteLength;
41.   };
42. }

43. // 初始化，创建实例，设置监听事件。
44. async function init() {
45.   audio.createAudioCapturer(audioCapturerOptions, (err, capturer) => { // 创建AudioCapturer实例。
46.     if (err) {
47.       console.error(`Invoke createAudioCapturer failed, code is ${err.code}, message is ${err.message}`);
48.       return;
49.     }
50.     console.info(`${TAG}: create AudioCapturer success`);
51.     audioCapturer = capturer;
52.     if (audioCapturer !== undefined) {
53.       audioCapturer.on('readData', readDataCallback);
54.     }
55.   });
56. }

57. // 开始一次音频采集。
58. async function start() {
59.   if (audioCapturer !== undefined) {
60.     let stateGroup = [audio.AudioState.STATE_PREPARED, audio.AudioState.STATE_PAUSED, audio.AudioState.STATE_STOPPED];
61.     if (stateGroup.indexOf(audioCapturer.state.valueOf()) === -1) { // 当且仅当状态为STATE_PREPARED、STATE_PAUSED和STATE_STOPPED之一时才能启动采集。
62.       console.error(`${TAG}: start failed`);
63.       return;
64.     }

65.     // 启动采集。
66.     audioCapturer.start((err: BusinessError) => {
67.       if (err) {
68.         console.error('Capturer start failed.');
69.       } else {
70.         console.info('Capturer start success.');
71.       }
72.     });
73.   }
74. }

75. // 停止采集。
76. async function stop() {
77.   if (audioCapturer !== undefined) {
78.     // 只有采集器状态为STATE_RUNNING或STATE_PAUSED的时候才可以停止。
79.     if (audioCapturer.state.valueOf() !== audio.AudioState.STATE_RUNNING && audioCapturer.state.valueOf() !== audio.AudioState.STATE_PAUSED) {
80.       console.info('Capturer is not running or paused');
81.       return;
82.     }

83.     // 停止采集。
84.     audioCapturer.stop((err: BusinessError) => {
85.       if (err) {
86.         console.error('Capturer stop failed.');
87.       } else {
88.         fs.close(file);
89.         console.info('Capturer stop success.');
90.       }
91.     });
92.   }
93. }

94. // 销毁实例，释放资源。
95. async function release() {
96.   if (audioCapturer !== undefined) {
97.     // 采集器状态不是STATE_RELEASED或STATE_NEW状态，才能release。
98.     if (audioCapturer.state.valueOf() === audio.AudioState.STATE_RELEASED || audioCapturer.state.valueOf() === audio.AudioState.STATE_NEW) {
99.       console.info('Capturer already released');
100.       return;
101.     }

102.     // 释放资源。
103.     audioCapturer.release((err: BusinessError) => {
104.       if (err) {
105.         console.error('Capturer release failed.');
106.       } else {
107.         console.info('Capturer release success.');
108.       }
109.     });
110.   }
111. }

112. @Entry
113. @Component
114. struct Index {
115.   build() {
116.     Scroll() {
117.       Column() {
118.         Row() {
119.           Column() {
120.             Text('初始化').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
121.           }
122.           .backgroundColor(Color.White)
123.           .borderRadius(30)
124.           .width('45%')
125.           .height('25%')
126.           .margin({ right: 12, bottom: 12 })
127.           .onClick(async () => {
128.             let context = this.getUIContext().getHostContext() as common.UIAbilityContext;
129.             initArguments(context);
130.             init();
131.           });

132.           Column() {
133.             Text('开始录制').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
134.           }
135.           .backgroundColor(Color.White)
136.           .borderRadius(30)
137.           .width('45%')
138.           .height('25%')
139.           .margin({ bottom: 12 })
140.           .onClick(async () => {
141.             start();
142.           });
143.         }

144.         Row() {
145.           Column() {
146.             Text('停止录制').fontSize(16).margin({ top: 12 });
147.           }
148.           .id('audio_effect_manager_card')
149.           .backgroundColor(Color.White)
150.           .borderRadius(30)
151.           .width('45%')
152.           .height('25%')
153.           .margin({ right: 12, bottom: 12 })
154.           .onClick(async () => {
155.             stop();
156.           });

157.           Column() {
158.             Text('释放资源').fontColor(Color.Black).fontSize(16).margin({ top: 12 });
159.           }
160.           .backgroundColor(Color.White)
161.           .borderRadius(30)
162.           .width('45%')
163.           .height('25%')
164.           .margin({ bottom: 12 })
165.           .onClick(async () => {
166.             release();
167.           });
168.         }
169.         .padding(12)
170.       }
171.       .height('100%')
172.       .width('100%')
173.       .backgroundColor('#F1F3F5');
174.     }
175.   }
176. }

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-call-overview "音频通话开发概述")
# AVCodec Kit简介

更新时间: 2025-12-16 16:35

AVCodec Kit（Audio & Video Codec Kit，音视频编解码，封装解析）是媒体系统中的音视频的编解码、媒体文件的解析、封装、媒体数据输入等原子能力。

基于性能考虑，AVCodec Kit仅提供C接口。

## 能力范围

- 媒体数据输入：媒体应用可以传入文件fd、或者流媒体url，进行后续的媒体信息解析等处理。
- 媒体基础能力（Media Foundation）：提供媒体数据处理的公共基础类型，包括[AVBuffer](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avbuffer-h)、[AVFormat](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avformat-h)等。
- 音频编码：音频类应用（比如音频通话、音频录制等）可以将未压缩的音频数据送到音频编码器进行编码，应用可以设置编码要用到的编码格式、码率、采样率等参数，控制编码的输出，达到压缩音频文件的目的。
- 视频编码：视频类应用（比如视频通话、视频录制等）可以将未压缩的视频数据送到视频编码器进行编码，应用可以设置编码要用到的编码格式、码率、帧率等参数，控制编码的输出，达到压缩视频文件的目的。
- 音频解码：音频类应用（比如音频通话、音频播放器等）将音频码流通过音频解码器解码，解码后的数据可以送到音频设备播放。
- 视频解码：视频类应用（比如视频通话、视频播放器等）将视频码流通过视频解码器解码，解码后的图像数据可以送到视频显示设备显示。
- 媒体文件解析：在媒体应用（音视频播放器等），将本地或者网络接收到的媒体文件解析，获得音视频的码流、音视频的呈现时间、编码格式、文件的一些基本属性信息等。
- 媒体文件封装：在媒体应用（音视频录制等），将音视频编码器编码后的码流数据封装成媒体文件（mp4、m4a），将音视频的码流、音视频的呈现时间、编码格式、文件的一些基本属性信息等按照文件格式写入应用指定的文件中。

## 亮点/特征

- 系统内部数据零拷贝：在视频解码过程，AVCodec通过回调函数提供AVBuffer给应用，由应用将要解码的sample数据写入AVBuffer，在AVCodec中数据不再需要从内存拷入硬件解码器，而是直接送入解码器解码，实现系统内数据零拷贝。
- 视频编码、解码支持硬件加速：支持H.264、H.265、H.265 10bit的硬件编解码。

## 基础概念

- 媒体文件：携带有音视频、字幕等媒体数据的文件，如.mp4、.m4a。
    
- 流媒体：可以边下载，边播放的媒体传输形式，下载协议如HTTP/HTTPS、HLS协议。
    
- 音视频编码：将未压缩原序列音视频数据转换为另一种格式数据，如H.264、AAC。
    
- 音视频解码：将一种数据格式转换为未压缩状态的原序列音视频数据，如YUV、PCM。
    
- 媒体文件封装：将音频、视频、字幕等数据以及描述信息，按照某种格式要求，写入到同一个文件中，如.mp4。
    
- 媒体文件解封装：将文件中的音频、视频、字幕等媒体数据读出，解析出媒体的描述信息。
    
- sample：有相同时间属性的一组数据。
    
    对于音视频，通常是有相同解码时间戳的压缩数据。
    
    对于字幕，通常包含对应时间点的字幕内容。
    
    所有的轨道结尾数据都为空。
    

## 使用方式

- 视频编解码
    
    视频编码的输入和视频解码的输出支持Surface模式。
    
    在编码和解码过程中，通过回调函数通知应用数据处理的情况；如编码过程通过回调通知应用，完成一帧编码，输出编码结果AVBuffer；在解码过程通过回调通知应用输入一帧码流到解码器解码，当解码完成也会通过回调通知应用解码完成，应用可以对数据做后续处理。
    
    视频编解码的逻辑如图所示。
    
    ![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163515.00033946527483829081071970918394:50001231000000:2800:30EA25F264E549C3622479E2B6E23DED0AE6E19474B475D36BA33A499A919930.png)
    
    具体开发指导请参考[视频解码Surface模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/video-decoding#surface%E6%A8%A1%E5%BC%8F)、[视频编码Surface模式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/video-encoding#surface%E6%A8%A1%E5%BC%8F)。
    
- 音频编解码
    
    音频编码的输入和音频解码的输出为PCM格式。
    
    在编码和解码过程中，通过回调函数通知应用数据处理的情况；如编码过程通过回调通知应用，完成一帧编码，输出编码结果AVBuffer；在解码过程通过回调通知应用输入一帧码流到解码器解码，当解码完成也会通过回调通知应用解码完成，应用可以对数据做后续处理。
    
    音频编解码逻辑如图所示。
    
    ![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163515.36023794342767207673596064675225:50001231000000:2800:057BFEE92385E9BFD8337E78B082F9E667CE328F28522BC2ED71C7162F5E1460.png)
    
    具体开发指导请参考[音频解码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-decoding)、[音频编码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-encoding)。
    
- 文件解析封装
    
    在文件封装环节，应用将AVBuffer送入Codec对应的接口，执行数据封装，AVBuffer可以是由上述编码输出的AVBuffer，也可以是应用创建的AVBuffer，AVBuffer中要携带有效的码流数据和相关的时间描述等信息；
    
    在文件解析环节，应用从Codec对应的接口获得携带有码流数据的AVBuffer，该AVBuffer可以送入上述视频和音频编解码对应接口。
    
    文件封装解封装逻辑如图所示。
    
    ![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163515.19281817177136435447313782885383:50001231000000:2800:D9615EEB31ABBB7DCE2B67EC577C0A5C5A805ED6CF688FC32E76A46A1E398655.png)
    
    具体开发指导请参考[媒体数据解析](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-demuxer)、[媒体数据封装](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-muxer)。
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/avcodec-kit "AVCodec Kit（音视频编解码服务）")
# AVCodec支持的格式

更新时间: 2025-12-16 16:35

音视频的编解码能力以及文件格式封装和解封装能力的支持情况，在不同平台存在能力和规格的差异。开发者可以通过[获取支持的编解码能力](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs)来获取实际的支持情况和规格情况。

## 媒体编解码

### 视频解码

当前支持的解码能力如下：

|视频解码类型|视频解码格式的MIME类型|
|:--|:--|
|MPEG2|[OH_AVCODEC_MIMETYPE_VIDEO_MPEG2](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|MPEG4|[OH_AVCODEC_MIMETYPE_VIDEO_MPEG4](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|H.263|[OH_AVCODEC_MIMETYPE_VIDEO_H263](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|AVC(H.264)|[OH_AVCODEC_MIMETYPE_VIDEO_AVC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|HEVC(H.265)|[OH_AVCODEC_MIMETYPE_VIDEO_HEVC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|VVC(H.266)|[OH_AVCODEC_MIMETYPE_VIDEO_VVC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|

通过MIME类型创建解码器时，如果系统平台支持硬件解码，系统平台会优先创建硬件解码器实例；如果系统平台不支持或者硬件解码器资源不足时，系统平台会创建软件解码器实例；如果系统平台无对应解码能力，会创建解码器实例失败。

系统平台提供的解码能力和设备强相关，开发者可以通过[获取支持的编解码能力](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs)获取系统平台支持的软硬件解码能力和能力规格。

例如可以通过OH_AVCODEC_MIMETYPE_VIDEO_AVC、OH_AVCODEC_MIMETYPE_VIDEO_HEVC、OH_AVCODEC_MIMETYPE_VIDEO_VVC来查询系统平台支持的H.264、H.265、H.266的硬件解码能力。

具体开发指导请参考[视频解码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/video-decoding)。

### 视频编码

当前支持的编码能力如下：

|视频编码类型|视频编码格式的MIME类型|
|:--|:--|
|HEVC(H.265)|[OH_AVCODEC_MIMETYPE_VIDEO_HEVC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|AVC(H.264)|[OH_AVCODEC_MIMETYPE_VIDEO_AVC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|

如果系统平台无对应编码能力，会创建编码器实例失败。

基于MimeType创建编码器时，可以配置为H.264(OH_AVCODEC_MIMETYPE_VIDEO_AVC)和H.265(OH_AVCODEC_MIMETYPE_VIDEO_HEVC)。

系统平台支持情况和每种编码的能力范围，可以通过[获取支持的编解码能力](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs)获取。

具体开发指导请参考[视频编码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/video-encoding)。

### 音频解码

当前支持的解码能力：

|音频解码类型|音频解码格式的MIME类型|
|:--|:--|
|AAC|[OH_AVCODEC_MIMETYPE_AUDIO_AAC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|MPEG(MP3)|[OH_AVCODEC_MIMETYPE_AUDIO_MPEG](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|Flac|[OH_AVCODEC_MIMETYPE_AUDIO_FLAC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|Vorbis|[OH_AVCODEC_MIMETYPE_AUDIO_VORBIS](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|AMR(amrnb、amrwb)|[OH_AVCODEC_MIMETYPE_AUDIO_AMR_NB](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)、[OH_AVCODEC_MIMETYPE_AUDIO_AMR_WB](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|G711mu|[OH_AVCODEC_MIMETYPE_AUDIO_G711MU](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|APE|[OH_AVCODEC_MIMETYPE_AUDIO_APE](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|G711a20+|[OH_AVCODEC_MIMETYPE_AUDIO_G711A](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|Audio ViVid11+|[OH_AVCODEC_MIMETYPE_AUDIO_VIVID](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|opus|[OH_AVCODEC_MIMETYPE_AUDIO_OPUS](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|

如果系统平台无对应解码能力，会创建解码器实例失败。

系统平台提供的解码能力和设备强相关，开发者可以通过[获取支持的编解码能力](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs)获取系统平台支持的解码能力和能力规格。

具体开发指导请参考[音频解码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-decoding)。

### 音频编码

当前支持的编码能力：

|音频编码类型|音频编码格式的MIME类型|
|:--|:--|
|AAC|[OH_AVCODEC_MIMETYPE_AUDIO_AAC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|Flac|[OH_AVCODEC_MIMETYPE_AUDIO_FLAC](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|MPEG(MP3)|[OH_AVCODEC_MIMETYPE_AUDIO_MPEG](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|G711mu|[OH_AVCODEC_MIMETYPE_AUDIO_G711MU](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|AMR(amrnb、amrwb)|[OH_AVCODEC_MIMETYPE_AUDIO_AMR_NB](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)、[OH_AVCODEC_MIMETYPE_AUDIO_AMR_WB](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|
|opus|[OH_AVCODEC_MIMETYPE_AUDIO_OPUS](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#%E5%8F%98%E9%87%8F)|

如果系统平台无对应编码能力，会创建编码器实例失败。

系统平台提供的编码能力和设备强相关，开发者可以通过[获取支持的编解码能力](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs)获取系统平台支持的编码能力和能力规格。

具体开发指导请参考[音频编码](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-encoding)。

## 媒体数据封装与解析

### 媒体数据解析

支持的解封装格式如下：

|媒体格式|封装格式|轨道格式|
|:--|:--|:--|
|音视频|mp4|视频轨：AVC(H.264)、HEVC(H.265)、VVC(H.266)、MPEG4<br><br>音频轨：AAC、MPEG(MP3)、Audio Vivid<br><br>字幕轨：WEBVTT<br><br>辅助轨：PREY(H.265)、DEPTH(H.265)、AUXL(AAC、MP3)<br><br>timed metadata轨|
|音视频|fmp4|视频轨：AVC(H.264)、HEVC(H.265)<br><br>音频轨：AAC、MPEG(MP3)、Audio Vivid|
|音视频|mkv|视频轨：AVC(H.264)、HEVC(H.265)<br><br>音频轨：AAC、MPEG(MP3)、OPUS|
|音视频|mpeg-ts|视频轨：AVC(H.264)、HEVC(H.265)、MPEG2、MPEG4<br><br>音频轨：AAC、MPEG(MP3)、Audio Vivid|
|音视频|flv|视频轨：AVC(H.264)、HEVC(H.265)<br><br>音频轨：AAC|
|音视频|mpeg-ps|视频轨：AVC(H.264)、MPEG2<br><br>音频轨：MPEG(MP2、MP3)|
|音视频|avi|视频轨：H.263、AVC(H.264)、MPEG2、MPEG4<br><br>音频轨：AAC、MPEG(MP2、MP3)、PCM|
|音频|m4a|音频轨：AAC、Audio Vivid|
|音频|aac|音频轨：AAC|
|音频|mp3|音频轨：MPEG(MP3)|
|音频|ogg|音频轨：Vorbis|
|音频|flac|音频轨：Flac|
|音频|wav|音频轨：PCM、G711mu、G711a|
|音频|amr|音频轨：AMR(amrnb、amrwb)|
|音频|ape|音频轨：APE|
|外挂字幕|srt|字幕轨：SRT|
|外挂字幕|webvtt|字幕轨：WEBVTT|

DRM解密能力支持的解封装格式：mp4(H.264，H.265，AAC)、mpeg-ts(H.264，H.265，AAC)。

具体开发指导请参考[媒体数据解析](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-demuxer)。

### 媒体数据封装

当前支持的封装能力如下：

|封装格式|视频编解码类型|音频编解码类型|封面类型|
|:--|:--|:--|:--|
|mp4|AVC（H.264）、HEVC（H.265）|AAC、MPEG（MP3）|jpeg、png、bmp|
|m4a|-|AAC|jpeg、png、bmp|
|mp3|-|MPEG（MP3）|-|
|amr|-|AMR(amrnb、amrwb)|-|
|wav|-|G711mu(pcm-mulaw) 、raw(pcm)|-|
|aac|-|AAC|-|
|flac|-|Flac|jpeg、png、bmp|

说明

- 封装格式为mp4，音频编解码类型为MPEG（MP3）时采样率需大于等于16000Hz。
- 封装格式为mp4/m4a，音频编解码类型为AAC时声道数范围为1~7。

文件级数据已定义的key如下所示：

|key|描述|
|:--|:--|
|OH_MD_KEY_CREATION_TIME|媒体文件创建时间的元数据，值类型为string（API14开始支持）。|
|OH_MD_KEY_COMMENT|媒体文件注释的键，值类型为string（API20开始支持）。|
|OH_MD_KEY_ENABLE_MOOV_FRONT|媒体文件moov元数据是否前置标志，值类型为int32_t（API20开始支持）。|

说明

用户自定义的key必须以"com.openharmony."为开头。值类型可以为int32_t、float、string，从API20开始增加支持uint8_t*。

配置选项key值说明：

mp4封装格式：

|key|描述|aac|mp3|H.264|H.265|jpg|png|bmp|
|:--|:--|:--|:--|:--|:--|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|必须|-|-|-|-|-|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|必须|-|-|-|-|-|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|可选|-|-|-|-|-|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|可选|-|-|-|-|-|
|OH_MD_KEY_PROFILE|编码档次|可选|-|-|-|-|-|-|
|OH_MD_KEY_BITRATE|码率|可选|可选|可选|可选|-|-|-|
|OH_MD_KEY_CODEC_CONFIG|编解码器特定数据|可选|-|可选|可选|-|-|-|
|OH_MD_KEY_WIDTH|宽度|-|-|必须|必须|必须|必须|必须|
|OH_MD_KEY_HEIGHT|高度|-|-|必须|必须|必须|必须|必须|
|OH_MD_KEY_FRAME_RATE|视频流帧率|-|-|可选|可选|-|-|-|
|OH_MD_KEY_COLOR_PRIMARIES|视频色域|-|-|可选|可选|-|-|-|
|OH_MD_KEY_TRANSFER_CHARACTERISTICS|视频传递函数|-|-|可选|可选|-|-|-|
|OH_MD_KEY_MATRIX_COEFFICIENTS|视频矩阵系数|-|-|可选|可选|-|-|-|
|OH_MD_KEY_RANGE_FLAG|值域标志|-|-|可选|可选|-|-|-|
|OH_MD_KEY_VIDEO_IS_HDR_VIVID|视频轨是否为HDR VIVID|-|-|-|可选|-|-|-|

mp4封装辅助轨格式：

|key|描述|aac|mp3|H.264|H.265|
|:--|:--|:--|:--|:--|:--|
|OH_MD_KEY_TRACK_TYPE|轨道媒体类型|必须|必须|必须|必须|
|OH_MD_KEY_TRACK_REFERENCE_TYPE|轨道引用类型|必须|必须|必须|必须|
|OH_MD_KEY_TRACK_DESCRIPTION|轨道标识|必须|必须|必须|必须|
|OH_MD_KEY_REFERENCE_TRACK_IDS|引用轨道编号|必须|必须|必须|必须|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|必须|-|-|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|必须|-|-|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|可选|-|-|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|可选|-|-|
|OH_MD_KEY_PROFILE|编码档次|可选|-|-|-|
|OH_MD_KEY_BITRATE|码率|可选|可选|可选|可选|
|OH_MD_KEY_CODEC_CONFIG|编解码器特定数据|可选|-|可选|可选|
|OH_MD_KEY_WIDTH|宽度|-|-|必须|必须|
|OH_MD_KEY_HEIGHT|高度|-|-|必须|必须|
|OH_MD_KEY_FRAME_RATE|视频流帧率|-|-|可选|可选|
|OH_MD_KEY_COLOR_PRIMARIES|视频色域|-|-|可选|可选|
|OH_MD_KEY_TRANSFER_CHARACTERISTICS|视频传递函数|-|-|可选|可选|
|OH_MD_KEY_MATRIX_COEFFICIENTS|视频矩阵系数|-|-|可选|可选|
|OH_MD_KEY_RANGE_FLAG|值域标志|-|-|可选|可选|
|OH_MD_KEY_VIDEO_IS_HDR_VIVID|视频轨是否为HDR VIVID|-|-|-|可选|

m4a封装格式：

|key|描述|aac|jpg|png|bmp|
|:--|:--|:--|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|-|-|-|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|-|-|-|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|-|-|-|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|-|-|-|
|OH_MD_KEY_PROFILE|编码档次|可选|-|-|-|
|OH_MD_KEY_BITRATE|码率|可选|-|-|-|
|OH_MD_KEY_CODEC_CONFIG|编解码器特定数据|可选|-|-|-|
|OH_MD_KEY_WIDTH|宽度|-|必须|必须|必须|
|OH_MD_KEY_HEIGHT|高度|-|必须|必须|必须|

amr封装格式：

|key|描述|amr_nb|amr_wb|
|:--|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|必须|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|必须|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|可选|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|可选|
|OH_MD_KEY_BITRATE|码率|可选|可选|

mp3封装格式：

|key|描述|mp3|jpg|
|:--|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|-|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|-|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|-|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|-|
|OH_MD_KEY_BITRATE|码率|可选|-|
|OH_MD_KEY_WIDTH|宽度|-|必须|
|OH_MD_KEY_HEIGHT|高度|-|必须|

wav封装格式：

|key|描述|g711mu|raw|
|:--|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|必须|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|必须|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|必须|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|可选|
|OH_MD_KEY_BITRATE|码率|必须|可选|

aac封装格式：

|key|描述|aac|
|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|可选|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|
|OH_MD_KEY_BITRATE|码率|可选|
|OH_MD_KEY_PROFILE|编码档次|必须|
|OH_MD_KEY_AAC_IS_ADTS|是否为ADTS格式|必须|

flac封装格式：

|key|描述|flac|
|:--|:--|:--|
|OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|
|OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|
|OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|必须|
|OH_MD_KEY_CHANNEL_LAYOUT|通道布局|可选|
|OH_MD_KEY_BITRATE|码率|可选|
|OH_MD_KEY_CODEC_CONFIG|编解码器特定数据|可选|

具体开发指导请参考[媒体数据封装](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-muxer)。

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/avcodec-kit-intro "AVCodec Kit简介")
# 获取支持的编解码能力

更新时间: 2025-12-16 16:35

因来源、编解码协议及设备能力的不同，导致不同设备上可用的编解码器及其能力存在差异。

为确保编解码行为符合预期，请通过音视频编解码能力接口查询系统支持的编解码器及其能力，选择符合开发需求的编解码器，并正确配置参数。

## 通用开发指导

1. 在CMake脚本中链接动态库。
    
    1. target_link_libraries(sample PUBLIC libnative_media_codecbase.so)
    2. target_link_libraries(sample PUBLIC libnative_media_core.so)
    3. target_link_libraries(sample PUBLIC libnative_media_venc.so)
    4. target_link_libraries(sample PUBLIC libnative_media_vdec.so)
    5. target_link_libraries(sample PUBLIC libnative_media_acodec.so)
    
    说明
    
    上述'sample'字样仅为示例，此处由开发者根据实际工程目录自定义。
    
2. 添加头文件。
    
    1. #include <algorithm>
    2. #include <multimedia/player_framework/native_avcapability.h>
    3. #include <multimedia/player_framework/native_avcodec_audiocodec.h>
    4. #include <multimedia/player_framework/native_avcodec_videoencoder.h>
    5. #include <multimedia/player_framework/native_avcodec_videodecoder.h>
    
3. 获得音视频编解码能力实例。
    
    支持两种方式获取音视频编解码能力实例。
    
    方式一：通过OH_AVCodec_GetCapability获取系统推荐的音视频编解码器能力实例。推荐策略与OH_XXX_CreateByMime系列接口一致。
    
    1. // 获取系统推荐的音频AAC解码器能力实例。
    2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_AUDIO_AAC, false);
    
    方式二：通过OH_AVCodec_GetCapabilityByCategory获取指定软硬件的编解码能力实例。
    
    1. // 获取指定硬件的视频AVC编码器能力实例。
    2. OH_AVCapability *capability = OH_AVCodec_GetCapabilityByCategory(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true, HARDWARE);
    
    若获取能力实例成功，继续向下执行。实例无显性释放接口，使用完毕后系统会自动回收。
    
4. 按需调用相应的查询接口。详细的API说明请参考[API文档](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcapability-h)。
    

## 场景化开发

基于开发过程中可能遇到的具体场景，此处将举例说明能力查询接口的使用方法。

### 创建指定名称的编解码器

如果系统存在多个相同MIME类型的编解码器，使用OH_XXX_CreateByMime系列接口创建系统推荐的编解码器。如需创建其他编解码器，先获取名称，再通过OH_XXX_CreateByName系列接口创建指定名称的编解码器。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetName|获取能力实例对应编解码器的名称。|

当H.264软件解码器和H.264硬件解码器同时存在时，创建H.264软件解码器的示例代码如下。

1. // 1. 获取H.264软件解码器能力实例。
2. OH_AVCapability *capability = OH_AVCodec_GetCapabilityByCategory(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false, SOFTWARE);
3. if (capability != nullptr) {
4.    // 2. 获取H.264软件解码器名称。
5.    const char *codecName = OH_AVCapability_GetName(capability);
6.    // 3. 创建H.264软件解码器实例。
7.    OH_AVCodec *videoDec = OH_VideoDecoder_CreateByName(codecName);
8. }

### 针对软硬件类别差异化配置编解码器参数

以下是软件编解码器和硬件编解码器的定义。

- **软件编解码器：** 指在CPU上工作的编解码器，具有迭代灵活、兼容性好和扩展能力强等特点。
    
- **硬件编解码器：** 指在专有硬件上工作的编解码器，具有低功耗、高性能和减少CPU负载等特点。
    

在硬件编解码器充足且满足能力要求时，优先使用硬件编解码器；否则使用软件编解码器。开发者可根据编解码器类别配置不同的编解码参数。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_IsHardware|确认能力实例对应的编解码器是否为硬件编解码器。|

视频编码的软硬件类别差异化配置帧率示例如下。

1. // 1. 确认推荐的H.264编码器的软硬件类别。
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. bool isHardware = OH_AVCapability_IsHardware(capability);
7. // 2. 基于软硬件类别差异化配置。
8. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
9. if (videoEnc == nullptr) {
10.    // 异常处理。
11. }
12. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, 1920, 1080);
13. if (format == nullptr) {
14.    // 异常处理。
15. }
16. double frameRate = isHardware ? 60.0 : 30.0;
17. if (!OH_AVFormat_SetDoubleValue(format, OH_MD_KEY_FRAME_RATE, frameRate)) {
18.    // 异常处理。
19. }
20. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
21.    // 异常处理。
22. }
23. OH_AVFormat_Destroy(format);

### 创建多路编解码器

部分业务场景涉及创建多路编解码器，基于系统内存、处理器和带宽等资源的限制，某一编解码器的实例数是有限的，不能无限制创建。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetMaxSupportedInstances|获取能力实例对应编解码器的最大实例数。实际创建数还受系统内存、处理器和带宽等资源的约束。|

优先创建硬件解码器实例，资源不足时创建软件解码器实例。示例如下。

1. constexpr int32_t NEEDED_VDEC_NUM = 8;
2. // 1. 创建硬件解码器实例。
3. OH_AVCapability *capHW = OH_AVCodec_GetCapabilityByCategory(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false, HARDWARE);
4. if (capHW == nullptr) {
5.    // 异常处理。
6. }
7. int32_t vDecNumHW = std::min(OH_AVCapability_GetMaxSupportedInstances(capHW), NEEDED_VDEC_NUM);
8. int32_t createdVDecNum = 0;
9. for (int i = 0; i < vDecNumHW; i++) {
10.    OH_AVCodec *videoDec = OH_VideoDecoder_CreateByName(OH_AVCapability_GetName(capHW));
11.    if (videoDec != nullptr) {
12.       // 维护在videoDecVector中。
13.       createdVDecNum++;
14.    }
15. }
16. if (createdVDecNum < NEEDED_VDEC_NUM) {
17.    // 2. 不够时，创建软件解码器实例。
18.    OH_AVCapability *capSW = OH_AVCodec_GetCapabilityByCategory(OH_AVCODEC_MIMETYPE_VIDEO_AVC, false, SOFTWARE);
19.    if (capSW == nullptr) {
20.       // 异常处理。
21.    }
22.    int32_t vDecNumSW = std::min(OH_AVCapability_GetMaxSupportedInstances(capSW), NEEDED_VDEC_NUM - createdVDecNum);
23.    for (int i = 0; i < vDecNumSW; i++) {
24.       OH_AVCodec *videoDec = OH_VideoDecoder_CreateByName(OH_AVCapability_GetName(capSW));
25.       if (videoDec != nullptr) {
26.          // 维护在videoDecVector中。
27.          createdVDecNum++;
28.       }
29.    }
30. }

### 控制编码质量

提供四种码控模式供开发者选择：恒定码率（CBR）、动态码率（VBR）、恒定质量（CQ）及质量稳定（SQR）。

- CBR和VBR码控模式下，编码质量取决于码率参数。
- CQ码控模式下，编码质量取决于质量参数。
- SQR码控模式下，编码质量由质量稳定码率因子和最大码率决定，且仅支持H.265（HEVC）编码。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_IsEncoderBitrateModeSupported|确认当前编码器是否支持给定的码控模式。|
|OH_AVCapability_GetEncoderBitrateRange|获取当前编码器支持的码率范围，适用于CBR、VBR和SQR码控模式。|
|OH_AVCapability_GetEncoderQualityRange|获取当前编码器支持的质量范围，适用于CQ码控模式。|

CBR和VBR码控模式示例如下。

1. OH_BitrateMode bitrateMode = BITRATE_MODE_CBR;
2. int32_t bitrate = 3000000;
3. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
4. if (capability == nullptr) {
5.    // 异常处理。
6. }
7. // 1. 确认待配置码控模式是否支持。
8. bool isSupported = OH_AVCapability_IsEncoderBitrateModeSupported(capability, bitrateMode);
9. if (!isSupported) {
10.    // 异常处理。
11. }
12. // 2. 获取码率范围，判断待配置码率参数是否在范围内。
13. OH_AVRange bitrateRange = {-1, -1};
14. int32_t ret = OH_AVCapability_GetEncoderBitrateRange(capability, &bitrateRange);
15. if (ret != AV_ERR_OK || bitrateRange.maxVal <= 0) {
16.    // 异常处理。
17. }
18. if (bitrate > bitrateRange.maxVal || bitrate < bitrateRange.minVal) {
19.    // 3.（可选）调整待配置码率参数。
20. }
21. // 4. 配置编码参数。
22. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
23. if (videoEnc == nullptr) {
24.    // 异常处理。
25. }
26. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, 1920, 1080);
27. if (format == nullptr) {
28.    // 异常处理。
29. }
30. if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_VIDEO_ENCODE_BITRATE_MODE, bitrateMode) ||
31.    !OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, static_cast<int64_t>(bitrate))) {
32.    // 异常处理。
33. }
34. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
35.    // 异常处理。
36. }
37. OH_AVFormat_Destroy(format);

CQ码控模式示例如下。

1. OH_BitrateMode bitrateMode = BITRATE_MODE_CQ;
2. int32_t quality = 0;
3. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
4. if (capability == nullptr) {
5.    // 异常处理。
6. }
7. // 1. 确认待配置码控模式是否支持。
8. bool isSupported = OH_AVCapability_IsEncoderBitrateModeSupported(capability, bitrateMode);
9. if (!isSupported) {
10.    // 异常处理。
11. }
12. // 2. 获取质量范围，判断待配置质量参数是否在范围内。
13. OH_AVRange qualityRange = {-1, -1};
14. int32_t ret = OH_AVCapability_GetEncoderQualityRange(capability, &qualityRange);
15. if (ret != AV_ERR_OK || qualityRange.maxVal < 0) {
16.    // 异常处理。
17. }
18. if (quality > qualityRange.maxVal || quality < qualityRange.minVal) {
19.    // 3.（可选）调整待配置质量参数。
20. }
21. // 4. 配置编码参数。
22. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
23. if (videoEnc == nullptr) {
24.    // 异常处理。
25. }
26. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, 1920, 1080);
27. if (format == nullptr) {
28.    // 异常处理。
29. }
30. if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_VIDEO_ENCODE_BITRATE_MODE, bitrateMode) ||
31.    !OH_AVFormat_SetIntValue(format, OH_MD_KEY_QUALITY, quality)) {
32.    // 异常处理。
33. }
34. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
35.    // 异常处理。
36. }
37. OH_AVFormat_Destroy(format);

SQR码控模式示例如下。

1. OH_BitrateMode bitrateMode = BITRATE_MODE_SQR;
2. int32_t sqrFactor = 30; // 质量稳定码率因子。
3. int32_t maxBitrate = 20000000; // 最大码率。
4. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_HEVC, true);
5. if (capability == nullptr) {
6.    // 异常处理。
7. }
8. // 1. 确认待配置码控模式是否支持。
9. bool isSupported = OH_AVCapability_IsEncoderBitrateModeSupported(capability, bitrateMode);
10. if (!isSupported) {
11.    // 异常处理。
12. }
13. // 2. 获取码率范围，判断待配置最大码率参数是否在范围内。
14. OH_AVRange bitrateRange = {-1, -1};
15. // 最大码率参数的取值范围同码率参数，故复用OH_AVCapability_GetEncoderBitrateRange获取取值范围。
16. int32_t ret = OH_AVCapability_GetEncoderBitrateRange(capability, &bitrateRange);
17. if (ret != AV_ERR_OK || bitrateRange.maxVal <= 0) {
18.    // 异常处理。
19. }

20. // 质量稳定码率因子取值范围为[0, 51]（同编码量化参数QP）。
21. if (sqrFactor > 51 || sqrFactor < 0) {
22.    // 3.（可选）调整待配置质量稳定码率因子参数。
23. }

24. if (maxBitrate > bitrateRange.maxVal || maxBitrate < bitrateRange.minVal) {
25.    // 4.（可选）调整待配置最大码率参数。
26. }

27. // 5. 配置编码参数。
28. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_HEVC);
29. if (videoEnc == nullptr) {
30.    // 异常处理。
31. }
32. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_HEVC, 1920, 1080);
33. if (format == nullptr) {
34.    // 异常处理。
35. }
36. if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_VIDEO_ENCODE_BITRATE_MODE, bitrateMode) ||
37.    !OH_AVFormat_SetIntValue(format, OH_MD_KEY_SQR_FACTOR, sqrFactor) ||
38.    !OH_AVFormat_SetIntValue(format, OH_MD_KEY_MAX_BITRATE, maxBitrate)) {
39.    // 异常处理。
40. }
41. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
42.    // 异常处理。
43. }
44. OH_AVFormat_Destroy(format);

45. // 6.启动编码器，开始编码。
46. ret = OH_VideoEncoder_Prepare(videoEnc);
47. if (ret != AV_ERR_OK) {
48.    // 异常处理。
49. }
50. ret = OH_VideoEncoder_Start(videoEnc);
51. if (ret != AV_ERR_OK) {
52.    // 异常处理。
53. }

54. // 7.（可选）OH_VideoEncoder_SetParameter()在运行过程中动态配置质量稳定码率因子参数和最大码率参数。
55. OH_AVFormat *dynamicFormat = OH_AVFormat_Create();
56. // SQR码控支持动态配置最大码率参数和质量稳定码率因子参数。
57. sqrFactor = 25; // 更新质量稳定码率因子。
58. maxBitrate = 10000000; // 更新最大码率参数。
59. OH_AVFormat_SetLongValue(dynamicFormat, OH_MD_KEY_MAX_BITRATE, maxBitrate);
60. OH_AVFormat_SetIntValue(dynamicFormat, OH_MD_KEY_SQR_FACTOR, sqrFactor);
61. ret = OH_VideoEncoder_SetParameter(videoEnc, dynamicFormat);
62. if (ret != AV_ERR_OK) {
63.    // 异常处理。
64. }
65. OH_AVFormat_Destroy(dynamicFormat);

### 查询编码器支持复杂度范围

复杂度等级决定了编码器使用的工具数量，但并非所有编码器都支持这一功能。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetEncoderComplexityRange|获取当前编码器支持的复杂度等级范围。|

1. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_AUDIO_AAC, true);
2. if (capability == nullptr) {
3.    // 异常处理。
4. }
5. // 确认支持的编码复杂度范围。
6. OH_AVRange complexityRange = {-1, -1};
7. int32_t ret = OH_AVCapability_GetEncoderComplexityRange(capability, &complexityRange);

### 设置正确的音频编解码参数

在音频编解码场景中，需要设置采样率和通道数。对于音频编码，还需要设置码率。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetAudioSupportedSampleRateRanges|获取当前音频编解码器支持的采样率范围。|
|OH_AVCapability_GetAudioChannelCountRange|获取当前音频编解码器支持的通道数范围。|
|OH_AVCapability_GetEncoderBitrateRange|获取当前编码器支持的码率范围。|

音频编解码参数查询示例如下。

1. int32_t sampleRate = 44100;
2. int32_t channelCount = 2;
3. int32_t bitrate = 261000;
4. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_AUDIO_AAC, true);
5. if (capability == nullptr) {
6.    // 异常处理。
7. }
8. // 1. 确认待配置采样率是否支持。
9. OH_AVRange *sampleRateRanges = nullptr;
10. uint32_t rangesNum = 0;
11. int32_t ret = OH_AVCapability_GetAudioSupportedSampleRateRanges(capability, &sampleRateRanges, &rangesNum);
12. if (ret != AV_ERR_OK || sampleRateRanges == nullptr || rangesNum == 0) {
13.    // 异常处理。
14. }
15. bool isMatched = false;
16. for (uint32_t i = 0; i < rangesNum; i++) {
17.    if (sampleRate >= sampleRateRanges[i].minVal && sampleRate <= sampleRateRanges[i].maxVal) {
18.       isMatched = true;
19.       break;
20.    }
21. }
22. if (!isMatched) {
23.    // 2.（可选）调整待配置采样率。
24. }
25. // 3. 获取通道数范围，判断待配置通道数参数是否在范围内。
26. OH_AVRange channelRange = {-1, -1};
27. ret = OH_AVCapability_GetAudioChannelCountRange(capability, &channelRange);
28. if (ret != AV_ERR_OK || channelRange.maxVal <= 0) {
29.    // 异常处理。
30. }
31. if (channelCount > channelRange.maxVal || channelCount < channelRange.minVal ) {
32.    // 4.（可选）调整待配置通道数。
33. }
34. // 5. 获取码率范围，判断待配置码率参数是否在范围内。
35. OH_AVRange bitrateRange = {-1, -1};
36. ret = OH_AVCapability_GetEncoderBitrateRange(capability, &bitrateRange);
37. if (ret != AV_ERR_OK || bitrateRange.maxVal <= 0) {
38.    // 异常处理。
39. }
40. if (bitrate > bitrateRange.maxVal || bitrate < bitrateRange.minVal ) {
41.    // 6.（可选）调整待配置码率值。
42. }
43. // 7. 配置编码参数。
44. OH_AVCodec *audioEnc = OH_AudioCodec_CreateByMime(OH_AVCODEC_MIMETYPE_AUDIO_AAC, true);
45. if (audioEnc == nullptr) {
46.    // 异常处理。
47. }
48. OH_AVFormat *format = OH_AVFormat_Create();
49. if (format == nullptr) {
50.    // 异常处理。
51. }
52. if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_SAMPLE_RATE, sampleRate) ||
53.    !OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_CHANNEL_COUNT, channelCount) ||
54.    !OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, static_cast<int64_t>(bitrate))) {
55.    // 异常处理。
56. }
57. if (OH_AudioCodec_Configure(audioEnc, format) != AV_ERR_OK) {
58.    // 异常处理。
59. }
60. OH_AVFormat_Destroy(format);

### 查询编解码档次和级别支持情况

编解码标准包含多种编码工具，适用于不同的编码场景。对于特定应用场景，编解码标准按档次确定所需编码工具的开启与关闭情况（例如，H.264有基本档次、主档次和高档次）。详情参见 [OH_AVCProfile](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#oh_avcprofile)。

级别划分了编解码器所需的处理能力和存储空间。H.264有1到6.2的20个级别，参考[OH_AVCLevel](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-base-h#oh_avclevel)。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetSupportedProfiles|获取当前编解码器支持的档次。|
|OH_AVCapability_GetSupportedLevelsForProfile|获取当前编解码器在给定档次的情况下支持的级别信息。|
|OH_AVCapability_AreProfileAndLevelSupported|确认当前编解码器是否支持特定的档次和级别组合。|

确认待配置的档次是否支持，并查询该档次下支持的级别，示例如下。

1. OH_AVCProfile profile = AVC_PROFILE_MAIN;
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 1. 确认待配置档次是否支持。
7. const int32_t *profiles = nullptr;
8. uint32_t profileNum = 0;
9. int32_t ret = OH_AVCapability_GetSupportedProfiles(capability, &profiles, &profileNum);
10. if (ret != AV_ERR_OK || profiles == nullptr || profileNum == 0) {
11.    // 异常处理。
12. }
13. bool isMatched = false;
14. for (int i = 0; i < profileNum; i++) {
15.    if (profiles[i] == profile) {
16.       isMatched = true;
17.       break;
18.    }
19. }
20. // 2. 查询待配置档次能支持的级别范围。
21. const int32_t *levels = nullptr;
22. uint32_t levelNum = 0;
23. ret = OH_AVCapability_GetSupportedLevelsForProfile(capability, profile, &levels, &levelNum);
24. if (ret != AV_ERR_OK || levels == nullptr || levelNum == 0) {
25.    // 异常处理。
26. }
27. OH_AVCLevel maxLevel = static_cast<OH_AVCLevel>(levels[0]);
28. for (int32_t i = 1; i < levelNum; i++) {
29.    OH_AVCLevel tmp = static_cast<OH_AVCLevel>(levels[i]);
30.    if (tmp > maxLevel) {
31.       maxLevel = tmp;
32.    }
33. }
34. // 3.（可选）基于支持的最大级别做业务逻辑区分。
35. if (maxLevel >= AVC_LEVEL_51) {
36.    // level5.1以上，宽、高可配置3840x2160。
37. } else if (maxLevel >= AVC_LEVEL_4) {
38.    // level4.0以上，宽、高可配1920x1080。
39. } else if (maxLevel >= AVC_LEVEL_31) {
40.    // level3.1以上，宽、高可配1280x720。
41. } else {
42.    // 报错，不做编码。
43. }
44. // 4. 配置档次参数。
45. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
46. if (videoEnc == nullptr) {
47.    // 异常处理。
48. }
49. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, 1920, 1080);
50. if (format == nullptr) {
51.    // 异常处理。
52. }
53. if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_PROFILE, profile)) {
54.    // 异常处理。
55. }
56. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
57.    // 异常处理。
58. }
59. OH_AVFormat_Destroy(format);

已知需要的编码档次和级别组合，直接查询支持情况示例如下。

1. // 1. 获取H.264编码器能力实例。
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 2. 查询编码档次和级别是否支持。
7. bool isSupported = OH_AVCapability_AreProfileAndLevelSupported(capability, AVC_PROFILE_MAIN, AVC_LEVEL_51);

### 设置正确的视频宽高

视频编解码器对宽度和高度有对齐约束。例如，主流编解码器默认编解码像素格式为YUV420系列，UV分量在宽度和高度两个方向都会下采样为原始尺寸的一半，因此视频编解码的宽度和高度至少要按2对齐。其他因素也可能导致更严格的对齐约束。

视频编解码的宽高不仅会受帧级编解码能力限制，同时也会受协议级别对帧级能力的限制。以H.264为例，AVC_LEVEL_51限定最大每帧宏块数目为36864个。

根据视频高度计算最大视频宽度的公式如下。

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163522.21628697965758197878979086268428:50001231000000:2800:CC6B046C15473B4334998D3F883C28F9F7B9B3949AE5300954CE9FAFF6028439.png)

MaxMBsPerFrameLevelLimits表示协议限定的编解码器最大每帧宏块数，MaxMBsPerFrameSubmit表示编解码器上报的最大每帧宏块数，实际能力取这两者的最小值。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetVideoWidthAlignment|获取当前视频编解码器的宽对齐。|
|OH_AVCapability_GetVideoHeightAlignment|获取当前视频编解码器的高对齐。|
|OH_AVCapability_GetVideoWidthRange|获取当前视频编解码器支持的宽的范围。|
|OH_AVCapability_GetVideoHeightRange|获取当前视频编解码器支持的高的范围。|
|OH_AVCapability_GetVideoWidthRangeForHeight|获取当前视频编解码器在给定高情况下的宽的范围。|
|OH_AVCapability_GetVideoHeightRangeForWidth|获取当前视频编解码器在给定宽情况下的高的范围。|
|OH_AVCapability_IsVideoSizeSupported|校验当前视频编解码器是否支持给定的宽高组合。|

校验视频高度和宽度是否支持，示例如下。

1. int32_t width = 1920;
2. int32_t height = 1080;
3. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
4. if (capability == nullptr) {
5.    // 异常处理。
6. }
7. // 1. 确认视频宽高是否支持。
8. bool isSupported = OH_AVCapability_IsVideoSizeSupported(capability, width, height);
9. if (!isSupported) {
10.    // 2. (可选) 按已知视频高或已知视频宽查询详细限制，并调整。
11. }

如果视频高度和视频宽度校验不支持或配置失败，可尝试以下方法确定正确的视频宽高范围。

已知视频宽度，可以按照以下示例找到正确的尺寸配置。

1. int32_t width = 1920;
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 1. 确认视频宽符合宽对齐要求。
7. int32_t widthAlignment = 0;
8. int32_t ret = OH_AVCapability_GetVideoWidthAlignment(capability, &widthAlignment);
9. if (ret != AV_ERR_OK || widthAlignment <= 0) {
10.    // 异常处理。
11. } else if (width % widthAlignment != 0) {
12.    // 2. (可选) 对齐视频宽。
13.    width = (width + widthAlignment - 1) / widthAlignment * widthAlignment;
14. }
15. // 3. 确认视频宽处在可支持宽范围内。
16. OH_AVRange widthRange = {-1, -1};
17. ret = OH_AVCapability_GetVideoWidthRange(capability, &widthRange);
18. if (ret != AV_ERR_OK || widthRange.maxVal <= 0) {
19.    // 异常处理。
20. } else if (width < widthRange.minVal || width > widthRange.maxVal) {
21.    // 4. (可选) 调整视频宽。
22.    width = std::min(std::max(width, widthRange.minVal), widthRange.maxVal);
23. }
24. // 5. 基于视频宽，获取可选视频高的范围。
25. OH_AVRange heightRange = {-1, -1};
26. ret = OH_AVCapability_GetVideoHeightRangeForWidth(capability, width, &heightRange);
27. if (ret != AV_ERR_OK || heightRange.maxVal <= 0) {
28.    // 异常处理。
29. }
30. // 6. 从可选高度范围中挑选合适的高度配置。

已知视频高度，可以按照以下示例找到正确的尺寸配置。

1. int32_t height = 1080;
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 1. 确认视频高符合高对齐要求。
7. int32_t heightAlignment = 0;
8. int32_t ret = OH_AVCapability_GetVideoHeightAlignment(capability, &heightAlignment);
9. if (ret != AV_ERR_OK || heightAlignment <= 0) {
10.    // 异常处理。
11. } else if (height % heightAlignment != 0) {
12.    // 2. (可选) 对齐视频高。
13.    height = (height + heightAlignment - 1) / heightAlignment * heightAlignment;
14. }
15. // 3. 确认视频高处在可支持高范围内。
16. OH_AVRange heightRange = {-1, -1};
17. ret = OH_AVCapability_GetVideoHeightRange(capability, &heightRange);
18. if (ret != AV_ERR_OK || heightRange.maxVal <= 0) {
19.    // 异常处理。
20. } else if (height < heightRange.minVal || height > heightRange.maxVal) {
21.    // 4. (可选) 调整视频高。
22.    height = std::min(std::max(height, heightRange.minVal), heightRange.maxVal);
23. }
24. // 5. 基于视频高，获取可选视频宽的范围。
25. OH_AVRange widthRange = {-1, -1};
26. ret = OH_AVCapability_GetVideoWidthRangeForHeight(capability, height, &widthRange);
27. if (ret != AV_ERR_OK || widthRange.maxVal <= 0) {
28.    // 异常处理。
29. }
30. // 6. 从可选宽度范围中挑选合适的宽度配置。

### 设置正确的视频帧率

视频编解码的帧率受编解码器的每秒编解码能力和协议级别的每秒处理能力限制。例如，H.264的AVC_LEVEL_51限定最大每秒宏块数目为983040个。

根据视频的宽度和高度，计算最大帧率的公式如下。

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163522.06003574845081625131832403170209:50001231000000:2800:66B7A3A8398C6DAF1DA013A7346A78D2EC1ED80472FB252107A59114E874A189.png)

MaxMBsPerSecondLevelLimits表示协议限定的编解码器最大每秒宏块数，MaxMBsPerSecondSubmit表示编解码器上报的最大每秒宏块数，实际能力取这两者的最小值。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetVideoFrameRateRange|获取当前视频编解码器支持的帧率的范围。|
|OH_AVCapability_GetVideoFrameRateRangeForSize|获取当前视频编解码器在给定图像尺寸情况下的帧率的范围。|
|OH_AVCapability_AreVideoSizeAndFrameRateSupported|校验视频编解码器是否支持视频大小和帧率的特定组合。|

有帧率目标需求时，校验帧率是否在可选范围内。示例如下。

1. int32_t frameRate = 120;
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 1. 获取支持的帧率范围。
7. OH_AVRange frameRateRange = {-1, -1};
8. int32_t ret = OH_AVCapability_GetVideoFrameRateRange(capability, &frameRateRange);
9. if (ret != AV_ERR_OK || frameRateRange.maxVal <= 0) {
10.    // 异常处理。
11. }
12. // 2. 判断是否在可选帧率范围内。
13. bool isSupported = frameRate >= frameRateRange.minVal && frameRate <= frameRateRange.maxVal;

根据待配置的尺寸选择合适的帧率配置，示例代码如下。

1. constexpr int32_t width = 1920;
2. constexpr int32_t height = 1080;
3. int32_t frameRate = 120;
4. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
5. if (capability == nullptr) {
6.    // 异常处理。
7. }
8. // 1. 确认待配置尺寸是否能达到理想帧率。
9. bool isSupported = OH_AVCapability_AreVideoSizeAndFrameRateSupported(capability, width, height, frameRate);
10. if (!isSupported) {
11.    // 2. 基于待配置视频尺寸，查询支持的帧率范围，并基于查询到的帧率调整待配置帧率。
12.    OH_AVRange frameRateRange = {-1, -1};
13.    int32_t ret = OH_AVCapability_GetVideoFrameRateRangeForSize(capability, width, height, &frameRateRange);
14.    if (ret != AV_ERR_OK || frameRateRange.maxVal <= 0) {
15.       // 异常处理。
16.    }
17.    frameRate = std::min(std::max(frameRate, frameRateRange.minVal), frameRateRange.maxVal);
18. }

19. // 3. 配置尺寸和帧率参数。
20. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
21. if (videoEnc == nullptr) {
22.    // 异常处理。
23. }
24. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, width, height);
25. if (format == nullptr) {
26.    // 异常处理。
27. }
28. if (!OH_AVFormat_SetDoubleValue(format, OH_MD_KEY_FRAME_RATE, static_cast<double>(frameRate))) {
29.    // 异常处理。
30. }
31. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
32.    // 异常处理。
33. }
34. OH_AVFormat_Destroy(format);

### 设置正确的视频像素格式信息

视频像素格式指示的编码输入图像或解码输出图像的像素排布方式，参考[OH_AVPixelFormat](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avformat-h#oh_avpixelformat)。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_GetVideoSupportedPixelFormats|获取当前视频编解码器支持的像素格式。|

1. constexpr OH_AVPixelFormat DEFAULT_PIXELFORMAT = AV_PIXEL_FORMAT_NV12;
2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
3. if (capability == nullptr) {
4.    // 异常处理。
5. }
6. // 1. 获取当前视频编解码器支持的像素格式。
7. const int32_t *pixFormats = nullptr;
8. uint32_t pixFormatNum = 0;
9. int32_t ret = OH_AVCapability_GetVideoSupportedPixelFormats(capability, &pixFormats, &pixFormatNum);
10. if (ret != AV_ERR_OK || pixFormats == nullptr || pixFormatNum == 0) {
11.    // 异常处理。
12. }
13. // 2. 校验是否支持对应像素格式。
14. bool isMatched = false;
15. for (int i = 0; i < pixFormatNum; i++) {
16.    if (pixFormats[i] == DEFAULT_PIXELFORMAT) {
17.       isMatched = true;
18.       break;
19.    }
20. }
21. if (!isMatched) {
22.    // 3. 替换其他像素格式输入或选择其他编解码器。
23. }

### 查询编解码特性支持情况并获取特性属性信息

编解码特性是指在特定编解码场景中使用的可选特性，例如视频编码场景的时域可分级编码、 低时延编解码等。具体请参考[OH_AVCapabilityFeature](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcapability-h#oh_avcapabilityfeature)。

|接口|功能描述|
|:--|:--|
|OH_AVCapability_IsFeatureSupported|确认当前编解码器是否支持给定的特性。|
|OH_AVCapability_GetFeatureProperties|获取当前编解码器支持的指定特性的属性。|

查询H.264编码器是否支持长期参考帧特性，示例如下。

1. constexpr int32_t NEEDED_LTR_NUM = 2;
2. OH_AVFormat *format = OH_AVFormat_CreateVideoFormat(OH_AVCODEC_MIMETYPE_VIDEO_AVC, 1920, 1080);
3. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_VIDEO_AVC, true);
4. if (capability == nullptr) {
5.    // 异常处理。
6. }
7. // 1. 查询是否支持长期参考帧特性。
8. bool isSupported = OH_AVCapability_IsFeatureSupported(capability,VIDEO_ENCODER_LONG_TERM_REFERENCE);
9. if (isSupported) {
10.    // 2. 查询支持的长期参考帧个数。
11.    OH_AVFormat *properties = OH_AVCapability_GetFeatureProperties(capability, VIDEO_ENCODER_LONG_TERM_REFERENCE);
12.    if (properties == nullptr) {
13.       // 异常处理。
14.    }
15.    int32_t maxLTRCount = -1;
16.    bool ret = OH_AVFormat_GetIntValue(properties, OH_FEATURE_PROPERTY_KEY_VIDEO_ENCODER_MAX_LTR_FRAME_COUNT, &maxLTRCount);
17.    if (ret && maxLTRCount >= NEEDED_LTR_NUM) {
18.       if (!OH_AVFormat_SetIntValue(format, OH_MD_KEY_VIDEO_ENCODER_LTR_FRAME_COUNT, NEEDED_LTR_NUM)) {
19.          // 异常处理。
20.       }
21.    }
22. }
23. // 3. 编码器创建和配置。
24. OH_AVCodec *videoEnc = OH_VideoEncoder_CreateByMime(OH_AVCODEC_MIMETYPE_VIDEO_AVC);
25. if (OH_VideoEncoder_Configure(videoEnc, format) != AV_ERR_OK) {
26.    // 异常处理。
27. }

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-codec "音视频编解码")
# 音频编码

更新时间: 2025-12-16 16:35

开发者可以调用本模块的Native API接口，完成音频编码，即将音频PCM编码压缩成不同的格式。

接口不限制PCM数据的来源，开发者可以调用麦克风录制获取、也可以导入编辑后的PCM数据，通过音频编码，输出对应格式的码流，最后封装为目标格式文件。

当前支持的编码能力请参考[AVCodec支持的格式](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/avcodec-support-formats#%E9%9F%B3%E9%A2%91%E7%BC%96%E7%A0%81)。

**适用场景**

- 音频录制
    
    通过录制传入PCM，然后编码出对应格式的码流，最后[封装](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-muxer)为所需格式的音频文件。
    
- 音频编辑
    
    编辑PCM后导出音频文件的场景，需要编码成对应音频格式后再[封装](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/audio-video-muxer)成文件。
    

说明

- AAC编码器默认采用的VBR可变码率模式，与配置的预期参数可能存在偏差。
- AAC编码器默认输出携带ADTS头部，帧数据的前7字节为ADTS头部。

## 开发指导

详细的API说明请参考[API文档](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-native-avcodec-audiocodec-h)。

参考以下示例代码，完成音频编码的全流程，包括：创建编码器、设置编码参数（采样率/码率/声道数等）、开始、刷新、重置、销毁资源。

在应用开发过程中，开发者应按一定顺序调用方法，执行对应操作，否则系统可能会抛出异常或生成其他未定义的行为。具体顺序可参考下列开发步骤及对应说明。

如下为音频编码调用关系图：

- 虚线表示可选。
    
- 实线表示必选。
    

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163524.46201621616655345708550248555573:50001231000000:2800:A66B37FE3E48EA61A79141FDD61631537630D6F5A5B1306C8A69E3A6DD508F55.png)

### 在 CMake 脚本中链接动态库

1. target_link_libraries(sample PUBLIC libnative_media_codecbase.so)
2. target_link_libraries(sample PUBLIC libnative_media_core.so)
3. target_link_libraries(sample PUBLIC libnative_media_acodec.so)

说明

上述'sample'字样仅为示例，此处由开发者根据实际工程目录自定义。

### 开发步骤

1. 添加所需的头文件。
    
    1. #include <multimedia/player_framework/native_avcodec_audiocodec.h>
    2. #include <multimedia/native_audio_channel_layout.h>
    3. #include <multimedia/player_framework/native_avcapability.h>
    4. #include <multimedia/player_framework/native_avcodec_base.h>
    5. #include <multimedia/player_framework/native_avformat.h>
    6. #include <multimedia/player_framework/native_avbuffer.h>
    
2. 创建编码器实例对象，OH_AVCodec*为编码器实例指针。
    
    应用可以通过媒体类型或编解码器名称创建编码器。
    
    方法一：通过mime type创建编码器。
    
    1. // 设置判定是否为编码；设置true表示当前是编码。
    2. bool isEncoder = true;
    3. // 通过媒体类型创建编码器。
    4. OH_AVCodec *audioEnc_ = OH_AudioCodec_CreateByMime(OH_AVCODEC_MIMETYPE_AUDIO_AAC, isEncoder);
    
    方法二：通过codec name创建编码器。
    
    1. // 通过codec name创建编码器。
    2. OH_AVCapability *capability = OH_AVCodec_GetCapability(OH_AVCODEC_MIMETYPE_AUDIO_AAC, true);
    3. const char *name = OH_AVCapability_GetName(capability);
    4. OH_AVCodec *audioEnc_ = OH_AudioCodec_CreateByName(name);
    
    添加头文件和命名空间:
    
    1. #include <mutex>
    2. #include <queue>
    3. // c++标准库命名空间。
    4. using namespace std;
    
    示例代码：
    
    1. // 初始化队列。
    2. class AEncBufferSignal {
    3. public:
    4.     std::mutex inMutex_;
    5.     std::mutex outMutex_;
    6.     std::mutex startMutex_;
    7.     std::condition_variable inCond_;
    8.     std::condition_variable outCond_;
    9.     std::condition_variable startCond_;
    10.     std::queue<uint32_t> inQueue_;
    11.     std::queue<uint32_t> outQueue_;
    12.     std::queue<OH_AVBuffer *> inBufferQueue_;
    13.     std::queue<OH_AVBuffer *> outBufferQueue_;
    14. };
    15. AEncBufferSignal *signal_;
    
3. 调用OH_AudioCodec_RegisterCallback()注册回调函数。
    
    注册回调函数指针集合OH_AVCodecCallback，包括：
    
    - OH_AVCodecOnError：编码器运行错误。
    - OH_AVCodecOnStreamChanged：音频编码器暂未支持此回调。
    - OH_AVCodecOnNeedInputBuffer：运行过程中需要新的输入数据，即编码器已准备好，可以输入PCM数据。
    - OH_AVCodecOnNewOutputBuffer：运行过程中产生了新的输出数据，即编码完成。
    
    开发者可以通过处理该回调报告的信息，确保编码器正常运转。
    
    注意
    
    请勿在回调中调用编码器的相关接口或进行耗时操作。
    
    1. // OH_AVCodecOnError回调函数的实现。
    2. static void OnError(OH_AVCodec *codec, int32_t errorCode, void *userData)
    3. {
    4.     (void)codec;
    5.     (void)errorCode;
    6.     (void)userData;
    7. }
    8. // OH_AVCodecOnStreamChanged回调函数的实现。
    9. static void OnOutputFormatChanged(OH_AVCodec *codec, OH_AVFormat *format, void *userData)
    10. {
    11.     (void)codec;
    12.     (void)format;
    13.     (void)userData;
    14. }
    15. // OH_AVCodecOnNeedInputBuffer回调函数的实现。
    16. static void OnInputBufferAvailable(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *data, void *userData)
    17. {
    18.     (void)codec;
    19.     // 编码输入码流送入InputBuffer队列。
    20.     AEncBufferSignal *signal = static_cast<AEncBufferSignal *>(userData);
    21.     unique_lock<mutex> lock(signal->inMutex_);
    22.     signal->inQueue_.push(index);
    23.     signal->inBufferQueue_.push(data);
    24.     signal->inCond_.notify_all();
    25. }
    26. // OH_AVCodecOnNewOutputBuffer回调函数的实现。
    27. static void OnOutputBufferAvailable(OH_AVCodec *codec, uint32_t index, OH_AVBuffer *data, void *userData)
    28. {
    29.     (void)codec;
    30.     // 将对应输出buffer的index送入OutputQueue_队列。
    31.     // 将对应编码完成的数据data送入outBuffer队列。
    32.     AEncBufferSignal *signal = static_cast<AEncBufferSignal *>(userData);
    33.     unique_lock<mutex> lock(signal->outMutex_);
    34.     signal->outQueue_.push(index);
    35.     signal->outBufferQueue_.push(data);
    36.     signal->outCond_.notify_all();
    37. }
    
    配置回调：
    
    38. signal_ = new AEncBufferSignal();
    39. OH_AVCodecCallback cb_ = {&OnError, &OnOutputFormatChanged, &OnInputBufferAvailable, &OnOutputBufferAvailable};
    40. // 配置异步回调。
    41. int32_t ret = OH_AudioCodec_RegisterCallback(audioEnc_, cb_, signal_);
    42. if (ret != AV_ERR_OK) {
    43.     // 异常处理。
    44. }
    
4. 调用OH_AudioCodec_Configure设置编码器。
    
    配置选项key值说明：
    
    |key|描述|AAC|Flac|MPEG(MP3)|G711mu|opus|amrnb|amrwb|
    |:--|:--|:--|:--|:--|:--|:--|:--|:--|
    |OH_MD_KEY_AUD_SAMPLE_RATE|采样率|必须|必须|必须|必须|必须|必须|必须|
    |OH_MD_KEY_AUD_CHANNEL_COUNT|声道数|必须|必须|必须|必须|必须|必须|必须|
    |OH_MD_KEY_AUDIO_SAMPLE_FORMAT|输出音频流格式|必须|必须|必须|必须|必须|必须|必须|
    |OH_MD_KEY_BITRATE|码率|可选|必须|必须|-|必须|必须|必须|
    |OH_MD_KEY_CHANNEL_LAYOUT|声道布局|可选|必须|-|-|-|-|-|
    |OH_MD_KEY_MAX_INPUT_SIZE|最大输入长度|可选|可选|可选|可选|可选|可选|可选|
    |OH_MD_KEY_PROFILE|编码档次|可选|-|-|-|-|-|-|
    |OH_MD_KEY_COMPLIANCE_LEVEL|兼容性等级|-|可选|-|-|-|-|-|
    
    各音频编码类型参数范围说明：
    
    |音频编码类型|采样率(Hz)|声道数|
    |:--|:--|:--|
    |Flac|8000、11025、12000、16000、22050、24000、32000、44100、48000、64000、88200、96000|1~8|
    |MP3|8000、11025、12000、16000、22050、24000、32000、44100、48000|1~2|
    |G711mu|8000|1|
    |AAC-LC|8000、11025、12000、16000、22050、24000、32000、44100、48000、64000、88200、96000|1、2、3、4、5、6、8|
    |HE-AAC、HE-AAC v2|16000、22050、24000、32000、44100、48000、64000、88200、96000|1、2、3、4、5、6、8|
    |opus|8000、12000、16000、24000、48000|1~2|
    |AMR(amrnb)|8000|1|
    |AMR(amrwb)|16000|1|
    
    例如对一个44100Hz采样率、2声道立体声、SAMPLE_S16LE采样格式的PCM音频，以32000bps的码率进行AAC编码的调用流程如下：
    
    1. int32_t ret;
    2. // 配置音频采样率（必须）
    3. constexpr uint32_t DEFAULT_SAMPLERATE = 44100;
    4. // 配置音频码率（必须）
    5. constexpr uint64_t DEFAULT_BITRATE = 32000;
    6. // 配置音频声道数（必须）
    7. constexpr uint32_t DEFAULT_CHANNEL_COUNT = 2;
    8. // 配置音频声道类型（必须）
    9. constexpr OH_AudioChannelLayout CHANNEL_LAYOUT = OH_AudioChannelLayout::CH_LAYOUT_STEREO;
    10. // 配置音频位深（必须）
    11. constexpr OH_BitsPerSample SAMPLE_FORMAT = OH_BitsPerSample::SAMPLE_S16LE;
    12. // 配置AAC profile（可选，默认值：AAC_PROFILE_LC，其他可选值：AAC_PROFILE_HE、AAC_PROFILE_HE_V2）
    13. constexpr int32_t AAC_PROFILE = OH_AACProfile::AAC_PROFILE_LC;
    
    14. OH_AVFormat *format = OH_AVFormat_Create();
    15. // 写入format
    16. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_CHANNEL_COUNT, DEFAULT_CHANNEL_COUNT);
    17. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_SAMPLE_RATE, DEFAULT_SAMPLERATE);
    18. OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, DEFAULT_BITRATE);
    19. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUDIO_SAMPLE_FORMAT, SAMPLE_FORMAT);
    20. OH_AVFormat_SetLongValue(format, OH_MD_KEY_CHANNEL_LAYOUT, CHANNEL_LAYOUT);
    21. OH_AVFormat_SetIntValue(format, OH_MD_KEY_PROFILE, AAC_PROFILE);
    22. // 配置编码器
    23. ret = OH_AudioCodec_Configure(audioEnc_, format);
    24. if (ret != AV_ERR_OK) {
    25.     // 异常处理
    26. }
    
    例FLAC调用流程：
    
    27. int32_t ret;
    28. // 配置音频采样率（必须）。
    29. constexpr uint32_t DEFAULT_SAMPLERATE = 44100;
    30. // 配置音频码率（必须）。
    31. constexpr uint64_t DEFAULT_BITRATE = 261000;
    32. // 配置音频声道数（必须）。
    33. constexpr uint32_t DEFAULT_CHANNEL_COUNT = 2;
    34. // 配置音频声道布局（必须）。
    35. // 值为CH_LAYOUT_MONO、CH_LAYOUT_STEREO、CH_LAYOUT_SURROUND、CH_LAYOUT_QUAD、CH_LAYOUT_5POINT0、CH_LAYOUT_5POINT1、CH_LAYOUT_6POINT1或CH_LAYOUT_7POINT1其中一项。
    36. constexpr OH_AudioChannelLayout CHANNEL_LAYOUT = OH_AudioChannelLayout::CH_LAYOUT_STEREO;
    37. // 配置音频位深（必须） flac只有SAMPLE_S16LE和SAMPLE_S32LE。
    38. constexpr OH_BitsPerSample SAMPLE_FORMAT = OH_BitsPerSample::SAMPLE_S32LE;
    39. // 配置音频compliance level (默认值0，取值范围-2~2)。
    40. constexpr int32_t COMPLIANCE_LEVEL = 0;
    
    41. OH_AVFormat *format = OH_AVFormat_Create();
    42. // 写入format。
    43. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_CHANNEL_COUNT, DEFAULT_CHANNEL_COUNT);
    44. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_SAMPLE_RATE, DEFAULT_SAMPLERATE);
    45. OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, DEFAULT_BITRATE);
    46. // 配置音频精度。API version 20前，FLAC编码必须设置此参数，设置为1即可；未设置此参数配置FLAC编码器时，调用OH_AudioCodec_Configure会返回错误码AV_ERR_INVALID_VAL。该值无实际作用，不会影响编码结果。从API version 20开始，无需设置此参数。
    47. // constexpr int32_t BITS_PER_CODED_SAMPLE = 1;
    48. // OH_AVFormat_SetIntValue(format, OH_MD_KEY_BITS_PER_CODED_SAMPLE, BITS_PER_CODED_SAMPLE);
    49. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUDIO_SAMPLE_FORMAT, SAMPLE_FORMAT);
    50. OH_AVFormat_SetLongValue(format, OH_MD_KEY_CHANNEL_LAYOUT, CHANNEL_LAYOUT);
    51. OH_AVFormat_SetLongValue(format, OH_MD_KEY_COMPLIANCE_LEVEL, COMPLIANCE_LEVEL);
    52. // 配置编码器。
    53. ret = OH_AudioCodec_Configure(audioEnc_, format);
    54. if (ret != AV_ERR_OK) {
    55.     // 异常处理。
    56. }
    
    例AMR编码调用流程：
    
    57. int32_t ret;
    58. // 配置音频采样率（必须），amr-nb输入采样率为8000hz的PCM，amr-wb输入采样率为16000hz的PCM
    59. constexpr uint32_t DEFAULT_SAMPLERATE = 8000;
    60. // 配置音频码率（必须）
    61. // amr-nb支持码率4750、5150、5900、6700、7400、7950、10200、12200
    62. // amr-wb支持码率6600、8850、12650、14250、15850、18250、19850、23050、23850
    63. constexpr uint64_t DEFAULT_BITRATE = 10200;
    64. // 配置音频声道数（必须）
    65. constexpr uint32_t DEFAULT_CHANNEL_COUNT = 1;
    66. // 配置音频声道类型（必须）
    67. constexpr OH_AudioChannelLayout CHANNEL_LAYOUT = OH_AudioChannelLayout::CH_LAYOUT_MONO;
    68. // 配置音频位深（必须）
    69. constexpr OH_BitsPerSample SAMPLE_FORMAT = OH_BitsPerSample::SAMPLE_S16LE;
    70. OH_AVFormat *format = OH_AVFormat_Create();
    71. // 写入format
    72. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_CHANNEL_COUNT, DEFAULT_CHANNEL_COUNT);
    73. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_SAMPLE_RATE, DEFAULT_SAMPLERATE);
    74. OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, DEFAULT_BITRATE);
    75. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUDIO_SAMPLE_FORMAT, SAMPLE_FORMAT);
    76. OH_AVFormat_SetLongValue(format, OH_MD_KEY_CHANNEL_LAYOUT, CHANNEL_LAYOUT);
    77. // 配置编码器
    78. ret = OH_AudioCodec_Configure(audioEnc_, format);
    79. if (ret != AV_ERR_OK) {
    80.     // 异常处理
    81. }
    
    例opus编码调用流程：
    
    82. int32_t ret;
    83. // 配置音频采样率（必须）
    84. // opus编码支持采样率：8000、12000、16000、24000、48000
    85. constexpr uint32_t DEFAULT_SAMPLERATE = 8000;
    86. // 配置音频码率（必须）
    87. // opus编码码率范围：[6000, 510000]
    88. constexpr uint64_t DEFAULT_BITRATE = 6000;
    89. // 配置音频声道数（必须）
    90. // opus编码支持声道数：1、2
    91. constexpr uint32_t DEFAULT_CHANNEL_COUNT = 1;
    92. // 配置音频位深（必须）
    93. // opus编码支持位深：SAMPLE_S16LE
    94. constexpr OH_BitsPerSample SAMPLE_FORMAT = OH_BitsPerSample::SAMPLE_S16LE;
    95. OH_AVFormat *format = OH_AVFormat_Create();
    96. // 写入format
    97. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_CHANNEL_COUNT, DEFAULT_CHANNEL_COUNT);
    98. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUD_SAMPLE_RATE, DEFAULT_SAMPLERATE);
    99. OH_AVFormat_SetLongValue(format, OH_MD_KEY_BITRATE, DEFAULT_BITRATE);
    100. OH_AVFormat_SetIntValue(format, OH_MD_KEY_AUDIO_SAMPLE_FORMAT, SAMPLE_FORMAT);
    101. // 配置编码器
    102. ret = OH_AudioCodec_Configure(audioEnc_, format);
    103. if (ret != AV_ERR_OK) {
    104.     // 异常处理
    105. }
    
5. 调用OH_AudioCodec_Prepare()，编码器就绪。
    
    1. int32_t ret = OH_AudioCodec_Prepare(audioEnc_);
    2. if (ret != AV_ERR_OK) {
    3.     // 异常处理。
    4. }
    
6. 调用OH_AudioCodec_Start()启动编码器，进入运行态。
    
    添加头文件：
    
    1. #include <fstream>
    
    使用示例：
    
    2. ifstream inputFile_;
    3. ofstream outFile_;
    
    4. // 根据实际使用情况填写输入文件路径。
    5. const char* inputFilePath = "/";
    6. // 根据实际使用情况填写输出文件路径。
    7. const char* outputFilePath = "/";
    8. // 打开待编码二进制文件路径（此处以输入为PCM文件为例）。
    9. inputFile_.open(inputFilePath, ios::in | ios::binary);
    10. // 配置编码文件输出路径（此处以输出为编码码流文件为例）。
    11. outFile_.open(outputFilePath, ios::out | ios::binary);
    12. // 开始编码。
    13. int32_t ret = OH_AudioCodec_Start(audioEnc_);
    14. if (ret != AV_ERR_OK) {
    15.     // 异常处理。
    16. }
    
7. 调用OH_AudioCodec_PushInputBuffer()，写入待编码的数据。需开发者填充完整的输入数据后调用。
    
    每次输入的采样点数（SAMPLES_PER_FRAME）取值方法如下：
    
    AAC-LC编码每帧包含1024个PCM样点，建议单次输入1024个样点的数据量。
    
    HE-AAC编码每帧包含2048个PCM样点，建议单次输入2048个样点的数据量。
    
    flac比较特殊，需要根据如下表格进行设置。
    
    |采样率|样点数|
    |:--|:--|
    |8000|576|
    |16000|1152|
    |22050|2304|
    |24000|2304|
    |32000|2304|
    |44100|4608|
    |48000|4608|
    |88200|8192|
    |96000|8192|
    
    说明
    
    单次编码输入的数据量（单位：字节）为：采样点数（SAMPLES_PER_FRAME） * 声道数 * 单个采样点的占用字节。
    
    flac编码的样点数建议参考表格根据采样率对应的样点数进行设置，否则可能出现编码文件损坏问题。
    
    1.  // 声道数。
    2.  constexpr int32_t DEFAULT_CHANNEL_COUNT = 2;
    3.  // 采样点数，这里以AAC-LC为例，采样点数为1024。
    4.  constexpr int32_t SAMPLES_PER_FRAME = 1024;
    5.  // 单次编码输入的数据量（单位：字节）为：采样点数 * 声道数 * 单个采样点的占用字节（以采样格式SAMPLE_S16LE为例）。
    6.  // 如果最后一帧数据不满足长度，建议进行丢弃或填充处理。
    7.  constexpr int32_t INPUT_FRAME_BYTES = SAMPLES_PER_FRAME * DEFAULT_CHANNEL_COUNT * sizeof(short);
    8.  uint32_t index = signal_->inQueue_.front();
    9.  auto buffer = signal_->inBufferQueue_.front();
    10.  OH_AVCodecBufferAttr attr = {0};
    11.  if (!inputFile_.eof()) {
    12.      inputFile_.read((char *)OH_AVBuffer_GetAddr(buffer), INPUT_FRAME_BYTES);
    13.      attr.size = INPUT_FRAME_BYTES;
    14.      attr.flags = AVCODEC_BUFFER_FLAGS_NONE;
    15.  } else {
    16.      attr.size = 0;
    17.      attr.flags = AVCODEC_BUFFER_FLAGS_EOS;
    18.  }
    19.  OH_AVBuffer_SetBufferAttr(buffer, &attr);
    20.  // 送入编码输入队列进行编码, index为对应队列下标。
    21.  int32_t ret = OH_AudioCodec_PushInputBuffer(audioEnc_, index);
    22.  if (ret != AV_ERR_OK) {
    23.      // 异常处理。
    24.  }
    
    在上方案例中，attr.flags代表缓冲区标记的类别。
    
    结束时需要将flags标识为AVCODEC_BUFFER_FLAGS_EOS。
    
    |枚举值|描述|
    |:--|:--|
    |AVCODEC_BUFFER_FLAGS_NONE|表示为普通帧。|
    |AVCODEC_BUFFER_FLAGS_EOS|表示缓冲区是流结束帧。|
    |AVCODEC_BUFFER_FLAGS_CODEC_DATA|表示缓冲区包含编解码特定数据。|
    
8. 调用OH_AudioCodec_FreeOutputBuffer()，释放编码后的数据。
    
    在取走编码码流后，就应及时调用OH_AudioCodec_FreeOutputBuffer()进行释放。
    
    1. uint32_t index = signal_->outQueue_.front();
    2. OH_AVBuffer *avBuffer = signal_->outBufferQueue_.front();
    3. if (avBuffer == nullptr) {
    4.     // 异常处理
    5. }
    6. // 获取buffer attributes。
    7. OH_AVCodecBufferAttr attr = {0};
    8. int32_t ret = OH_AVBuffer_GetBufferAttr(avBuffer, &attr);
    9. if (ret != AV_ERR_OK) {
    10.     // 异常处理。
    11. }
    12. // 将编码完成数据data写入到对应输出文件中。
    13. outFile_.write(reinterpret_cast<char *>(OH_AVBuffer_GetAddr(avBuffer)), attr.size);
    14. // 释放已完成写入的数据。
    15. ret = OH_AudioCodec_FreeOutputBuffer(audioEnc_, index);
    16. if (ret != AV_ERR_OK) {
    17.     // 异常处理。
    18. }
    19. if (attr.flags == AVCODEC_BUFFER_FLAGS_EOS) {
    20.     // 结束。
    21. }
    
9. （可选）调用OH_AudioCodec_Flush()刷新编码器。
    
    调用OH_AudioCodec_Flush()后，编码器处于Flush状态，会将当前编码队列清空。
    
    此时需要调用OH_AudioCodec_Start()重新开始编码。
    
    使用情况：
    
    - 在编码输出buffer属性为AVCODEC_BUFFER_FLAGS_EOS后，若想重新使用相同配置进行编码时，需要调用刷新。
    - 在执行过程中遇到可继续执行的错误时（即OH_AudioCodec_IsValid()为true）可以调用刷新，然后调用OH_AudioCodec_Start()重新开始编码。
    
    1. // 刷新编码器 audioEnc_。
    2. int32_t ret = OH_AudioCodec_Flush(audioEnc_);
    3. if (ret != AV_ERR_OK) {
    4.     // 异常处理。
    5. }
    6. // 重新开始编码。
    7. ret = OH_AudioCodec_Start(audioEnc_);
    8. if (ret != AV_ERR_OK) {
    9.     // 异常处理。
    10. }
    
10. （可选）调用OH_AudioCodec_Reset()重置编码器。
    
    调用OH_AudioCodec_Reset()后，编码器回到初始化状态，重置前获取到的输入/输出buffer都无法继续使用，需先调用OH_AudioCodec_Configure()重新配置，再调用OH_AudioCodec_Start()重新开始编码。启动后重新获取输入/输出buffer。
    
    1. // 重置编码器 audioEnc_。
    2. int32_t ret = OH_AudioCodec_Reset(audioEnc_);
    3. if (ret != AV_ERR_OK) {
    4.     // 异常处理。
    5. }
    6. // 重新配置编码器参数。
    7. ret = OH_AudioCodec_Configure(audioEnc_, format);
    8. if (ret != AV_ERR_OK) {
    9.     // 异常处理。
    10. }
    
11. 调用OH_AudioCodec_Stop()停止编码器。
    
    停止后，可以通过调用OH_AudioCodec_Start()重新进入已启动状态（started）。停止前获取到的输入/输出buffer都无法继续使用，需要在启动后重新获取输入/输出buffer。
    
    1. // 终止编码器 audioEnc_。
    2. int32_t ret = OH_AudioCodec_Stop(audioEnc_);
    3. if (ret != AV_ERR_OK) {
    4.     // 异常处理。
    5. }
    
12. 调用OH_AudioCodec_Destroy()销毁编码器实例，释放资源。
    
    说明
    
    禁止重复销毁编码器。
    
    1. // 调用OH_AudioCodec_Destroy, 销毁编码器。
    2. int32_t ret = OH_AudioCodec_Destroy(audioEnc_);
    3. if (ret != AV_ERR_OK) {
    4.     // 异常处理。
    5. } else {
    6.     audioEnc_ = NULL; // 不可重复destroy。
    7. }
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/obtain-supported-codecs "获取支持的编解码能力")
