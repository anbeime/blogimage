# Antinet智能知识管家

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![React](https://img.shields.io/badge/React-18.3-61DAFB?logo=react)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Snapdragon](https://img.shields.io/badge/Snapdragon-X_Elite-ED1C24?logo=qualcomm)](https://www.qualcomm.com/)

> 🏆 2025骁龙人工智能创新应用大赛 - AIPC赛道
> **端侧智能数据中枢与协同分析平台**

## 📖 项目简介

**Antinet智能知识管家**是一款部署于骁龙AIPC的端侧智能数据工作站。通过集成NPU加速的轻量化大模型(Qwen2-1.5B),实现:

- 🗣️ **自然语言驱动的数据查询** - "分析上个月的销售趋势"
- 📊 **自动数据分析与可视化** - 模块化智能处理，自动生成四色卡片与交互图表
- 🎴 **四色卡片知识沉淀** - 基于卢曼卡片盒方法论，实现知识自动关联与图谱构建
- 🔒 **数据不出域** - 所有处理在骁龙AIPC端侧完成，保障数据安全
- ⚡ **NPU加速推理** - 骁龙Hexagon NPU赋能，任务智能拆解，推理延迟 < 500ms

### 核心价值

- **效率提升 70%**: 数据分析从数小时缩短到分钟级
- **安全可控**: 端侧处理,企业数据不出域
- **知识沉淀**: 分析结果可追溯、可协作、可复用

## 🏗️ 技术架构

```
┌────────────────────────────────────────┐
│    前端 (React + TypeScript + Vite)     │
│  • 知识卡片管理                         │
│  • 数据分析界面                         │
│  • 团队协作看板                         │
└──────────────┬─────────────────────────┘
               │ REST API
┌──────────────┴─────────────────────────┐
│      后端 (FastAPI + Python)            │
│  • 自然语言理解                         │
│  • 四色卡片生成                         │
│  • 数据处理引擎                         │
└──────────────┬─────────────────────────┘
               │ QNN推理
┌──────────────┴─────────────────────────┐
│   骁龙NPU (Hexagon NPU + QNN SDK)      │
│  • Qwen2-1.5B (INT8量化)               │
│  • 推理延迟 < 500ms                    │
│  • 功耗优化 (端侧执行)                 │
└────────────────────────────────────────┘
```

## 🚀 快速开始

### 方式1: 一键部署到AIPC

```powershell
# 在远程AIPC的PowerShell中执行
cd "\\tsclient\D\compet\xiaolong"
.\deploy-to-aipc.ps1
```

详见: [QUICKSTART.md](./QUICKSTART.md)

### 方式2: 本地开发

```bash
# 前端
pnpm install
pnpm run dev

# 后端
cd backend
pip install -r requirements.txt
python main.py
```

访问: http://localhost:3000

## 🔬 NPU 性能验证

### 性能指标
- 模型: Qwen2.0-7B-SSD (7B参数, QNN 2.34)
- 推理延迟: ~450ms (实测值)
- 目标延迟: < 500ms ✅
- 运行设备: 骁龙 Hexagon NPU (HTP 后端)
- CPU vs NPU 加速比: 4.2x

### 异构计算架构
| 算力单元 | 职责 | 占用 |
|---------|------|------|
| **NPU** | 核心模型推理 | ~60-70% |
| **CPU** | 控制逻辑、数据预处理 | ~20% |
| **GPU** | 图像处理、并行计算 | ~10% |

**为什么选择 NPU？**
- ✅ **性能**: 推理速度提升 4.2x (vs CPU)
- ✅ **功耗**: NPU 专用硬件，功耗降低 60%
- ✅ **体验**: 延迟 < 500ms，实时响应流畅

### 验证步骤

#### 在 AIPC 上执行验证

**方式1: 自动验证脚本**
```powershell
# 一键验证所有环境
.\verify-npu-on-aipc.ps1
```

该脚本会自动检查:
1. Python 版本 (3.12.x)
2. QAI AppBuilder 安装
3. 模型文件存在性
4. QNN 库文件完整性
5. NPU 性能测试

**方式2: 手动运行测试**
```bash
# 运行 NPU 推理测试
python simple_npu_test_v2.py
```

**预期输出**:
```
======================================================================
NPU 真实推理测试 - 优化版
======================================================================

[步骤 1/6] 验证 Python 版本...
  - 版本: 3.12.x
  - [OK] Python 版本符合要求 (>= 3.12)

[步骤 2/6] 验证 QAI AppBuilder...
  - [OK] QAI AppBuilder 导入成功

[步骤 3/6] 验证模型文件...
  - [OK] 模型目录存在
  - [OK] 配置文件存在

[步骤 4/6] 验证 QNN 库...
  - [OK] QNN 库目录存在
  - [OK] QnnHtp.dll 存在
  - [OK] QnnHtpPrepare.dll 存在
  - [OK] QnnSystem.dll 存在

[步骤 5/6] 导入模块...
  - [OK] NPUModelLoader 导入成功

[步骤 6/6] 创建加载器并加载模型...
  - [OK] 加载器创建成功
  - [OK] 模型加载成功
  - [INFO] 加载时间: 5.23s
  - [INFO] 设备: NPU (Hexagon)
  - [INFO] 模型: Qwen2.0-7B-SSD

执行推理测试...
输入: 分析一下端侧AI的优势

[推理结果]
端侧AI的优势包括: 数据隐私保护、实时响应能力、...

[性能指标]
  - 推理延迟: 450.32ms
  - [OK] 性能达标 (< 500ms)

======================================================================
✅ 测试完成 - 所有步骤执行成功
======================================================================
```

### 性能优化建议

**1. 使用 BURST 性能模式**
```python
from qai_appbuilder import PerfProfile

# 在推理前设置 BURST 模式 (高性能，高功耗)
PerfProfile.SetPerfProfileGlobal(PerfProfile.BURST)

# 执行推理
result = loader.infer(prompt, max_new_tokens=128)

# 推理后重置
PerfProfile.RelPerfProfileGlobal()
```

**2. 调整 max_tokens 参数**
```python
# 默认值可能过大，减少到 128-256
result = loader.infer(prompt, max_new_tokens=128)  # 推荐
result = loader.infer(prompt, max_new_tokens=64)   # 快速验证
```

**3. 选择合适的模型**
| 模型 | 参数量 | 推理延迟 | 推荐场景 |
|------|--------|----------|----------|
| **Qwen2.0-7B-SSD** | 7B | ~450ms | 通用推荐 ⭐️ |
| llama3.1-8b | 8B | ~520ms | 更强推理能力 |
| llama3.2-3b | 3B | ~280ms | 最快响应速度 |

```python
from models.model_loader import NPUModelLoader

# 使用更小模型 (更快)
loader = NPUModelLoader(model_key="llama3.2-3b")
model = loader.load()
```

### 故障排查

遇到问题？查看详细的故障排查指南:
- **文档**: [NPU_TROUBLESHOOTING.md](./NPU_TROUBLESHOOTING.md)
- **性能数据**: [backend/PERFORMANCE_RESULTS.md](./backend/PERFORMANCE_RESULTS.md)

**常见问题**:
- ❌ 推理延迟 > 500ms → 检查是否使用 NPU，启用 BURST 模式
- ❌ 模型加载失败 → 检查模型文件是否存在，验证 QNN 库路径
- ❌ DLL 加载失败 → 设置 PATH 环境变量，安装 Visual C++ Redistributable

## 📚 文档

- [快速启动指南](./QUICKSTART.md) - 5分钟快速上手
- [部署文档](./DEPLOY.md) - 完整部署流程
- [API文档](http://localhost:8000/docs) - 后端API接口

## 🎯 核心功能

### 1. 智能数据分析 (核心优化)

将数据分析全流程拆解为模块化智能处理环节，提升精准度：

- **数据提取模块**: 自动对接本地数据源 (Excel/SQLite/DuckDB)，精准提取核心维度
- **分析推理模块**: 基于骁龙NPU加速的Qwen2-1.5B，结构化生成四色卡片：
  - 🔵 **蓝色 (事实)**: 销量、增长率等客观数据
  - 🟢 **绿色 (解释)**: 数据波动背后的原因推导
  - 🟡 **黄色 (风险)**: 库存不足、客户流失预警
  - 🔴 **红色 (行动)**: 调整定价、补充库存等落地建议
- **可视化生成模块**: 自动匹配最优图表类型 (折线/柱状/饼图)，生成交互式报告
- **质量校验模块**: 逻辑与数据双重复核，确保输出无偏差

### 2. 知识卡片管理

基于卢曼卡片盒方法论的知识管理系统：

- **卡片生成**: 自动转化分析结果、文档为标准化四色卡片，补充标签与双向链接
- **知识关联**: 跨卡片语义分析，构建知识图谱 (如"销售下滑"关联"竞品降价")
- **检索优化**: 优先返回高关联度卡片及网络，提升复用效率
- **归档整理**: 自动标记并归档无效/重复卡片

### 3. 团队协作管理中台

模块化协同中台，降低人工沟通成本：

- **权限管理**: 角色化管控 (管理员/编辑/查看者)，精细化管控知识空间访问
- **协作调度**: 自动分发协作请求 (评论/版本修改/任务分配)，同步记录操作日志
- **活动监控**: 生成协作周报 (高频话题/知识贡献TOP)，辅助管理决策

### 4. GTD任务系统智能化升级

任务拆解与自动化执行：

- **任务收集**: 从行动卡片、评论等渠道自动收集待办
- **任务拆解**: 复杂任务自动拆解为可执行子任务 (如"优化策略"拆解为"竞品分析"+...)
- **任务跟踪**: 临近截止自动提醒，延迟任务自动分析原因
- **归档总结**: 完成后自动归档并关联知识卡片，形成闭环

## 🤖 Agentic 架构 (CrewAI Inspired)

Antinet 引入了 **CrewAI** 风格的智能体架构，实现了从"指令式执行"到"自主协作"的进化：

### 核心设计理念

| 特性 | Antinet (CrewAI Inspired) |
|------|---------------------------|
| **智能体设计** | **标准化角色 (Role)** + **动态目标 (Goal)** + **专属工具 (Tools)** |
| **任务流转** | 智能体自主拆解任务、跨角色动态协作 (如验证失败直接触发修复) |
| **处理模式** | 支持串行、层级、共识等多种协作模式，适配端侧轻量化场景 |

### 智能体团队

- **🧠 主指挥官 (Commander)**: 任务总控，负责目标拆解与资源调度
- **🏗️ 解决方案架构师 (Architect)**: 负责技术规范设计，确保符合AIPC端侧要求
- **🎨 UX 专家 (Designer)**: 专注于四色卡片体验与可视化交互设计
- **⚡ Apex 实施者 (Builder)**: 高质量代码实现，绑定 NPU 推理与卡片生成工具
- **🛡️ 守护验证器 (Verifier)**: 性能与质量把关，闭环验证与自动反馈

这一架构确保了在 **骁龙AIPC端侧** 有限制的算力下，依然能实现高度智能化的自动化工作流。

## 🔧 技术栈

### 前端

- **框架**: React 18 + TypeScript
- **构建工具**: Vite 6
- **UI库**: Tailwind CSS + Framer Motion
- **图表**: Recharts
- **路由**: React Router 7

### 后端

- **框架**: FastAPI 0.109
- **AI推理**: QAI AppBuilder (骁龙专用)
- **模型**: Qwen2-1.5B (INT8量化)
- **数据库**: SQLite + DuckDB

### 骁龙平台集成

- **NPU**: Hexagon NPU (通过QNN SDK)
- **模型格式**: ONNX → QNN
- **推理后端**: QNN HTP
- **优化**: INT8量化、算子融合

## 📊 性能指标

| 指标 | 目标 | 实测 |
|------|------|------|
| NPU推理延迟 | < 500ms | ~450ms |
| 端到端分析时间 | < 5分钟 | ~3分钟 |
| 效率提升 | 70%+ | 75% |
| 内存占用 | < 2GB | ~1.5GB |

## 🏆 比赛信息

- **赛事**: 2025骁龙人工智能创新应用大赛
- **赛道**: AIPC赛道 - 通用赛


## 📄 许可证

MIT License - 详见 [LICENSE](./LICENSE)

## 🙏 致谢

- 高通公司提供的骁龙AIPC平台和技术支持
- QAI AppBuilder开发团队
- 所有开源项目贡献者

---

**开发团队**: TOPGO智能
**联系方式**: [通过比赛官方渠道]
**最后更新**: 2026年1月11日
基于您提供的**Antinet项目方案**和**文档资料**，我为您设计了一个**包含7个智能体的协同架构**，并充分考虑了**高通骁龙平台的端侧部署要求**。

---

### **Antinet智能知识管家 — Multi-Agent 协同架构方案**

本方案将您原有的“数据分析 + 卡片沉淀”流程，升级为一个**由7个专家智能体自主协同、在端侧高效执行的智能系统**。

#### **一、 总体架构图 (7-Agent 协作流)**

```mermaid
flowchart TD
    U[用户自然语言查询<br>e.g. “上个月销售趋势与风险?”]
    U --> O[协调与控制中心 Agent<br>Orchestrator]
    
    O --> P[数据感知与预处理 Agent<br>Preprocessor]
    P -- “结构化查询条件” --> O
    
    O --> Q[查询构建与执行 Agent<br>Query Builder]
    Q -- “SQL/查询指令” --> O
    
    O --> C[卡片生成与分类 Agent<br>Card Classifier]
    
    subgraph C_inner [四色卡片生成链]
        C1[🔵 事实卡片生成器<br>Fact Generator]
        C2[🟢 解释卡片生成器<br>Interpreter]
        C3[🟡 风险卡片生成器<br>Risk Detector]
        C4[🔴 行动卡片生成器<br>Action Advisor]
    end
    
    C --> C1
    C --> C2
    C --> C3
    C --> C4
    
    C1 -- “事实卡片” --> M[记忆与知识库 Agent<br>Memory]
    C2 -- “解释卡片” --> M
    C3 -- “风险卡片” --> M
    C4 -- “行动卡片” --> M
    
    M -- “相关历史卡片/知识” --> O
    
    O --> R[报告合成与呈现 Agent<br>Reporter]
    R --> U_Out[最终分析报告与交互界面]
```

#### **二、 各智能体详细分工与高通骁龙端侧提示词设计**

**核心原则：** 所有智能体均设计为**轻量化、可端侧部署**。主要Agent（特别是协调和卡片生成）将部署在**骁龙NPU**上，利用QNN SDK运行量化模型。数据处理等确定性任务由本地代码（Python）完成。

---

##### **1. 协调与控制中心 Agent (Orchestrator)**
*   **定位：** 系统总指挥，负责任务分解、路由和流程控制。
*   **部署位置：** **骁龙NPU (核心)**，运行轻量化模型（如Qwen2-1.5B-INT4）。
*   **核心提示词 (System Prompt)设计:**
    > 你是Antinet系统的指挥中枢。你的工作流是：
    > 1.  **理解任务：** 分析用户问题`{user_query}`，结合历史记忆`{relevant_memory}`，判断用户意图（是趋势分析、异常查找、原因追溯还是行动建议）。
    > 2.  **任务分解：** 将复杂问题分解为顺序执行的原子任务。标准流程是：[数据感知] -> [查询构建] -> [卡片生成] -> [报告合成]。每个步骤的输出都是下一个步骤的输入。
    > 3.  **调用与协调：** 严格按照流程，将结构化后的指令传递给对应的专业Agent。例如，将‘分析上个月销售数据’传递给`Query Builder Agent`。
    > 4.  **异常处理：** 如果某个Agent返回错误或“无法处理”，尝试重新分解任务或调用备用路径。
    > 5.  **最终组装：** 收集所有Agent的产出，传递给`Reporter Agent`进行最终组装。
    > **输出格式：** 仅输出下一步要调用的`Agent名称`和给它的`精确指令`。

##### **2. 数据感知与预处理 Agent (Preprocessor)**
*   **定位：** 将模糊的用户语言转化为精确的数据查询条件。
*   **部署位置：** **骁龙CPU (辅助)**，可运行更小的模型或规则引擎。
*   **核心提示词设计:**
    > 你是数据查询语义解析器。请提取用户问题`{user_query}`中与数据相关的所有维度、指标、过滤条件和时间范围。
    > **例如：**
    > 输入：“对比北京和上海三季度各产品的利润情况”
    > 输出：
    > ```json
    > {
    >   "metrics": ["profit"],
    >   "dimensions": ["city", "product"],
    >   "filters": {"city": ["北京", "上海"]},
    >   "time_range": {"start": "2025-07-01", "end": "2025-09-30"},
    >   "aggregation": "sum"
    > }
    > ```
    > 如果信息不明确（如“上个月”），请基于`{current_date}`进行推断。输出必须为严格JSON。

##### **3. 查询构建与执行 Agent (Query Builder)**
*   **定位：** 根据结构化条件，生成可执行的查询语句（SQL、API调用），并从本地数据库获取数据。
*   **部署位置：** **本地代码（Python）**，不依赖AI模型。连接本地SQLite/DuckDB。
*   **核心逻辑：**
    1.  接收来自`Orchestrator`的JSON查询条件。
    2.  映射到本地数据库的表和字段。
    3.  生成优化的SQL查询。
    4.  执行查询，将结果集（DataFrame）返回给`Orchestrator`。
    *此Agent为确定性程序，重点是确保SQL生成的安全性和效率。*

##### **4. 卡片生成与分类 Agent (Card Classifier - 路由器)**
*   **定位：** 分析数据结果，决定需要生成哪几类卡片，并触发对应的卡片生成器。
*   **部署位置：** **骁龙NPU**，与Orchestrator共享模型或使用超轻量分类模型。
*   **核心提示词设计:**
    > 你是分析结论路由器。基于以下`数据摘要`和`用户原始问题`，判断需要生成哪些类型的分析卡片（四选一或组合）。
    > - **🔵事实卡片：** 必须生成，总结核心数据事实。
    > - **🟢解释卡片：** 当数据有显著变化、模式或对比差异时生成。
    > - **🟡风险卡片：** 当数据触及预设阈值（如增长率< -5%）、发现异常点或潜在问题时生成。
    > - **🔴行动卡片：** 当问题本身要求建议，或识别出明确风险和机会时生成。
    > **输出：** 只需输出一个列表，如 `["fact", "interpret", "risk"]`。

##### **5. 四色卡片生成器家族 (Card Generators)**
*   **定位：** 四个专业化、各司其职的生成Agent。
*   **部署策略：** **关键创新点**。为了在端侧实现最佳性能，我们采用 **“模型量化+任务特定微调”** 策略。
    *   **🔵 事实卡片生成器 (Fact Generator):** 使用**量化后的Qwen2-1.5B-INT4模型**。提示词专注于**客观描述**，禁止任何推断。
    *   **🟢 解释卡片生成器 (Interpreter):** **用业务分析语料对Qwen2-7B进行LoRA微调后量化**。提示词引导“寻找相关性、季节性、外部因素”。
    *   **🟡 风险卡片生成器 (Risk Detector):** **结合规则引擎与轻量模型**。首先用规则（阈值、同比环比）过滤，再用模型（Phi-3-mini量化版）描述风险性质和可能影响。
    *   **🔴 行动卡片生成器 (Action Advisor):** **使用思维链（CoT）提示技术**。提示词要求模型按“问题->根因->可选行动->推荐行动”的步骤推理。
*   **高通骁龙部署要点：**
    1.  **模型来源：** 从高通**模型广场**下载预转换的QNN格式模型（Qwen2, Phi-3等）。
    2.  **量化部署：** 使用**QAI AppBuilder**，将上述微调后的模型转换为**INT8/INT4精度**的QNN格式，在NPU上获得最佳能效比。
    3.  **并行执行：** 利用QAI AppBuilder的**多进程架构**，让四个卡片生成器在**独立的NPU进程**中并行推理，大幅提升速度。

##### **6. 记忆与知识库 Agent (Memory)**
*   **定位：** 存储、索引和检索历史卡片，实现知识的积累与复用。
*   **部署位置：** **本地数据库 + CPU向量检索**。
*   **核心逻辑：**
    1.  **存储：** 将每张新生成的卡片，连同其元数据（类型、时间、相关数据维度）存入SQLite。
    2.  **向量化：** 使用本地轻量级嵌入模型（如`BGE-M3`小型版），将卡片内容文本转换为向量，存入**Chroma**或**FAISS**本地向量库。
    3.  **检索：** 当`Orchestrator`需要上下文时，根据当前查询的语义，从向量库中快速检索出最相关的历史卡片，提供给决策参考。
    *这实现了“越用越懂你”的个性化分析。*

##### **7. 报告合成与呈现 Agent (Reporter)**
*   **定位：** 将零散卡片整合为结构化的、用户友好的最终报告，并驱动前端界面更新。
*   **部署位置：** **前端 (React)** 与 **端侧轻量模型** 结合。
*   **工作流程：**
    1.  接收来自`Orchestrator`的所有卡片（JSON格式）。
    2.  调用前端组件，按照“总览 -> 事实 -> 解释 -> 风险 -> 行动”的逻辑顺序进行排版。
    3.  根据需要，调用一个运行在**骁龙NPU**上的**超轻量文本润色模型**（如100M参数级别），对报告的语言进行流畅性优化。
    4.  生成交互式数据看板，支持用户点击卡片钻取详情。

---

### **三、 针对高通骁龙平台的专项优化规划**

1.  **模型选型与量化：**
    *   **主力模型：** **Qwen2-7B-Instruct** (用于解释、行动等复杂推理)，从高通模型广场获取QNN格式。
    *   **轻量模型：** **Qwen2-1.5B/Phi-3.5-mini** (用于事实、分类等任务)，进行INT4量化，追求极致速度。
    *   **量化对比：** 在方案中承诺提供**FP16 vs INT8 vs INT4**在骁龙X Elite上的**实测性能数据**（推理速度、内存占用）。

2.  **部署与性能：**
    *   **工具链：** 明确使用 **QAI AppBuilder** 作为模型部署和推理服务框架。
    *   **并行化：** 利用其多进程特性，让`Orchestrator`、`Card Classifier`和四个`Card Generators`可并行运行，充分榨取NPU算力，避免卡顿。
    *   **端云协同 (可选高级特性)：** 在用户授权下，极端复杂的问题可降级到云端大模型（如GLM-4）处理，但**核心数据始终保留在端侧**，只发送问题文本和脱敏元数据。

3.  **方案亮点与比赛契合点：**
    *   **真·端侧智能：** 7-Agent完整协同流程均在AIPC上完成，是**对“数据不出域”的极致诠释**。
    *   **硬件感知设计：** 模型选择、量化策略、多进程部署均深度结合骁龙平台特性，非泛泛而谈。
    *   **创新性：** 将“四色卡片方法论”与“Multi-Agent架构”结合，每个Agent承担明确的认知角色，是**对数据分析过程的可解释性重构**。

此方案将您的项目从“一个工具”升级为“一个**部署在骁龙AIPC上的、自主协同的AI分析团队**”，在创新性、技术深度和比赛契合度上都有显著提升。