# IPC Kit简介

更新时间: 2025-12-16 16:38

## 基本概念

| 缩写     | 全称                          | 中文描述   | 说明                   |
| :----- | :-------------------------- | :----- | :------------------- |
| IPC    | Inter Process Communication | 进程间通信  | 指设备内的进程间通信。          |
| RPC    | Remote Procedure Call       | 远程过程调用 | 指设备间的进程间通信。          |
| Client | Client                      | 客户端    | 请求服务的一端，称为代理（Proxy）。 |
| Server | Server                      | 服务端    | 提供服务的一端，称为Stub。      |

说明

- 使用IPC和RPC进行跨进程通信时，需要先调用元能力的连接服务接口获取Proxy对象。IPC和RPC的典型使用场景包括：
    
- IPC典型使用场景是后台服务，后台服务通过IPC机制提供单设备跨进程接口调用与数据传递能力。
    
- RPC典型使用场景是多端协同，多端协同通过RPC机制提供跨设备远端接口调用与数据传递能力。
    

## 实现原理

IPC和RPC用于实现跨进程通信。IPC使用Binder驱动，适用于设备内的跨进程通信；RPC使用软总线驱动，适用于跨设备的跨进程通信。每个进程拥有独立的资源和内存空间，其他进程无法直接访问，因此需要使用IPC和RPC实现跨进程通信。

IPC和RPC采用客户端-服务端（Client-Server）模型。在使用时，Client进程可以获取Server进程的代理（Proxy），通过Proxy读写数据和发起请求，Stub处理请求并应答结果，实现进程间通信。Proxy和Stub提供了一组由服务/业务自定义的接口，Proxy实现每一个具体的请求方法，Stub实现对应的每一个具体请求的处理方法以及应答数据的内容。

## 约束与限制

- 单个设备上跨进程通信时，传输的数据量最大为200KB。超过200KB的数据量传输可以使用[匿名共享内存](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#ashmem8)。
    
- 不支持在RPC中订阅匿名Stub对象（没有向SAMgr注册的Stub对象）的[死亡通知](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/subscribe-remote-state)。
    
- 不支持把跨设备的Proxy对象回传到该Proxy对象指向的Stub对象所在的设备。
    
- 指向远端设备Stub的Proxy对象不能在本设备内二次跨进程传递。
    

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/ipc-kit "IPC Kit（进程间通信服务）")
# IPC与RPC通信开发指导(ArkTS)

更新时间: 2025-12-16 16:38

## 场景介绍

IPC/RPC的主要工作是跨进程建立对象通信的连接（客户端进程的Proxy和服务端进程的Stub建立一一对应关系），从而通过Proxy的接口可以和Stub进行IPC/RPC通信。

## 开发步骤

### 客户端连接服务，获取服务代理对象Proxy

**创建变量want和connect**

1. 创建变量want，指定要连接的Ability所在应用的包名、组件名。在跨设备的场景下，还需要连接目标设备的NetworkId（组网场景下对应设备的标识符，可以使用distributedDeviceManager获取目标设备的NetworkId）。
    
2. 创建变量connect，指定连接成功、连接失败和断开连接时的回调函数。
    
    在IPC场景中，创建变量want和connect。
    
    1. import { Want, common } from '@kit.AbilityKit';
    2. import { rpc } from '@kit.IPCKit';
    3. import { hilog } from '@kit.PerformanceAnalysisKit';
    
    4. let proxy: rpc.IRemoteObject | undefined;
    
    5. let want: Want = {
    6.   // 包名和组件名写实际的值
    7.   bundleName: "ohos.rpc.test.server",
    8.   abilityName: "ohos.rpc.test.server.ServiceAbility",
    9. };
    10. let connect: common.ConnectOptions = {
    11.   onConnect: (elementName, remoteProxy) => {
    12.     hilog.info(0x0000, 'testTag', 'RpcClient: js onConnect called');
    13.     proxy = remoteProxy;
    14.   },
    15.   onDisconnect: (elementName) => {
    16.     hilog.info(0x0000, 'testTag', 'RpcClient: onDisconnect');
    17.   },
    18.   onFailed: () => {
    19.     hilog.info(0x0000, 'testTag', 'RpcClient: onFailed');
    20.   }
    21. };
    
    在RPC场景中，创建变量want和connect。
    
    22. import { Want, common } from '@kit.AbilityKit';
    23. import { rpc } from '@kit.IPCKit';
    24. import { hilog } from '@kit.PerformanceAnalysisKit';
    25. import { distributedDeviceManager } from '@kit.DistributedServiceKit';
    26. import { BusinessError } from '@kit.BasicServicesKit';
    
    27. let dmInstance: distributedDeviceManager.DeviceManager | undefined;
    28. let proxy: rpc.IRemoteObject | undefined;
    29. let deviceList: Array<distributedDeviceManager.DeviceBasicInfo> | undefined;
    30. let networkId: string | undefined;
    31. let want: Want | undefined;
    32. let connect: common.ConnectOptions | undefined;
    
    33. try{
    34.   dmInstance = distributedDeviceManager.createDeviceManager("ohos.rpc.test");
    35. } catch (error) {
    36.   let err: BusinessError = error as BusinessError;
    37.   hilog.error(0x0000, 'testTag', 'createDeviceManager errCode:' + err.code + ', errMessage:' + err.message);
    38. }
    
    39. // 使用distributedDeviceManager获取目标设备NetworkId
    40. if (dmInstance != undefined) {
    41.   try {
    42.     deviceList = dmInstance.getAvailableDeviceListSync();
    43.     if (deviceList.length !== 0) {
    44.       networkId = deviceList[0].networkId;
    45.       want = {
    46.         bundleName: "ohos.rpc.test.server",
    47.         abilityName: "ohos.rpc.test.service.ServiceAbility",
    48.         deviceId: networkId,
    49.       };
    50.       connect = {
    51.         onConnect: (elementName, remoteProxy) => {
    52.           hilog.info(0x0000, 'testTag', 'RpcClient: js onConnect called');
    53.           proxy = remoteProxy;
    54.         },
    55.         onDisconnect: (elementName) => {
    56.           hilog.info(0x0000, 'testTag', 'RpcClient: onDisconnect');
    57.         },
    58.         onFailed: () => {
    59.           hilog.info(0x0000, 'testTag', 'RpcClient: onFailed');
    60.         }
    61.       };
    62.     }
    63.   } catch (error) {
    64.     let err: BusinessError = error as BusinessError;
    65.     hilog.error(0x0000, 'testTag', 'createDeviceManager err:' + err);
    66.   }
    67. }
    

**连接服务**

FA模型使用[connectAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-ability-featureability#featureabilityconnectability7)接口连接Ability。

1. import { featureAbility } from '@kit.AbilityKit';

2. // 建立连接后返回的Id需要保存下来，在解绑服务时需要作为参数传入
3. let connectId = featureAbility.connectAbility(want, connect);

Stage模型使用common.UIAbilityContext的[connectServiceExtensionAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-inner-application-uiabilitycontext#connectserviceextensionability)接口连接Ability。

在本文档的示例中，通过this.getUIContext().getHostContext()来获取UIAbilityContext，其中this代表继承自UIAbility的UIAbility实例。如需要在页面中使用UIAbilityContext提供的能力，请参见[获取UIAbility的上下文信息](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/uiability-usage#%E8%8E%B7%E5%8F%96uiability%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF)。

1. let context: common.UIAbilityContext = this.getUIContext().getHostContext(); // UIAbilityContext
2. // 建立连接后返回的Id需要保存下来，在解绑服务时需要作为参数传入
3. let connectId = context.connectServiceExtensionAbility(want, connect);

### 客户端发送信息给服务端

成功连接服务后，可以通过onConnect回调函数获取服务端的代理对象Proxy。然后，使用该Proxy调用[sendMessageRequest](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#sendmessagerequest9-2)方法发起请求。当服务端处理请求并返回数据时，可在Promise契约（用于表示一个异步操作的成功/失败的结果值）中接收结果。

1. import { rpc } from '@kit.IPCKit';
2. import { hilog } from '@kit.PerformanceAnalysisKit';

3. // 此示例代码段中的proxy是在与服务端连接成功后的onConnect回调里拿到的proxy
4. let proxy: rpc.IRemoteObject | undefined;

5. // 使用Promise契约
6. let option = new rpc.MessageOption();
7. let data = rpc.MessageSequence.create();
8. let reply = rpc.MessageSequence.create();
9. // 在data里写入参数，以传递字符串为例
10. data.writeString("hello world");

11. if (proxy != undefined) {
12.   proxy.sendMessageRequest(1, data, reply, option)
13.     .then((result: rpc.RequestResult) => {
14.       if (result.errCode != 0) {
15.         hilog.error(0x0000, 'testTag', 'sendMessageRequest failed, errCode: ' + result.errCode);
16.         return;
17.       }
18.       // 从result.reply里读取结果
19.       // 此处是根据前面创建ServiceExtensionAbility，实现服务端做的示例
20.       result.reply.readString();
21.     })
22.     .catch((e: Error) => {
23.       hilog.error(0x0000, 'testTag', 'sendMessageRequest got exception: ' + e);
24.     })
25.     .finally(() => {
26.       data.reclaim();
27.       reply.reclaim();
28.     })
29. }

### 服务端处理客户端请求

服务端在onConnect回调函数里返回继承自[rpc.RemoteObject](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#remoteobject)的Stub对象，该对象需要实现[onRemoteMessageRequest](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#onremotemessagerequest9)方法，处理客户端的请求。

1. import { rpc } from '@kit.IPCKit';
2. import { hilog } from '@kit.PerformanceAnalysisKit';

3. class Stub extends rpc.RemoteObject {
4.   constructor(descriptor: string) {
5.     super(descriptor);
6.   }
7.   onRemoteMessageRequest(code: number, data: rpc.MessageSequence, reply: rpc.MessageSequence,
8.     option: rpc.MessageOption): boolean | Promise<boolean> {
9.     // 服务端Stub根据不同的请求code分别执行对应的处理流程
10.     if (code == 1) {
11.       let str = data.readString();
12.       hilog.info(0x0000, 'testTag', 'stub receive str : ' + str);
13.       // 服务端使用reply回传请求处理的结果给客户端
14.       reply.writeString("hello rpc");
15.       return true;
16.     } else {
17.         hilog.info(0x0000, 'testTag', 'stub unknown code: ' + code);
18.         return false;
19.     }
20.   }
21. }

### 断开连接

IPC通信结束后，FA模型使用[disconnectAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-ability-featureability#featureabilitydisconnectability7)接口断开连接，此处的connectId是在连接服务时保存的。

1. import { featureAbility } from "@kit.AbilityKit";
2. import { hilog } from '@kit.PerformanceAnalysisKit';

3. function disconnectCallback() {
4.   hilog.info(0x0000, 'testTag', 'disconnect ability done');
5. }
6. // 断开连接，使用连接服务成功时保存下来的connectId断开连接
7. featureAbility.disconnectAbility(connectId, disconnectCallback);

Stage模型使用common.UIAbilityContext提供的[disconnectServiceExtensionAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-inner-application-uiabilitycontext#disconnectserviceextensionability-1)接口断开连接，此处的connectId是在连接服务时保存的。

在本文档的示例中，通过this.getUIContext().getHostContext()来获取UIAbilityContext，其中this代表继承自UIAbility的UIAbility实例。如需要在页面中使用UIAbilityContext提供的能力，请参见[获取UIAbility的上下文信息](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/uiability-usage#%E8%8E%B7%E5%8F%96uiability%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF)。

1. let context: common.UIAbilityContext = this.getUIContext().getHostContext(); // UIAbilityContext

2. // 断开连接，使用连接服务成功时保存下来的connectId断开连接
3. context.disconnectServiceExtensionAbility(connectId);

## 完整示例

针对IPC与RPC通信开发，端到端的完整示例，请参考：

- [IPC通信完整样例-使用Parcelable/ArrayBuffer通信](https://gitcode.com/openharmony/applications_app_samples/tree/master/code/SystemFeature/IPC/ObjectTransfer)

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/ipc-rpc-overview "IPC Kit简介")
# IPC与RPC通信开发指导(C/C++)

更新时间: 2025-12-16 16:38

## 场景介绍

IPC让运行在不同进程间的Proxy和Stub实现互相通信。IPC CAPI是IPC Kit提供的C语言接口。

IPC CAPI接口不直接提供获取通信代理对象的能力，该功能由[Ability Kit](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/abilitykit-overview)提供。

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtyPub/011/111/111/0000000000011111111.20251216163820.10041692961835914949048347759596:50001231000000:2800:6D230BF5A75592FC3900A5DF596A8EFE84314DCED037A71A59C0C64DBE75DF2B.png)

进程间IPC通道的建立，请参考[Native子进程开发指导（C/C++）](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/capi_nativechildprocess_development_guideline)。本文重点介绍IPC CAPI的使用。

## 接口说明

**表1** IPC CAPI侧关键接口

|接口名|描述|
|:--|:--|
|typedef int (*OH_OnRemoteRequestCallback)<br><br>(uint32_t code, const OHIPCParcel *data, OHIPCParcel *reply,<br><br>void *userData);|Stub端用于处理远端数据请求的回调函数。|
|OHIPCRemoteStub* OH_IPCRemoteStub_Create<br><br>(const char *descriptor, OH_OnRemoteRequestCallback requestCallback,<br><br>OH_OnRemoteDestroyCallback destroyCallback, void *userData);|创建OHIPCRemoteStub对象。|
|int OH_IPCRemoteProxy_SendRequest(const OHIPCRemoteProxy *proxy,<br><br>uint32_t code, const OHIPCParcel *data, OHIPCParcel *reply,<br><br>const OH_IPC_MessageOption *option);|IPC消息发送函数。|
|struct OHIPCRemoteProxy;|用于向远端发送请求的OHIPCRemoteProxy对象，需要依赖元能力接口返回。|
|OHIPCDeathRecipient* OH_IPCDeathRecipient_Create<br><br>(OH_OnDeathRecipientCallback deathRecipientCallback,<br><br>OH_OnDeathRecipientDestroyCallback destroyCallback,<br><br>void *userData);|创建用于监听远端OHIPCRemoteStub对象死亡的通知对象（OHIPCDeathRecipient对象）。|
|int OH_IPCRemoteProxy_AddDeathRecipient(OHIPCRemoteProxy *proxy,<br><br>OHIPCDeathRecipient *recipient);|向OHIPCRemoteProxy对象注册死亡监听，用于接收远端OHIPCRemoteStub对象死亡时的回调通知。|

详细的接口说明请参考[IPCKit](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/capi-ipckit)。

## 开发步骤

先创建服务端Stub对象，通过元能力获取其客户端代理Proxy对象，然后用Proxy对象与服务端Stub对象进行IPC通信，同时再注册远端对象的死亡通知回调，用于Proxy侧感知服务端Stub对象所在进程的死亡状态。

### 添加动态链接库

CMakeLists.txt中添加以下lib。

1. # ipc capi
2. libipc_capi.so
3. # 元能力，ability capi
4. libchild_process.so

### 头文件

1. // ipc capi
2. #include <IPCKit/ipc_kit.h>
3. // 元能力，ability capi。
4. #include <AbilityKit/native_child_process.h>

### 异步调用场景

**公共数据及函数定义**

1. #include <string>
2. #include <thread>
3. #include <mutex>
4. #include <chrono>
5. #include <condition_variable>
6. #include <IPCKit/ipc_kit.h>
7. #include <AbilityKit/native_child_process.h>
8. #include <hilog/log.h>
9. #undef LOG_DOMAIN
10. #undef LOG_TAG
11. #define LOG_DOMAIN 0x0201
12. #define LOG_TAG "IPCCApiSample"

13. enum RequestCode {
14.     ASYNC_ADD_CODE = 1,
15.     REQUEST_EXIT_CODE = 2,
16.     OTHER_CODE
17. };
18. static constexpr int MAX_MEMORY_SIZE = 204800;
19. static const std::string INTERFACE_DESCRIPTOR = "INTERFACE_DESCRIPTOR";
20. static const std::string NATIVE_REMOTE_STUB_TEST_TOKEN = "native.remote.stub";
21. static const std::string NATIVE_REMOTE_STUB_ASYNC_CALL_TEST_TOKEN = "native.remote.stub.async.call";

22. // 定义内存分配函数。
23. static void* LocalMemoryAllocator(int32_t len) {
24.     if (len < 0 || len > MAX_MEMORY_SIZE ) {
25.         return nullptr;
26.     }
27.     void *buffer = malloc(len);
28.     if (buffer == nullptr) {
29.         return nullptr;
30.     }
31.     memset(buffer, 0, len);
32.     return buffer;
33. }

**服务端对象: IpcCApiStubTest**

1. class IpcCApiStubTest {
2. public:
3.     explicit IpcCApiStubTest();
4.     ~IpcCApiStubTest();
5.     void MainProc();
6.     OHIPCRemoteStub* GetRemoteStub();
7.     static int OnRemoteRequest(uint32_t code, const OHIPCParcel *data, OHIPCParcel *reply, void *userData);
8. private:
9.     int AsyncAdd(const OHIPCParcel *data);
10.     int RequestExitChildProcess();
11. private:
12.     OHIPCRemoteStub *stub_{ nullptr };
13.     std::mutex childMutex_;
14.     std::condition_variable childCondVar_;
15. };

16. IpcCApiStubTest::IpcCApiStubTest() {
17.     // 创建stub对象。
18.     stub_ = OH_IPCRemoteStub_Create(INTERFACE_DESCRIPTOR.c_str(), &IpcCApiStubTest::OnRemoteRequest,
19.         nullptr, this);
20. }

21. IpcCApiStubTest::~IpcCApiStubTest() {
22.     if (stub_ != nullptr) {
23.         // 当stub对象不再使用时，销毁该对象。
24.         OH_IPCRemoteStub_Destroy(stub_);
25.     }
26. }

27. void IpcCApiStubTest::MainProc() {
28.     std::unique_lock<std::mutex> autoLock(childMutex_);
29.     childCondVar_.wait(autoLock);
30. }

31. OHIPCRemoteStub* IpcCApiStubTest::GetRemoteStub() {
32.     return stub_;
33. }

34. // 服务端的请求处理函数，客户端发送的请求在该函数中处理。
35. int IpcCApiStubTest::OnRemoteRequest(uint32_t code, const OHIPCParcel *data, OHIPCParcel *reply, void *userData) {
36.     int readLen = 0;
37.     char *token = nullptr;
38.     // 根据客户端传过来的interfaceToken校验当前通信是否合法。
39.     if (OH_IPCParcel_ReadInterfaceToken(data, &token, &readLen, LocalMemoryAllocator) != OH_IPC_SUCCESS
40.         || NATIVE_REMOTE_STUB_TEST_TOKEN != token) {
41.         if (token != nullptr) {
42.             OH_LOG_ERROR(LOG_APP, "check InterfaceToken failed");
43.             free(token);
44.         }
45.         return OH_IPC_PARCEL_WRITE_ERROR;
46.     }
47.     free(token);
48.     auto *stubTest = reinterpret_cast<IpcCApiStubTest *>(userData);
49.     if (stubTest == nullptr) {
50.         return OH_IPC_CHECK_PARAM_ERROR;
51.     }
52.     auto rqCode = RequestCode(code);
53.     switch (rqCode) {
54.         case ASYNC_ADD_CODE: {
55.             return stubTest->AsyncAdd(data);
56.         }
57.         case REQUEST_EXIT_CODE: {
58.             return stubTest->RequestExitChildProcess();
59.         }
60.         default:
61.             break;
62.     }
63.     return OH_IPC_SUCCESS;
64. }

65. int IpcCApiStubTest::AsyncAdd(const OHIPCParcel *data) {
66.     int a = 0;
67.     int b = 0;
68.     OH_LOG_INFO(LOG_APP, "start async add a=%d,b=%d", a, b);
69.     if ((OH_IPCParcel_ReadInt32(data, &a) != OH_IPC_SUCCESS)
70.         || (OH_IPCParcel_ReadInt32(data, &b) != OH_IPC_SUCCESS)) {
71.         return OH_IPC_PARCEL_READ_ERROR;
72.     }
73.     // 此处获取proxy对象，用于后续的IPC通信调用。
74.     auto proxyCallBack = OH_IPCParcel_ReadRemoteProxy(data);
75.     if (proxyCallBack == nullptr) {
76.         return OH_IPC_PARCEL_READ_ERROR;
77.     }
78.     OH_LOG_INFO(LOG_APP, "start create sendCallBack thread!");
79.     // 此处开启线程异步完成功能实现并利用proxyCallBack完成结果响应，如果同步调用，则直接通过replyData写入响应结果即可。
80.     std::thread th([proxyCallBack, a, b] {
81.         auto data = OH_IPCParcel_Create();
82.         if (data == nullptr) {
83.             // 当创建parcel失败，则销毁获取到的proxyCallBack对象。
84.             OH_IPCRemoteProxy_Destroy(proxyCallBack);
85.             return;
86.         }
87.         auto reply = OH_IPCParcel_Create();
88.         if (reply == nullptr) {
89.             OH_IPCParcel_Destroy(data);
90.             OH_IPCRemoteProxy_Destroy(proxyCallBack);
91.             return;
92.         }
93.         if (OH_IPCParcel_WriteInt32(data, a + b) != OH_IPC_SUCCESS) {
94.             OH_IPCParcel_Destroy(data);
95.             OH_IPCParcel_Destroy(reply);
96.             OH_IPCRemoteProxy_Destroy(proxyCallBack);
97.             return;
98.         }
99.         // 异步线程处理结果通过IPC同步调用方式返回给业务请求方。
100.         OH_IPC_MessageOption option = { OH_IPC_REQUEST_MODE_SYNC, 0 };
101.         OH_LOG_INFO(LOG_APP, "thread start sendCallBack!");
102.         // 发送IPC通信请求。
103.         int ret = OH_IPCRemoteProxy_SendRequest(proxyCallBack, ASYNC_ADD_CODE, data, reply, &option);
104.         OH_LOG_INFO(LOG_APP, "thread sendCallBack ret = %d", ret);
105.         if (ret != OH_IPC_SUCCESS) {
106.             OH_IPCParcel_Destroy(data);
107.             OH_IPCParcel_Destroy(reply);
108.             OH_IPCRemoteProxy_Destroy(proxyCallBack);
109.             return;
110.         }
111.         OH_IPCRemoteProxy_Destroy(proxyCallBack);
112.         OH_IPCParcel_Destroy(data);
113.         OH_IPCParcel_Destroy(reply);
114.     });
115.     th.detach();
116.     return OH_IPC_SUCCESS;
117. }

118. int IpcCApiStubTest::RequestExitChildProcess() {
119.     std::unique_lock<std::mutex> autoLock(childMutex_);
120.     childCondVar_.notify_all();
121.     return OH_IPC_SUCCESS;
122. }

**客户端代理对象: IpcCApiProxyTest**

1. // 用户自定义错误码。
2. static constexpr int OH_IPC_CREATE_OBJECT_ERROR = OH_IPC_USER_ERROR_CODE_MIN + 1;

3. class IpcCApiProxyTest {
4. public:
5.     explicit IpcCApiProxyTest(OHIPCRemoteProxy *proxy);
6.     ~IpcCApiProxyTest();
7. public:
8.     int AsyncAdd(int a, int b, int &result);
9.     int RequestExitChildProcess();
10.     void ClearResource();
11. private:
12.     void SendAsyncReply(int &replyValue);
13.     int WaitForAsyncReply(int timeOut);
14.     // 注意：OnRemoteRequest方法是Stub对象需要实现的处理IPC请求消息的回调函数，Proxy侧不需要实现该函数。
15.     // 此处的OnRemoteRequest是用来给异步回调对象（下文中的replyStub_）配套使用的处理IPC请求消息的回调函数。
16.     static int OnRemoteRequest(uint32_t code, const OHIPCParcel *data,
17.         OHIPCParcel *reply, void *userData);
18.     static void OnDeathRecipientCB(void *userData);
19. private:
20.     int asyncReply_{};
21.     std::mutex mutex_;
22.     std::condition_variable cv_;
23.     OHIPCRemoteProxy *proxy_{ nullptr };
24.     OHIPCRemoteStub *replyStub_{ nullptr };
25.     OHIPCDeathRecipient *deathRecipient_{ nullptr };
26. };

27. IpcCApiProxyTest::IpcCApiProxyTest(OHIPCRemoteProxy *proxy) {
28.     if (proxy == nullptr) {
29.         OH_LOG_ERROR(LOG_APP, "proxy is nullptr");
30.         return;
31.     }
32.     proxy_ = proxy;
33.     replyStub_ = OH_IPCRemoteStub_Create(NATIVE_REMOTE_STUB_ASYNC_CALL_TEST_TOKEN.c_str(), OnRemoteRequest,
34.         nullptr, this);
35.     if (replyStub_ == nullptr) {
36.         OH_LOG_ERROR(LOG_APP, "create reply stub failed!");
37.         return;
38.     }
39.     // 创建死亡回调对象。
40.     deathRecipient_ = OH_IPCDeathRecipient_Create(OnDeathRecipientCB, nullptr, this);
41.     if (deathRecipient_ == nullptr) {
42.         OH_LOG_ERROR(LOG_APP, "OH_IPCDeathRecipient_Create failed!");
43.         return;
44.     }
45.     // 向Proxy注册死亡回调对象，用于感知服务端Stub对象的死亡状态。
46.     OH_IPCRemoteProxy_AddDeathRecipient(proxy_, deathRecipient_);
47. }

48. IpcCApiProxyTest::~IpcCApiProxyTest() {
49.     if (proxy_ != nullptr) {
50.         OH_IPCRemoteProxy_Destroy(proxy_);
51.     }
52.     if (deathRecipient_ != nullptr) {
53.         OH_IPCDeathRecipient_Destroy(deathRecipient_);
54.     }
55.     if (replyStub_ != nullptr) {
56.         OH_IPCRemoteStub_Destroy(replyStub_);
57.     }
58. }

59. int IpcCApiProxyTest::AsyncAdd(int a, int b, int &result) {
60.     OH_LOG_INFO(LOG_APP, "start %d + %d", a, b);
61.     auto data = OH_IPCParcel_Create();
62.     if (data == nullptr) {
63.         return OH_IPC_CREATE_OBJECT_ERROR;
64.     }
65.     // 写入接口校验token。
66.     if (OH_IPCParcel_WriteInterfaceToken(data, NATIVE_REMOTE_STUB_TEST_TOKEN.c_str()) != OH_IPC_SUCCESS) {
67.         OH_LOG_ERROR(LOG_APP, "OH_IPCParcel_WriteInterfaceToken failed!");
68.         OH_IPCParcel_Destroy(data);
69.         return OH_IPC_PARCEL_WRITE_ERROR;
70.     }
71.     if (OH_IPCParcel_WriteInt32(data, a) != OH_IPC_SUCCESS
72.         || OH_IPCParcel_WriteInt32(data, b) != OH_IPC_SUCCESS
73.         || OH_IPCParcel_WriteRemoteStub(data, replyStub_) != OH_IPC_SUCCESS) {
74.         OH_IPCParcel_Destroy(data);
75.         return OH_IPC_PARCEL_WRITE_ERROR;
76.     }
77.     // 异步发送使用replyStub_进行响应结果接收，异步处理需要写入用于接收结果的OHIPCRemoteStub对象。
78.     OH_IPC_MessageOption option = { OH_IPC_REQUEST_MODE_ASYNC, 0 };
79.     int ret = OH_IPCRemoteProxy_SendRequest(proxy_, RequestCode::ASYNC_ADD_CODE, data, nullptr, &option);
80.     if (ret != OH_IPC_SUCCESS) {
81.         OH_IPCParcel_Destroy(data);
82.         OH_LOG_ERROR(LOG_APP, "OH_IPCRemoteProxy_SendRequest failed!");
83.         return ret;
84.     }
85.     static constexpr int TIMEOUT = 3;
86.     WaitForAsyncReply(TIMEOUT);
87.     OH_LOG_INFO(LOG_APP, "asyncReply_:%d", asyncReply_);
88.     result = asyncReply_;
89.     OH_IPCParcel_Destroy(data);
90.     return OH_IPC_SUCCESS;
91. }

92. int IpcCApiProxyTest::RequestExitChildProcess() {
93.     auto data = OH_IPCParcel_Create();
94.     if (data == nullptr) {
95.         return OH_IPC_CREATE_OBJECT_ERROR;
96.     }
97.     auto reply = OH_IPCParcel_Create();
98.     if (reply == nullptr) {
99.         OH_IPCParcel_Destroy(data);
100.         return OH_IPC_CREATE_OBJECT_ERROR;
101.     }
102.     if (OH_IPCParcel_WriteInterfaceToken(data, NATIVE_REMOTE_STUB_TEST_TOKEN.c_str()) != OH_IPC_SUCCESS) {
103.         OH_LOG_ERROR(LOG_APP, "OH_IPCParcel_WriteInterfaceToken failed!");
104.         OH_IPCParcel_Destroy(data);
105.         OH_IPCParcel_Destroy(reply);
106.         return OH_IPC_PARCEL_WRITE_ERROR;
107.     }
108.     OH_IPC_MessageOption option = { OH_IPC_REQUEST_MODE_SYNC, 0 };
109.     int ret = OH_IPCRemoteProxy_SendRequest(proxy_, RequestCode::REQUEST_EXIT_CODE, data, reply, &option);
110.     if (ret != OH_IPC_SUCCESS) {
111.         OH_IPCParcel_Destroy(data);
112.         OH_IPCParcel_Destroy(reply);
113.         OH_LOG_ERROR(LOG_APP, "OH_IPCRemoteProxy_SendRequest failed!");
114.         return ret;
115.     }
116.     OH_IPCParcel_Destroy(data);
117.     OH_IPCParcel_Destroy(reply);
118.     return OH_IPC_SUCCESS;
119. }

120. void IpcCApiProxyTest::SendAsyncReply(int &replyValue) {
121.     std::unique_lock<std::mutex> lck(mutex_);
122.     asyncReply_ = replyValue;
123.     cv_.notify_all();
124. }

125. int IpcCApiProxyTest::WaitForAsyncReply(int timeOut) {
126.     asyncReply_ = 0;
127.     std::unique_lock<std::mutex> lck(mutex_);
128.     cv_.wait_for(lck, std::chrono::seconds(timeOut), [&] {
129.         return asyncReply_ != 0;
130.     });
131.     return asyncReply_;
132. }

133. int IpcCApiProxyTest::OnRemoteRequest(uint32_t code, const OHIPCParcel *data,
134.         OHIPCParcel *reply, void *userData) {
135.     OH_LOG_INFO(LOG_APP, "start %u", code);
136.     auto *proxyTest = reinterpret_cast<IpcCApiProxyTest *>(userData);
137.     if (proxyTest == nullptr || code != static_cast<uint32_t>(RequestCode::ASYNC_ADD_CODE)) {
138.         OH_LOG_ERROR(LOG_APP, "check param failed!");
139.         return OH_IPC_CHECK_PARAM_ERROR;
140.     }
141.     int32_t val = -1;
142.     if (OH_IPCParcel_ReadInt32(data, &val) != OH_IPC_SUCCESS) {
143.         OH_LOG_ERROR(LOG_APP, "OH_IPCParcel_ReadInt32 failed!");
144.         return OH_IPC_PARCEL_READ_ERROR;
145.     }
146.     proxyTest->SendAsyncReply(val);
147.     return OH_IPC_SUCCESS;
148. }

149. void IpcCApiProxyTest::ClearResource() {
150.     // clear resource;
151. }

152. void IpcCApiProxyTest::OnDeathRecipientCB(void *userData) {
153.     auto *proxyTest = reinterpret_cast<IpcCApiProxyTest *>(userData);
154.     if (proxyTest != nullptr) {
155.         proxyTest->ClearResource();
156.     }
157.     OH_LOG_INFO(LOG_APP, "the stub is dead!");
158. }

**服务端调用入口，服务端文件"libipcCapiDemo.so"**

1. IpcCApiStubTest g_ipcStubObj;

2. #ifdef __cplusplus
3. extern "C" {

4. // 服务需要实现如下函数，具体可参考元能力接口说明。
5. OHIPCRemoteStub* NativeChildProcess_OnConnect() {
6.     OH_LOG_INFO(LOG_APP, "NativeChildProcess_OnConnect");
7.     return g_ipcStubObj.GetRemoteStub();
8. }

9. void NativeChildProcess_MainProc() {
10.     OH_LOG_INFO(LOG_APP, "NativeChildProcess_MainProc");
11.     g_ipcStubObj.MainProc();
12.     OH_LOG_INFO(LOG_APP, "NativeChildProcess_MainProc End");
13. }

14. }
15. #endif

**客户端调用入口**

1. IpcCApiProxyTest *g_ipcProxy = nullptr;

2. // 元能力打通IPC通道回调接口。
3. void OnNativeChildProcessStarted(int errCode, OHIPCRemoteProxy *remoteProxy) {
4.     OH_LOG_INFO(LOG_APP, "OnNativeChildProcessStarted proxy=%{public}p err=%{public}d", remoteProxy, errCode);
5.     if (remoteProxy == nullptr) {
6.         return;
7.     }
8.     g_ipcProxy = new (std::nothrow) IpcCApiProxyTest(remoteProxy);
9.     if (g_ipcProxy == nullptr) {
10.         OH_IPCRemoteProxy_Destroy(remoteProxy);
11.         OH_LOG_ERROR(LOG_APP, "Alloc IpcCApiProxyTest object failed");
12.         return;
13.     }
14. }

15. int main(int argc, char *argv[]) {
16.     // 调用元能力接口，创建子进程，并加载参数中指定的libipcCapiDemo.so文件，进程启动结果通过回调参数OnNativeChildProcessStarted异步通知，在该回调函数中获取Proxy对象。
17.     int32_t ret = OH_Ability_CreateNativeChildProcess("libipcCapiDemo.so", OnNativeChildProcessStarted);
18.     if (ret != 0) {
19.         return -1;
20.     }
21.     if (g_ipcProxy == nullptr) {
22.         return -1;
23.     }
24.     int a = 2;
25.     int b = 3;
26.     int result = 0;
27.     ret = g_ipcProxy->AsyncAdd(a, b, result);
28.     OH_LOG_INFO(LOG_APP, "AsyncAdd: %d + %d = %d, ret=%d", a, b, result, ret);

29.     // 触发Stub侧进程退出。
30.     ret = g_ipcProxy->RequestExitChildProcess();
31.     // 此时，死亡通知回调函数（IpcCApiProxyTest::OnDeathRecipientCB）会被自动执行。
32.     if (g_ipcProxy != nullptr) {
33.         delete g_ipcProxy;
34.         g_ipcProxy = nullptr;
35.     }
36.     return 0;
37. }

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/ipc-rpc-development-guideline "IPC与RPC通信开发指导(ArkTS)")
# 远端状态订阅开发实例

更新时间: 2025-12-16 16:38

IPC/RPC提供了订阅远端Stub对象状态的机制。当远端Stub对象死亡时，可以自动触发本端Proxy注册的死亡通知。这种死亡通知订阅需要调用指定接口[registerDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#registerdeathrecipient9-1)完成。不再需要订阅时，也需要调用指定接口[unregisterDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#unregisterdeathrecipient9-1)取消订阅。

使用这种订阅机制的用户需要继承死亡通知类[DeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#deathrecipient)，并实现[onRemoteDied](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#onremotedied)方法清理资源。该方法会在远端Stub对象所在进程退出或当前RPC通信依赖的软总线连接断开时被回调。

注意

- 首先，Proxy订阅Stub死亡通知，若在订阅期间Stub状态正常，则在不再需要时取消订阅。
- 其次，若在订阅期间，Stub所在进程退出或当前RPC通信依赖的软总线连接断开，则会自动触发执行业务已向Proxy注册的自定义的[onRemoteDied](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#onremotedied)方法。

## 使用场景

IPC/RPC的订阅机制适用于以下场景：

1. IPC通信，Proxy对象需要感知远端Stub对象所在进程的状态。
2. RPC通信，Proxy对象需要感知远端Stub对象所在进程的状态，或者RPC通信依赖的软总线连接断开。
    
    当Proxy感知到Stub端死亡后，应该清理本地Proxy对象以及相关资源。
    
    注意
    
    RPC不支持匿名Stub对象（没有向SAMgr注册）的死亡通知，IPC支持匿名Stub对象的死亡通知。
    

## ArkTS侧接口

说明

- 此文档中的示例代码描述的是系统应用跨进程通信。
    
- 使用场景约束：客户端是第三方/系统应用，服务端是系统应用/服务
    

|接口名|返回值类型|功能描述|
|:--|:--|:--|
|[registerDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#registerdeathrecipient9-1)|void|注册用于接收远程对象死亡通知的回调，该方法应该在proxy侧调用。|
|[unregisterDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#unregisterdeathrecipient9-1)|void|注销用于接收远程对象死亡通知的回调。|
|[onRemoteDied](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#onremotedied)|void|Proxy侧注册死亡通知成功后，当远端Stub对象所在进程死亡时，将自动回调本方法。|

### 参考代码

在IPC场景中，创建变量want和connect。

1. import { Want, common } from '@kit.AbilityKit';
2. import { rpc } from '@kit.IPCKit';
3. import { hilog } from '@kit.PerformanceAnalysisKit';

4. let proxy: rpc.IRemoteObject | undefined;

5. let want: Want = {
6.   // 包名和组件名写实际的值
7.   bundleName: "ohos.rpc.test.server",
8.   abilityName: "ohos.rpc.test.server.ServiceAbility",
9. };
10. let connect: common.ConnectOptions = {
11.   onConnect: (elementName, remoteProxy) => {
12.     hilog.info(0x0000, 'testTag', 'RpcClient: js onConnect called');
13.     proxy = remoteProxy;
14.   },
15.   onDisconnect: (elementName) => {
16.     hilog.info(0x0000, 'testTag', 'RpcClient: onDisconnect');
17.   },
18.   onFailed: () => {
19.     hilog.info(0x0000, 'testTag', 'RpcClient: onFailed');
20.   }
21. };

在RPC场景中，创建变量want和connect。

1. import { Want, common } from '@kit.AbilityKit';
2. import { rpc } from '@kit.IPCKit';
3. import { hilog } from '@kit.PerformanceAnalysisKit';
4. import { distributedDeviceManager } from '@kit.DistributedServiceKit';
5. import { BusinessError } from '@kit.BasicServicesKit';

6. let dmInstance: distributedDeviceManager.DeviceManager | undefined;
7. let proxy: rpc.IRemoteObject | undefined;
8. let deviceList: Array<distributedDeviceManager.DeviceBasicInfo> | undefined;
9. let networkId: string | undefined;
10. let want: Want | undefined;
11. let connect: common.ConnectOptions | undefined;

12. try{
13.   dmInstance = distributedDeviceManager.createDeviceManager("ohos.rpc.test");
14. } catch (error) {
15.   let err: BusinessError = error as BusinessError;
16.   hilog.error(0x0000, 'testTag', 'createDeviceManager errCode:' + err.code + ', errMessage:' + err.message);
17. }

18. // 使用distributedDeviceManager获取目标设备NetworkId
19. if (dmInstance != undefined) {
20.   try {
21.     deviceList = dmInstance.getAvailableDeviceListSync();
22.     if (deviceList.length !== 0) {
23.       networkId = deviceList[0].networkId;
24.       want = {
25.         bundleName: "ohos.rpc.test.server",
26.         abilityName: "ohos.rpc.test.service.ServiceAbility",
27.         deviceId: networkId,
28.       };
29.       connect = {
30.         onConnect: (elementName, remoteProxy) => {
31.           hilog.info(0x0000, 'testTag', 'RpcClient: js onConnect called');
32.           proxy = remoteProxy;
33.         },
34.         onDisconnect: (elementName) => {
35.           hilog.info(0x0000, 'testTag', 'RpcClient: onDisconnect');
36.         },
37.         onFailed: () => {
38.           hilog.info(0x0000, 'testTag', 'RpcClient: onFailed');
39.         }
40.       };
41.     }
42.   } catch (error) {
43.     let err: BusinessError = error as BusinessError;
44.     hilog.error(0x0000, 'testTag', 'createDeviceManager err:' + err);
45.   }
46. }

FA模型使用[connectAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-ability-featureability#featureabilityconnectability7)接口连接Ability。

1. import { featureAbility } from '@kit.AbilityKit';

2. // 建立连接后返回的Id需要保存下来，在解绑服务时需要作为参数传入
3. let connectId = featureAbility.connectAbility(want, connect);

Stage模型使用common.UIAbilityContext的[connectServiceExtensionAbility](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-inner-application-uiabilitycontext#connectserviceextensionability)接口连接Ability。

在本文档的示例中，通过this.getUIContext().getHostContext()来获取UIAbilityContext，其中this代表继承自UIAbility的UIAbility实例。如需要在页面中使用UIAbilityContext提供的能力，请参见[获取UIAbility的上下文信息](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/uiability-usage#%E8%8E%B7%E5%8F%96uiability%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E4%BF%A1%E6%81%AF)。

1. let context: common.UIAbilityContext = this.getUIContext().getHostContext(); // UIAbilityContext
2. // 建立连接后返回的Id需要保存下来，在解绑服务时需要作为参数传入
3. let connectId = context.connectServiceExtensionAbility(want, connect);

成功连接服务后，onConnect回调函数中的Proxy对象会被赋值。此时，可以调用Proxy对象的[registerDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#registerdeathrecipient9-1)接口方法注册死亡回调，在Proxy不再使用的时候，调用[unregisterDeathRecipient](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#unregisterdeathrecipient9-1)接口方法注销死亡回调。

1. import { rpc } from '@kit.IPCKit';
2. import { hilog } from '@kit.PerformanceAnalysisKit';

3. let proxy: rpc.IRemoteObject | undefined;

4. class MyDeathRecipient implements rpc.DeathRecipient{
5.   onRemoteDied() {
6.     hilog.info(0x0000, 'testTag', 'server died');
7.   }
8. }
9. let deathRecipient = new MyDeathRecipient();
10. if (proxy != undefined) {
11.   // 此处的0为注册死亡监听的死亡通知的保留标志，暂无实际意义。且移除监听仅为示例，实际移除时机由业务自行判断
12.   proxy.registerDeathRecipient(deathRecipient, 0);
13.   proxy.unregisterDeathRecipient(deathRecipient, 0);
14. }

## Stub反向感知Proxy死亡状态（匿名Stub的特殊用法）

正向的死亡通知是Proxy感知Stub的状态，要实现反向的死亡通知（即Stub感知Proxy的状态），可以利用反向死亡通知。例如，进程A（原Stub所在进程）和进程B（原Proxy所在进程），进程B获取到进程A的原Proxy对象后，在B进程新建一个匿名Stub对象（未向SAMgr注册），称为回调Stub，通过[sendMessageRequest](https://developer.huawei.com/consumer/cn/doc/harmonyos-references/js-apis-rpc#sendmessagerequest9-2)接口将回调Stub传给进程A的原Stub，进程A就可以获取到进程B的回调Proxy。只要向回调Proxy注册了死亡通知，当进程B（回调Stub）死亡或者RPC通信依赖的软总线连接断开时，回调Proxy会感知并通知进程A（原Stub），从而实现反向死亡通知。

注意

- 反向死亡通知仅限设备内跨进程通信使用，不可用于跨设备。
- 当匿名Stub对象没有被任何一个Proxy引用时，对象会被自动释放。

[  
](https://developer.huawei.com/consumer/cn/doc/harmonyos-guides/ipc-capi-development-guideline "IPC与RPC通信开发指导(C/C++)")
